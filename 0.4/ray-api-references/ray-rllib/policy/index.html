
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="icon" href="../../../images/favicon.ico">
      <meta name="generator" content="mkdocs-1.2.3, mkdocs-material-8.1.3">
    
    
      
        <title>Policies - Ray</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.edf004c2.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.e6a45f82.min.css">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../../css/termynal.css">
    
      <link rel="stylesheet" href="../../../css/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="blue">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#policy-package" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-component="outdated" hidden>
        <aside class="md-banner md-banner--warning">
          
        </aside>
      </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="https://ray.io" title="Ray" class="md-header__button md-logo" aria-label="Ray" data-md-component="logo">
      
  <img src="../../../images/ray-logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Ray
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Policies
            
          </span>
        </div>
      </div>
    </div>
    
      <form class="md-header__option" data-md-component="palette">
        
          
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="blue"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
          
            <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31z"/></svg>
            </label>
          
        
          
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="red"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
          
            <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22z"/></svg>
            </label>
          
        
      </form>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/ray-project/ray" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ray-project/ray
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        Getting Started
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../ray-deployment/" class="md-tabs__link">
        Deploying Ray
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../ray-ecosystem/" class="md-tabs__link">
        Ecosystem
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../ray-examples/" class="md-tabs__link">
        Examples
      </a>
    </li>
  

      
        
  
  
    
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../" class="md-tabs__link md-tabs__link--active">
        API
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../ray-contributor-guide/" class="md-tabs__link">
        Contribute
      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="https://ray.io" title="Ray" class="md-nav__button md-logo" aria-label="Ray" data-md-component="logo">
      
  <img src="../../../images/ray-logo.png" alt="logo">

    </a>
    Ray
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/ray-project/ray" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ray-project/ray
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_1" type="checkbox" id="__nav_1" >
      
      
      
        
          
            
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../..">Getting Started</a>
          
            <label for="__nav_1">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="Getting Started" data-md-level="1">
        <label class="md-nav__title" for="__nav_1">
          <span class="md-nav__icon md-icon"></span>
          Getting Started
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../ray-overview/what-and-why-ray/" class="md-nav__link">
        Why Ray?
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../ray-overview/more-information/" class="md-nav__link">
        Learn more
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_1_4" type="checkbox" id="__nav_1_4" >
      
      
      
        
          
            
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../ray-core/">Ray Core</a>
          
            <label for="__nav_1_4">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="Ray Core" data-md-level="2">
        <label class="md-nav__title" for="__nav_1_4">
          <span class="md-nav__icon md-icon"></span>
          Ray Core
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../ray-core/key-concepts/" class="md-nav__link">
        Key concepts
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../ray-core/tutorials/" class="md-nav__link">
        Tutorials
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_1_5" type="checkbox" id="__nav_1_5" >
      
      
      
        
          
            
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../ray-ml/ray-data/">Ray Data</a>
          
            <label for="__nav_1_5">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="Ray Data" data-md-level="2">
        <label class="md-nav__title" for="__nav_1_5">
          <span class="md-nav__icon md-icon"></span>
          Ray Data
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../ray-ml/ray-data/key-concepts/" class="md-nav__link">
        Key concepts
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_1_5_3" type="checkbox" id="__nav_1_5_3" >
      
      
      
        
          
            
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../ray-ml/ray-data/tutorials/">Tutorials</a>
          
        </div>
      
      <nav class="md-nav" aria-label="Tutorials" data-md-level="3">
        <label class="md-nav__title" for="__nav_1_5_3">
          <span class="md-nav__icon md-icon"></span>
          Tutorials
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_1_6" type="checkbox" id="__nav_1_6" >
      
      
      
        
          
            
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../ray-ml/ray-train/">Ray Train</a>
          
            <label for="__nav_1_6">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="Ray Train" data-md-level="2">
        <label class="md-nav__title" for="__nav_1_6">
          <span class="md-nav__icon md-icon"></span>
          Ray Train
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../ray-ml/ray-train/key-concepts/" class="md-nav__link">
        Key concepts
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../ray-ml/ray-train/tutorials/" class="md-nav__link">
        Tutorials
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_1_7" type="checkbox" id="__nav_1_7" >
      
      
      
        
          
            
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../ray-ml/ray-rllib/">Ray RLlib</a>
          
            <label for="__nav_1_7">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="Ray RLlib" data-md-level="2">
        <label class="md-nav__title" for="__nav_1_7">
          <span class="md-nav__icon md-icon"></span>
          Ray RLlib
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../ray-ml/ray-rllib/key-concepts/" class="md-nav__link">
        Key concepts
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../ray-ml/ray-rllib/tutorials/" class="md-nav__link">
        Tutorials
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_1_8" type="checkbox" id="__nav_1_8" >
      
      
      
        
          
            
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../ray-ml/ray-tune/">Ray Tune</a>
          
            <label for="__nav_1_8">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="Ray Tune" data-md-level="2">
        <label class="md-nav__title" for="__nav_1_8">
          <span class="md-nav__icon md-icon"></span>
          Ray Tune
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../ray-ml/ray-tune/key-concepts/" class="md-nav__link">
        Key concepts
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../ray-ml/ray-tune/tutorials/" class="md-nav__link">
        Tutorials
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_1_9" type="checkbox" id="__nav_1_9" >
      
      
      
        
          
            
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../ray-ml/ray-serve/">Ray Serve</a>
          
            <label for="__nav_1_9">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="Ray Serve" data-md-level="2">
        <label class="md-nav__title" for="__nav_1_9">
          <span class="md-nav__icon md-icon"></span>
          Ray Serve
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../ray-ml/ray-serve/key-concepts/" class="md-nav__link">
        Key concepts
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_1_9_3" type="checkbox" id="__nav_1_9_3" >
      
      
      
        
          
            
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../ray-ml/ray-serve/tutorials/">Tutorials</a>
          
            <label for="__nav_1_9_3">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="Tutorials" data-md-level="3">
        <label class="md-nav__title" for="__nav_1_9_3">
          <span class="md-nav__icon md-icon"></span>
          Tutorials
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../ray-ml/ray-serve/tutorials/model-composition/" class="md-nav__link">
        Model composition
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_1_10" type="checkbox" id="__nav_1_10" >
      
      
      
        
          
            
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../ray-ml/ray-workflows/">Ray Workflows</a>
          
            <label for="__nav_1_10">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="Ray Workflows" data-md-level="2">
        <label class="md-nav__title" for="__nav_1_10">
          <span class="md-nav__icon md-icon"></span>
          Ray Workflows
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../ray-ml/ray-workflows/key-concepts/" class="md-nav__link">
        Key concepts
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../ray-ml/ray-workflows/tutorials/" class="md-nav__link">
        Tutorials
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" >
      
      
      
        
          
            
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../ray-deployment/">Deploying Ray</a>
          
            <label for="__nav_2">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="Deploying Ray" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Deploying Ray
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../ray-deployment/key-concepts/" class="md-nav__link">
        Key concepts
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../ray-deployment/tutorials/" class="md-nav__link">
        Tutorials
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
      
        
          
            
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../ray-ecosystem/">Ecosystem</a>
          
            <label for="__nav_3">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="Ecosystem" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Ecosystem
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../ray-ecosystem/integrations/integrations/" class="md-nav__link">
        Integrations
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../ray-ecosystem/integrations/joblib/" class="md-nav__link">
        Joblib
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" >
      
      
      
        
          
            
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../ray-examples/">Examples</a>
          
            <label for="__nav_4">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="Examples" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Examples
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_2" type="checkbox" id="__nav_4_2" >
      
      
      
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_4_2">
          Crash Course
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Crash Course" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_2">
          <span class="md-nav__icon md-icon"></span>
          Crash Course
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../ray-examples/ray-crash-course/00-Ray-Crash-Course-Overview/" class="md-nav__link">
        Ray "Crash Course" Overview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../ray-examples/ray-crash-course/01-Ray-Tasks/" class="md-nav__link">
        Ray Crash Course - Tasks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../ray-examples/ray-crash-course/02-Ray-Actors/" class="md-nav__link">
        Ray Crash Course - Actors
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../ray-examples/ray-crash-course/03-Why-Ray/" class="md-nav__link">
        Ray Crash Course - Why Ray?
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../ray-examples/ray-crash-course/04-Ray-Multiprocessing/" class="md-nav__link">
        Ray Crash Course - Python Multiprocessing with Ray
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../ray-examples/ray-crash-course/05-Ray-Parallel-Iterators/" class="md-nav__link">
        Ray Crash Course - Ray Parallel Iterators (Now deprecated in Ray 1.7)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../ray-examples/ray-crash-course/06-Exploring-Ray-API-Calls/" class="md-nav__link">
        Ray Crash Course - Exploring Ray API Calls
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../ray-examples/ray-crash-course/07-Running-Ray-Clusters/" class="md-nav__link">
        Ray Crash Course - Ray Clusters and the Ray CLI
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" checked>
      
      
      
        
          
            
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../">API</a>
          
            <label for="__nav_5">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="API" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          API
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_2" type="checkbox" id="__nav_5_2" checked>
      
      
      
        
          
            
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../">Ray RLlib</a>
          
            <label for="__nav_5_2">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="Ray RLlib" data-md-level="2">
        <label class="md-nav__title" for="__nav_5_2">
          <span class="md-nav__icon md-icon"></span>
          Ray RLlib
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../agents/" class="md-nav__link">
        Agents
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Policies
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Policies
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy" class="md-nav__link">
    Policy
  </a>
  
    <nav class="md-nav" aria-label="Policy">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.apply_gradients" class="md-nav__link">
    apply_gradients()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.compute_actions" class="md-nav__link">
    compute_actions()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.compute_actions_from_input_dict" class="md-nav__link">
    compute_actions_from_input_dict()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.compute_gradients" class="md-nav__link">
    compute_gradients()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.compute_log_likelihoods" class="md-nav__link">
    compute_log_likelihoods()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.compute_single_action" class="md-nav__link">
    compute_single_action()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.export_checkpoint" class="md-nav__link">
    export_checkpoint()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.export_model" class="md-nav__link">
    export_model()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.get_exploration_state" class="md-nav__link">
    get_exploration_state()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.get_initial_state" class="md-nav__link">
    get_initial_state()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.get_num_samples_loaded_into_buffer" class="md-nav__link">
    get_num_samples_loaded_into_buffer()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.get_session" class="md-nav__link">
    get_session()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.get_state" class="md-nav__link">
    get_state()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.get_weights" class="md-nav__link">
    get_weights()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.import_model_from_h5" class="md-nav__link">
    import_model_from_h5()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.is_recurrent" class="md-nav__link">
    is_recurrent()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.learn_on_batch" class="md-nav__link">
    learn_on_batch()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.learn_on_loaded_batch" class="md-nav__link">
    learn_on_loaded_batch()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.load_batch_into_buffer" class="md-nav__link">
    load_batch_into_buffer()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.loss" class="md-nav__link">
    loss()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.num_state_tensors" class="md-nav__link">
    num_state_tensors()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.on_global_var_update" class="md-nav__link">
    on_global_var_update()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.postprocess_trajectory" class="md-nav__link">
    postprocess_trajectory()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.set_state" class="md-nav__link">
    set_state()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.set_weights" class="md-nav__link">
    set_weights()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy" class="md-nav__link">
    TorchPolicy
  </a>
  
    <nav class="md-nav" aria-label="TorchPolicy">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.apply_gradients" class="md-nav__link">
    apply_gradients()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.compute_actions" class="md-nav__link">
    compute_actions()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.compute_actions_from_input_dict" class="md-nav__link">
    compute_actions_from_input_dict()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.export_checkpoint" class="md-nav__link">
    export_checkpoint()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.export_model" class="md-nav__link">
    export_model()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.extra_action_out" class="md-nav__link">
    extra_action_out()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.extra_compute_grad_fetches" class="md-nav__link">
    extra_compute_grad_fetches()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.extra_grad_info" class="md-nav__link">
    extra_grad_info()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.extra_grad_process" class="md-nav__link">
    extra_grad_process()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.get_initial_state" class="md-nav__link">
    get_initial_state()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.get_num_samples_loaded_into_buffer" class="md-nav__link">
    get_num_samples_loaded_into_buffer()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.get_state" class="md-nav__link">
    get_state()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.get_tower_stats" class="md-nav__link">
    get_tower_stats()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.get_weights" class="md-nav__link">
    get_weights()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.import_model_from_h5" class="md-nav__link">
    import_model_from_h5()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.is_recurrent" class="md-nav__link">
    is_recurrent()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.learn_on_loaded_batch" class="md-nav__link">
    learn_on_loaded_batch()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.load_batch_into_buffer" class="md-nav__link">
    load_batch_into_buffer()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.num_state_tensors" class="md-nav__link">
    num_state_tensors()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.optimizer" class="md-nav__link">
    optimizer()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.set_state" class="md-nav__link">
    set_state()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.set_weights" class="md-nav__link">
    set_weights()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy" class="md-nav__link">
    TFPolicy
  </a>
  
    <nav class="md-nav" aria-label="TFPolicy">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.apply_gradients" class="md-nav__link">
    apply_gradients()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.build_apply_op" class="md-nav__link">
    build_apply_op()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.compute_actions" class="md-nav__link">
    compute_actions()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.compute_actions_from_input_dict" class="md-nav__link">
    compute_actions_from_input_dict()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.compute_gradients" class="md-nav__link">
    compute_gradients()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.compute_log_likelihoods" class="md-nav__link">
    compute_log_likelihoods()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.copy" class="md-nav__link">
    copy()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.export_checkpoint" class="md-nav__link">
    export_checkpoint()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.export_model" class="md-nav__link">
    export_model()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.extra_compute_action_feed_dict" class="md-nav__link">
    extra_compute_action_feed_dict()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.extra_compute_action_fetches" class="md-nav__link">
    extra_compute_action_fetches()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.extra_compute_grad_feed_dict" class="md-nav__link">
    extra_compute_grad_feed_dict()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.extra_compute_grad_fetches" class="md-nav__link">
    extra_compute_grad_fetches()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.get_exploration_state" class="md-nav__link">
    get_exploration_state()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.get_placeholder" class="md-nav__link">
    get_placeholder()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.get_session" class="md-nav__link">
    get_session()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.get_state" class="md-nav__link">
    get_state()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.get_weights" class="md-nav__link">
    get_weights()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.gradients" class="md-nav__link">
    gradients()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.import_model_from_h5" class="md-nav__link">
    import_model_from_h5()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.is_recurrent" class="md-nav__link">
    is_recurrent()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.learn_on_batch" class="md-nav__link">
    learn_on_batch()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.loss_initialized" class="md-nav__link">
    loss_initialized()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.num_state_tensors" class="md-nav__link">
    num_state_tensors()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.optimizer" class="md-nav__link">
    optimizer()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.set_state" class="md-nav__link">
    set_state()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.set_weights" class="md-nav__link">
    set_weights()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.variables" class="md-nav__link">
    variables()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy_template.build_policy_class" class="md-nav__link">
    build_policy_class()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy_template.build_tf_policy" class="md-nav__link">
    build_tf_policy()
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../env/" class="md-nav__link">
        Environments
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../models/" class="md-nav__link">
        Models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../evaluation/" class="md-nav__link">
        Evaluation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../execution/" class="md-nav__link">
        Execution
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../utils/" class="md-nav__link">
        Utility
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../ray-core/" class="md-nav__link">
        Ray Core
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../ray-data/" class="md-nav__link">
        Ray Data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../ray-train/" class="md-nav__link">
        Ray Train
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../ray-tune/" class="md-nav__link">
        Ray Tune
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../ray-workflows/" class="md-nav__link">
        Ray Workflows
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../ray-serve/" class="md-nav__link">
        Ray Serve
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6" type="checkbox" id="__nav_6" >
      
      
      
        
          
            
          
        
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../ray-contributor-guide/">Contribute</a>
          
            <label for="__nav_6">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="Contribute" data-md-level="1">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          Contribute
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../ray-contributor-guide/getting-involved/" class="md-nav__link">
        Start Contributing
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../ray-contributor-guide/installing-ray/building-ray-on-linux-and-macos/" class="md-nav__link">
        Building Ray on Linux and macOS
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../ray-contributor-guide/installing-ray/building-ray-on-windows/" class="md-nav__link">
        Building Ray on Windows
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy" class="md-nav__link">
    Policy
  </a>
  
    <nav class="md-nav" aria-label="Policy">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.apply_gradients" class="md-nav__link">
    apply_gradients()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.compute_actions" class="md-nav__link">
    compute_actions()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.compute_actions_from_input_dict" class="md-nav__link">
    compute_actions_from_input_dict()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.compute_gradients" class="md-nav__link">
    compute_gradients()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.compute_log_likelihoods" class="md-nav__link">
    compute_log_likelihoods()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.compute_single_action" class="md-nav__link">
    compute_single_action()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.export_checkpoint" class="md-nav__link">
    export_checkpoint()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.export_model" class="md-nav__link">
    export_model()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.get_exploration_state" class="md-nav__link">
    get_exploration_state()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.get_initial_state" class="md-nav__link">
    get_initial_state()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.get_num_samples_loaded_into_buffer" class="md-nav__link">
    get_num_samples_loaded_into_buffer()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.get_session" class="md-nav__link">
    get_session()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.get_state" class="md-nav__link">
    get_state()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.get_weights" class="md-nav__link">
    get_weights()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.import_model_from_h5" class="md-nav__link">
    import_model_from_h5()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.is_recurrent" class="md-nav__link">
    is_recurrent()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.learn_on_batch" class="md-nav__link">
    learn_on_batch()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.learn_on_loaded_batch" class="md-nav__link">
    learn_on_loaded_batch()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.load_batch_into_buffer" class="md-nav__link">
    load_batch_into_buffer()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.loss" class="md-nav__link">
    loss()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.num_state_tensors" class="md-nav__link">
    num_state_tensors()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.on_global_var_update" class="md-nav__link">
    on_global_var_update()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.postprocess_trajectory" class="md-nav__link">
    postprocess_trajectory()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.set_state" class="md-nav__link">
    set_state()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy.Policy.set_weights" class="md-nav__link">
    set_weights()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy" class="md-nav__link">
    TorchPolicy
  </a>
  
    <nav class="md-nav" aria-label="TorchPolicy">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.apply_gradients" class="md-nav__link">
    apply_gradients()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.compute_actions" class="md-nav__link">
    compute_actions()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.compute_actions_from_input_dict" class="md-nav__link">
    compute_actions_from_input_dict()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.export_checkpoint" class="md-nav__link">
    export_checkpoint()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.export_model" class="md-nav__link">
    export_model()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.extra_action_out" class="md-nav__link">
    extra_action_out()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.extra_compute_grad_fetches" class="md-nav__link">
    extra_compute_grad_fetches()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.extra_grad_info" class="md-nav__link">
    extra_grad_info()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.extra_grad_process" class="md-nav__link">
    extra_grad_process()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.get_initial_state" class="md-nav__link">
    get_initial_state()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.get_num_samples_loaded_into_buffer" class="md-nav__link">
    get_num_samples_loaded_into_buffer()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.get_state" class="md-nav__link">
    get_state()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.get_tower_stats" class="md-nav__link">
    get_tower_stats()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.get_weights" class="md-nav__link">
    get_weights()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.import_model_from_h5" class="md-nav__link">
    import_model_from_h5()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.is_recurrent" class="md-nav__link">
    is_recurrent()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.learn_on_loaded_batch" class="md-nav__link">
    learn_on_loaded_batch()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.load_batch_into_buffer" class="md-nav__link">
    load_batch_into_buffer()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.num_state_tensors" class="md-nav__link">
    num_state_tensors()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.optimizer" class="md-nav__link">
    optimizer()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.set_state" class="md-nav__link">
    set_state()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.torch_policy.TorchPolicy.set_weights" class="md-nav__link">
    set_weights()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy" class="md-nav__link">
    TFPolicy
  </a>
  
    <nav class="md-nav" aria-label="TFPolicy">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.apply_gradients" class="md-nav__link">
    apply_gradients()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.build_apply_op" class="md-nav__link">
    build_apply_op()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.compute_actions" class="md-nav__link">
    compute_actions()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.compute_actions_from_input_dict" class="md-nav__link">
    compute_actions_from_input_dict()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.compute_gradients" class="md-nav__link">
    compute_gradients()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.compute_log_likelihoods" class="md-nav__link">
    compute_log_likelihoods()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.copy" class="md-nav__link">
    copy()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.export_checkpoint" class="md-nav__link">
    export_checkpoint()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.export_model" class="md-nav__link">
    export_model()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.extra_compute_action_feed_dict" class="md-nav__link">
    extra_compute_action_feed_dict()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.extra_compute_action_fetches" class="md-nav__link">
    extra_compute_action_fetches()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.extra_compute_grad_feed_dict" class="md-nav__link">
    extra_compute_grad_feed_dict()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.extra_compute_grad_fetches" class="md-nav__link">
    extra_compute_grad_fetches()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.get_exploration_state" class="md-nav__link">
    get_exploration_state()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.get_placeholder" class="md-nav__link">
    get_placeholder()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.get_session" class="md-nav__link">
    get_session()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.get_state" class="md-nav__link">
    get_state()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.get_weights" class="md-nav__link">
    get_weights()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.gradients" class="md-nav__link">
    gradients()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.import_model_from_h5" class="md-nav__link">
    import_model_from_h5()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.is_recurrent" class="md-nav__link">
    is_recurrent()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.learn_on_batch" class="md-nav__link">
    learn_on_batch()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.loss_initialized" class="md-nav__link">
    loss_initialized()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.num_state_tensors" class="md-nav__link">
    num_state_tensors()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.optimizer" class="md-nav__link">
    optimizer()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.set_state" class="md-nav__link">
    set_state()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.set_weights" class="md-nav__link">
    set_weights()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy.TFPolicy.variables" class="md-nav__link">
    variables()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ray.rllib.policy.policy_template.build_policy_class" class="md-nav__link">
    build_policy_class()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ray.rllib.policy.tf_policy_template.build_tf_policy" class="md-nav__link">
    build_tf_policy()
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                

<h1 id="policy-package"><code>policy</code> package</h1>


  <div class="doc doc-object doc-class">



<h2 class="doc doc-heading" id="ray.rllib.policy.policy.Policy">
        <code>
ray.rllib.policy.policy.Policy        </code>



</h2>

    <div class="doc doc-contents first">

      <p>Policy base class: Calculates actions, losses, and holds NN models.</p>
<p>Policy is the abstract superclass for all DL-framework specific sub-classes
(e.g. TFPolicy or TorchPolicy). It exposes APIs to</p>
<p>1) Compute actions from observation (and possibly other) inputs.
2) Manage the Policy's NN model(s), like exporting and loading their
   weights.
3) Postprocess a given trajectory from the environment or other input
   via the <code>postprocess_trajectory</code> method.
4) Compute losses from a train batch.
5) Perform updates from a train batch on the NN-models (this normally
   includes loss calculations) either a) in one monolithic step
   (<code>train_on_batch</code>) or b) via batch pre-loading, then n steps of actual
   loss computations and updates (<code>load_batch_into_buffer</code> +
   <code>learn_on_loaded_batch</code>).</p>
<p>Note: It is not recommended to sub-class Policy directly, but rather use
one of the following two convenience methods:
<code>rllib.policy.policy_template::build_policy_class</code> (PyTorch) or
<code>rllib.policy.tf_policy_template::build_tf_policy_class</code> (TF).</p>




  <div class="doc doc-children">









  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.policy.Policy.__init__">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_space</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h3>

    <div class="doc doc-contents ">

      <p>Initializes a Policy instance.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>observation_space</code></td>
        <td><code>Space</code></td>
        <td><p>Observation space of the policy.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>action_space</code></td>
        <td><code>Space</code></td>
        <td><p>Action space of the policy.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>config</code></td>
        <td><code>dict</code></td>
        <td><p>A complete Trainer/Policy config dict. For the default
config keys and values, see rllib/trainer/trainer.py.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_space</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span> <span class="n">action_space</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>             <span class="n">config</span><span class="p">:</span> <span class="n">TrainerConfigDict</span><span class="p">):</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="sd">&quot;&quot;&quot;Initializes a Policy instance.</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="sd">        observation_space: Observation space of the policy.</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="sd">        action_space: Action space of the policy.</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="sd">        config: A complete Trainer/Policy config dict. For the default</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="sd">            config keys and values, see rllib/trainer/trainer.py.</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Space</span> <span class="o">=</span> <span class="n">observation_space</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Space</span> <span class="o">=</span> <span class="n">action_space</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>    <span class="c1"># The base struct of the action space.</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>    <span class="c1"># E.g. action-space = gym.spaces.Dict({&quot;a&quot;: Discrete(2)}) -&gt;</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a>    <span class="c1"># action_space_struct = {&quot;a&quot;: Discrete(2)}</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">action_space_struct</span> <span class="o">=</span> <span class="n">get_base_struct_from_space</span><span class="p">(</span><span class="n">action_space</span><span class="p">)</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">:</span> <span class="n">TrainerConfigDict</span> <span class="o">=</span> <span class="n">config</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">framework</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;framework&quot;</span><span class="p">)</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a>    <span class="c1"># Create the callbacks object to use for handling custom callbacks.</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;callbacks&quot;</span><span class="p">):</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span> <span class="s2">&quot;DefaultCallbacks&quot;</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;callbacks&quot;</span><span class="p">)()</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a>        <span class="kn">from</span> <span class="nn">ray.rllib.agents.callbacks</span> <span class="kn">import</span> <span class="n">DefaultCallbacks</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span> <span class="s2">&quot;DefaultCallbacks&quot;</span> <span class="o">=</span> <span class="n">DefaultCallbacks</span><span class="p">()</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a>    <span class="c1"># The global timestep, broadcast down from time to time from the</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a>    <span class="c1"># local worker to all remote workers.</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">global_timestep</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a>    <span class="c1"># The action distribution class to use for action sampling, if any.</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a>    <span class="c1"># Child classes may set this.</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">dist_class</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Type</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a>    <span class="c1"># Maximal view requirements dict for `learn_on_batch()` and</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a>    <span class="c1"># `compute_actions` calls.</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a>    <span class="c1"># View requirements will be automatically filtered out later based</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>    <span class="c1"># on the postprocessing and loss functions to ensure optimal data</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a>    <span class="c1"># collection and transfer performance.</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a>    <span class="n">view_reqs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_default_view_requirements</span><span class="p">()</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;view_requirements&quot;</span><span class="p">):</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">view_requirements</span> <span class="o">=</span> <span class="n">view_reqs</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a>        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">view_reqs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>            <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">view_requirements</span><span class="p">:</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">view_requirements</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a>    <span class="c1"># Whether the Model&#39;s initial state (method) has been added</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a>    <span class="c1"># automatically based on the given view requirements of the model.</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_model_init_state_automatically_added</span> <span class="o">=</span> <span class="kc">False</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.policy.Policy.apply_gradients">
<code class="highlight language-python"><span class="n">apply_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gradients</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Applies the (previously) computed gradients.</p>
<p>Either this in combination with <code>compute_gradients()</code> or
<code>learn_on_batch()</code> must be implemented by subclasses.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>gradients</code></td>
        <td><code>Union[List[Tuple[Any, Any]], List[Any]]</code></td>
        <td><p>The already calculated gradients to apply to this
Policy.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">apply_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gradients</span><span class="p">:</span> <span class="n">ModelGradients</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="sd">&quot;&quot;&quot;Applies the (previously) computed gradients.</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="sd">    Either this in combination with `compute_gradients()` or</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="sd">    `learn_on_batch()` must be implemented by subclasses.</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="sd">        gradients: The already calculated gradients to apply to this</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="sd">            Policy.</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.policy.Policy.compute_actions">
<code class="highlight language-python"><span class="n">compute_actions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs_batch</span><span class="p">,</span> <span class="n">state_batches</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prev_action_batch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prev_reward_batch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">info_batch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">episodes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">explore</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">timestep</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Computes actions for the current policy.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>obs_batch</code></td>
        <td><code>Union[List[Union[Any, dict, tuple]], Any, dict, tuple]</code></td>
        <td><p>Batch of observations.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>state_batches</code></td>
        <td><code>Optional[List[Any]]</code></td>
        <td><p>List of RNN state input batches, if any.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>prev_action_batch</code></td>
        <td><code>Union[List[Union[Any, dict, tuple]], Any, dict, tuple]</code></td>
        <td><p>Batch of previous action values.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>prev_reward_batch</code></td>
        <td><code>Union[List[Union[Any, dict, tuple]], Any, dict, tuple]</code></td>
        <td><p>Batch of previous rewards.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>info_batch</code></td>
        <td><code>Optional[Dict[str, list]]</code></td>
        <td><p>Batch of info objects.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>episodes</code></td>
        <td><code>Optional[List[Episode]]</code></td>
        <td><p>List of Episode objects, one for each obs in
obs_batch. This provides access to all of the internal
episode state, which may be useful for model-based or
multi-agent algorithms.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>explore</code></td>
        <td><code>Optional[bool]</code></td>
        <td><p>Whether to pick an exploitation or exploration action.
Set to None (default) for using the value of
<code>self.config["explore"]</code>.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>timestep</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>The current (sampling) time step.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>actions (TensorType)</code></td>
      <td><p>Batch of output actions, with shape like
    [BATCH_SIZE, ACTION_SHAPE].
state_outs (List[TensorType]): List of RNN state output
    batches, if any, each with shape [BATCH_SIZE, STATE_SIZE].
info (List[dict]): Dictionary of extra feature batches, if any,
    with shape like
    {"f1": [BATCH_SIZE, ...], "f2": [BATCH_SIZE, ...]}.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@abstractmethod</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="k">def</span> <span class="nf">compute_actions</span><span class="p">(</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>        <span class="n">obs_batch</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorStructType</span><span class="p">],</span> <span class="n">TensorStructType</span><span class="p">],</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>        <span class="n">state_batches</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>        <span class="n">prev_action_batch</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorStructType</span><span class="p">],</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>                                 <span class="n">TensorStructType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>        <span class="n">prev_reward_batch</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorStructType</span><span class="p">],</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>                                 <span class="n">TensorStructType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>        <span class="n">info_batch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>        <span class="n">episodes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="s2">&quot;Episode&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>        <span class="n">explore</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>        <span class="n">timestep</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>        <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> \
<a id="__codelineno-0-16" name="__codelineno-0-16"></a>        <span class="n">Tuple</span><span class="p">[</span><span class="n">TensorType</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]]:</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>    <span class="sd">&quot;&quot;&quot;Computes actions for the current policy.</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a><span class="sd">        obs_batch: Batch of observations.</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a><span class="sd">        state_batches: List of RNN state input batches, if any.</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a><span class="sd">        prev_action_batch: Batch of previous action values.</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a><span class="sd">        prev_reward_batch: Batch of previous rewards.</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a><span class="sd">        info_batch: Batch of info objects.</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a><span class="sd">        episodes: List of Episode objects, one for each obs in</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a><span class="sd">            obs_batch. This provides access to all of the internal</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a><span class="sd">            episode state, which may be useful for model-based or</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a><span class="sd">            multi-agent algorithms.</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a><span class="sd">        explore: Whether to pick an exploitation or exploration action.</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a><span class="sd">            Set to None (default) for using the value of</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a><span class="sd">            `self.config[&quot;explore&quot;]`.</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a><span class="sd">        timestep: The current (sampling) time step.</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a><span class="sd">    Keyword Args:</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a><span class="sd">        kwargs: Forward compatibility placeholder</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a><span class="sd">        actions (TensorType): Batch of output actions, with shape like</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a><span class="sd">            [BATCH_SIZE, ACTION_SHAPE].</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a><span class="sd">        state_outs (List[TensorType]): List of RNN state output</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a><span class="sd">            batches, if any, each with shape [BATCH_SIZE, STATE_SIZE].</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a><span class="sd">        info (List[dict]): Dictionary of extra feature batches, if any,</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a><span class="sd">            with shape like</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a><span class="sd">            {&quot;f1&quot;: [BATCH_SIZE, ...], &quot;f2&quot;: [BATCH_SIZE, ...]}.</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.policy.Policy.compute_actions_from_input_dict">
<code class="highlight language-python"><span class="n">compute_actions_from_input_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dict</span><span class="p">,</span> <span class="n">explore</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">timestep</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">episodes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Computes actions from collected samples (across multiple-agents).</p>
<p>Takes an input dict (usually a SampleBatch) as its main data input.
This allows for using this method in case a more complex input pattern
(view requirements) is needed, for example when the Model requires the
last n observations, the last m actions/rewards, or a combination
of any of these.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>input_dict</code></td>
        <td><code>Union[ray.rllib.policy.sample_batch.SampleBatch, Dict[str, Union[Any, dict, tuple]]]</code></td>
        <td><p>A SampleBatch or input dict containing the Tensors
to compute actions. <code>input_dict</code> already abides to the
Policy's as well as the Model's view requirements and can
thus be passed to the Model as-is.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>explore</code></td>
        <td><code>bool</code></td>
        <td><p>Whether to pick an exploitation or exploration
action (default: None -&gt; use self.config["explore"]).</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>timestep</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>The current (sampling) time step.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>episodes</code></td>
        <td><code>Optional[List[Episode]]</code></td>
        <td><p>This provides access to all of the internal episodes'
state, which may be useful for model-based or multi-agent
algorithms.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>actions</code></td>
      <td><p>Batch of output actions, with shape like
    [BATCH_SIZE, ACTION_SHAPE].
state_outs: List of RNN state output
    batches, if any, each with shape [BATCH_SIZE, STATE_SIZE].
info: Dictionary of extra feature batches, if any, with shape like
    {"f1": [BATCH_SIZE, ...], "f2": [BATCH_SIZE, ...]}.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">compute_actions_from_input_dict</span><span class="p">(</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>        <span class="n">input_dict</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">SampleBatch</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorStructType</span><span class="p">]],</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>        <span class="n">explore</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>        <span class="n">timestep</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>        <span class="n">episodes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="s2">&quot;Episode&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>        <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> \
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>        <span class="n">Tuple</span><span class="p">[</span><span class="n">TensorType</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]]:</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>    <span class="sd">&quot;&quot;&quot;Computes actions from collected samples (across multiple-agents).</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="sd">    Takes an input dict (usually a SampleBatch) as its main data input.</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a><span class="sd">    This allows for using this method in case a more complex input pattern</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a><span class="sd">    (view requirements) is needed, for example when the Model requires the</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a><span class="sd">    last n observations, the last m actions/rewards, or a combination</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a><span class="sd">    of any of these.</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a><span class="sd">        input_dict: A SampleBatch or input dict containing the Tensors</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a><span class="sd">            to compute actions. `input_dict` already abides to the</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a><span class="sd">            Policy&#39;s as well as the Model&#39;s view requirements and can</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a><span class="sd">            thus be passed to the Model as-is.</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a><span class="sd">        explore: Whether to pick an exploitation or exploration</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a><span class="sd">            action (default: None -&gt; use self.config[&quot;explore&quot;]).</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a><span class="sd">        timestep: The current (sampling) time step.</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a><span class="sd">        episodes: This provides access to all of the internal episodes&#39;</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a><span class="sd">            state, which may be useful for model-based or multi-agent</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a><span class="sd">            algorithms.</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a><span class="sd">    Keyword Args:</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a><span class="sd">        kwargs: Forward compatibility placeholder.</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a><span class="sd">        actions: Batch of output actions, with shape like</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a><span class="sd">            [BATCH_SIZE, ACTION_SHAPE].</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a><span class="sd">        state_outs: List of RNN state output</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a><span class="sd">            batches, if any, each with shape [BATCH_SIZE, STATE_SIZE].</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a><span class="sd">        info: Dictionary of extra feature batches, if any, with shape like</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a><span class="sd">            {&quot;f1&quot;: [BATCH_SIZE, ...], &quot;f2&quot;: [BATCH_SIZE, ...]}.</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a>    <span class="c1"># Default implementation just passes obs, prev-a/r, and states on to</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a>    <span class="c1"># `self.compute_actions()`.</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a>    <span class="n">state_batches</span> <span class="o">=</span> <span class="p">[</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>        <span class="n">s</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">input_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span><span class="p">[:</span><span class="mi">9</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;state_in_&quot;</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a>    <span class="p">]</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_actions</span><span class="p">(</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a>        <span class="n">input_dict</span><span class="p">[</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">OBS</span><span class="p">],</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a>        <span class="n">state_batches</span><span class="p">,</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a>        <span class="n">prev_action_batch</span><span class="o">=</span><span class="n">input_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">PREV_ACTIONS</span><span class="p">),</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a>        <span class="n">prev_reward_batch</span><span class="o">=</span><span class="n">input_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">PREV_REWARDS</span><span class="p">),</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a>        <span class="n">info_batch</span><span class="o">=</span><span class="n">input_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">INFOS</span><span class="p">),</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a>        <span class="n">explore</span><span class="o">=</span><span class="n">explore</span><span class="p">,</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a>        <span class="n">timestep</span><span class="o">=</span><span class="n">timestep</span><span class="p">,</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a>        <span class="n">episodes</span><span class="o">=</span><span class="n">episodes</span><span class="p">,</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a>        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a>    <span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.policy.Policy.compute_gradients">
<code class="highlight language-python"><span class="n">compute_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">postprocessed_batch</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Computes gradients given a batch of experiences.</p>
<p>Either this in combination with <code>apply_gradients()</code> or
<code>learn_on_batch()</code> must be implemented by subclasses.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>postprocessed_batch</code></td>
        <td><code>SampleBatch</code></td>
        <td><p>The SampleBatch object to use
for calculating gradients.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>grads</code></td>
      <td><p>List of gradient output values.
grad_info: Extra policy-specific info values.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">compute_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">postprocessed_batch</span><span class="p">:</span> <span class="n">SampleBatch</span><span class="p">)</span> <span class="o">-&gt;</span> \
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>        <span class="n">Tuple</span><span class="p">[</span><span class="n">ModelGradients</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]]:</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="sd">&quot;&quot;&quot;Computes gradients given a batch of experiences.</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="sd">    Either this in combination with `apply_gradients()` or</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="sd">    `learn_on_batch()` must be implemented by subclasses.</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="sd">        postprocessed_batch: The SampleBatch object to use</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="sd">            for calculating gradients.</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a><span class="sd">        grads: List of gradient output values.</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a><span class="sd">        grad_info: Extra policy-specific info values.</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.policy.Policy.compute_log_likelihoods">
<code class="highlight language-python"><span class="n">compute_log_likelihoods</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">obs_batch</span><span class="p">,</span> <span class="n">state_batches</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prev_action_batch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prev_reward_batch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">actions_normalized</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Computes the log-prob/likelihood for a given action and observation.</p>
<p>The log-likelihood is calculated using this Policy's action
distribution class (self.dist_class).</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>actions</code></td>
        <td><code>Union[List[Any], Any]</code></td>
        <td><p>Batch of actions, for which to retrieve the
log-probs/likelihoods (given all other inputs: obs,
states, ..).</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>obs_batch</code></td>
        <td><code>Union[List[Any], Any]</code></td>
        <td><p>Batch of observations.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>state_batches</code></td>
        <td><code>Optional[List[Any]]</code></td>
        <td><p>List of RNN state input batches, if any.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>prev_action_batch</code></td>
        <td><code>Union[List[Any], Any]</code></td>
        <td><p>Batch of previous action values.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>prev_reward_batch</code></td>
        <td><code>Union[List[Any], Any]</code></td>
        <td><p>Batch of previous rewards.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>actions_normalized</code></td>
        <td><code>bool</code></td>
        <td><p>Is the given <code>actions</code> already normalized
(between -1.0 and 1.0) or not? If not and
<code>normalize_actions=True</code>, we need to normalize the given
actions first, before calculating log likelihoods.</p></td>
        <td><code>True</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Batch of log probs/likelihoods, with shape</code></td>
      <td><p>[BATCH_SIZE].</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">compute_log_likelihoods</span><span class="p">(</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>        <span class="n">actions</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">],</span> <span class="n">TensorType</span><span class="p">],</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>        <span class="n">obs_batch</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">],</span> <span class="n">TensorType</span><span class="p">],</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>        <span class="n">state_batches</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>        <span class="n">prev_action_batch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">],</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>                                          <span class="n">TensorType</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>        <span class="n">prev_reward_batch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">],</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>                                          <span class="n">TensorType</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>        <span class="n">actions_normalized</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorType</span><span class="p">:</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>    <span class="sd">&quot;&quot;&quot;Computes the log-prob/likelihood for a given action and observation.</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a><span class="sd">    The log-likelihood is calculated using this Policy&#39;s action</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a><span class="sd">    distribution class (self.dist_class).</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a><span class="sd">        actions: Batch of actions, for which to retrieve the</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a><span class="sd">            log-probs/likelihoods (given all other inputs: obs,</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a><span class="sd">            states, ..).</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a><span class="sd">        obs_batch: Batch of observations.</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a><span class="sd">        state_batches: List of RNN state input batches, if any.</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a><span class="sd">        prev_action_batch: Batch of previous action values.</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a><span class="sd">        prev_reward_batch: Batch of previous rewards.</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a><span class="sd">        actions_normalized: Is the given `actions` already normalized</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a><span class="sd">            (between -1.0 and 1.0) or not? If not and</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a><span class="sd">            `normalize_actions=True`, we need to normalize the given</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a><span class="sd">            actions first, before calculating log likelihoods.</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a><span class="sd">        Batch of log probs/likelihoods, with shape: [BATCH_SIZE].</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a>    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.policy.Policy.compute_single_action">
<code class="highlight language-python"><span class="n">compute_single_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">prev_action</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prev_reward</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">info</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">episode</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">explore</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">timestep</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Computes and returns a single (B=1) action value.</p>
<p>Takes an input dict (usually a SampleBatch) as its main data input.
This allows for using this method in case a more complex input pattern
(view requirements) is needed, for example when the Model requires the
last n observations, the last m actions/rewards, or a combination
of any of these.
Alternatively, in case no complex inputs are required, takes a single
<code>obs</code> values (and possibly single state values, prev-action/reward
values, etc..).</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>obs</code></td>
        <td><code>Union[Any, dict, tuple]</code></td>
        <td><p>Single observation.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>state</code></td>
        <td><code>Optional[List[Any]]</code></td>
        <td><p>List of RNN state inputs, if any.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>prev_action</code></td>
        <td><code>Union[Any, dict, tuple]</code></td>
        <td><p>Previous action value, if any.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>prev_reward</code></td>
        <td><code>Union[Any, dict, tuple]</code></td>
        <td><p>Previous reward, if any.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>info</code></td>
        <td><code>dict</code></td>
        <td><p>Info object, if any.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>input_dict</code></td>
        <td><code>Optional[ray.rllib.policy.sample_batch.SampleBatch]</code></td>
        <td><p>A SampleBatch or input dict containing the
single (unbatched) Tensors to compute actions. If given, it'll
be used instead of <code>obs</code>, <code>state</code>, <code>prev_action|reward</code>, and
<code>info</code>.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>episode</code></td>
        <td><code>Optional[Episode]</code></td>
        <td><p>This provides access to all of the internal episode state,
which may be useful for model-based or multi-agent algorithms.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>explore</code></td>
        <td><code>Optional[bool]</code></td>
        <td><p>Whether to pick an exploitation or
exploration action
(default: None -&gt; use self.config["explore"]).</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>timestep</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>The current (sampling) time step.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Tuple[Union[Any, dict, tuple], List[Any], Dict[str, Any]]</code></td>
      <td><p>Tuple consisting of the action, the list of RNN state outputs (if
any), and a dictionary of extra features (if any).</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">compute_single_action</span><span class="p">(</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>        <span class="n">obs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorStructType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>        <span class="n">state</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>        <span class="o">*</span><span class="p">,</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>        <span class="n">prev_action</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorStructType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>        <span class="n">prev_reward</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorStructType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>        <span class="n">info</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>        <span class="n">input_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">SampleBatch</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>        <span class="n">episode</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;Episode&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>        <span class="n">explore</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>        <span class="n">timestep</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>        <span class="c1"># Kwars placeholder for future compatibility.</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>        <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> \
<a id="__codelineno-0-16" name="__codelineno-0-16"></a>        <span class="n">Tuple</span><span class="p">[</span><span class="n">TensorStructType</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]]:</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>    <span class="sd">&quot;&quot;&quot;Computes and returns a single (B=1) action value.</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a><span class="sd">    Takes an input dict (usually a SampleBatch) as its main data input.</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a><span class="sd">    This allows for using this method in case a more complex input pattern</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a><span class="sd">    (view requirements) is needed, for example when the Model requires the</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a><span class="sd">    last n observations, the last m actions/rewards, or a combination</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a><span class="sd">    of any of these.</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a><span class="sd">    Alternatively, in case no complex inputs are required, takes a single</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a><span class="sd">    `obs` values (and possibly single state values, prev-action/reward</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a><span class="sd">    values, etc..).</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a><span class="sd">        obs: Single observation.</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a><span class="sd">        state: List of RNN state inputs, if any.</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a><span class="sd">        prev_action: Previous action value, if any.</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a><span class="sd">        prev_reward: Previous reward, if any.</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a><span class="sd">        info: Info object, if any.</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a><span class="sd">        input_dict: A SampleBatch or input dict containing the</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a><span class="sd">            single (unbatched) Tensors to compute actions. If given, it&#39;ll</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a><span class="sd">            be used instead of `obs`, `state`, `prev_action|reward`, and</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a><span class="sd">            `info`.</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a><span class="sd">        episode: This provides access to all of the internal episode state,</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a><span class="sd">            which may be useful for model-based or multi-agent algorithms.</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a><span class="sd">        explore: Whether to pick an exploitation or</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a><span class="sd">            exploration action</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a><span class="sd">            (default: None -&gt; use self.config[&quot;explore&quot;]).</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a><span class="sd">        timestep: The current (sampling) time step.</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a><span class="sd">    Keyword Args:</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a><span class="sd">        kwargs: Forward compatibility placeholder.</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="sd">        Tuple consisting of the action, the list of RNN state outputs (if</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="sd">        any), and a dictionary of extra features (if any).</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a>    <span class="c1"># Build the input-dict used for the call to</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a>    <span class="c1"># `self.compute_actions_from_input_dict()`.</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a>    <span class="k">if</span> <span class="n">input_dict</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a>        <span class="n">input_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">OBS</span><span class="p">:</span> <span class="n">obs</span><span class="p">}</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a>        <span class="k">if</span> <span class="n">state</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a>            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">state</span><span class="p">):</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a>                <span class="n">input_dict</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;state_in_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">s</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a>        <span class="k">if</span> <span class="n">prev_action</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a>            <span class="n">input_dict</span><span class="p">[</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">PREV_ACTIONS</span><span class="p">]</span> <span class="o">=</span> <span class="n">prev_action</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a>        <span class="k">if</span> <span class="n">prev_reward</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a>            <span class="n">input_dict</span><span class="p">[</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">PREV_REWARDS</span><span class="p">]</span> <span class="o">=</span> <span class="n">prev_reward</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a>        <span class="k">if</span> <span class="n">info</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a>            <span class="n">input_dict</span><span class="p">[</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">INFOS</span><span class="p">]</span> <span class="o">=</span> <span class="n">info</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a>    <span class="c1"># Batch all data in input dict.</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a>    <span class="n">input_dict</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">map_structure_with_path</span><span class="p">(</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a>        <span class="k">lambda</span> <span class="n">p</span><span class="p">,</span> <span class="n">s</span><span class="p">:</span> <span class="p">(</span><span class="n">s</span> <span class="k">if</span> <span class="n">p</span> <span class="o">==</span> <span class="s2">&quot;seq_lens&quot;</span> <span class="k">else</span> <span class="n">s</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="k">if</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>                      <span class="n">torch</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="k">else</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a>                      <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="mi">0</span><span class="p">)),</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a>        <span class="n">input_dict</span><span class="p">)</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>    <span class="n">episodes</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>    <span class="k">if</span> <span class="n">episode</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>        <span class="n">episodes</span> <span class="o">=</span> <span class="p">[</span><span class="n">episode</span><span class="p">]</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_actions_from_input_dict</span><span class="p">(</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>        <span class="n">input_dict</span><span class="o">=</span><span class="n">SampleBatch</span><span class="p">(</span><span class="n">input_dict</span><span class="p">),</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a>        <span class="n">episodes</span><span class="o">=</span><span class="n">episodes</span><span class="p">,</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a>        <span class="n">explore</span><span class="o">=</span><span class="n">explore</span><span class="p">,</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>        <span class="n">timestep</span><span class="o">=</span><span class="n">timestep</span><span class="p">,</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>    <span class="p">)</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>    <span class="c1"># Some policies don&#39;t return a tuple, but always just a single action.</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>    <span class="c1"># E.g. ES and ARS.</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a>        <span class="n">single_action</span> <span class="o">=</span> <span class="n">out</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>        <span class="n">state_out</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a>        <span class="n">info</span> <span class="o">=</span> <span class="p">{}</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a>    <span class="c1"># Normal case: Policy should return (action, state, info) tuple.</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a>        <span class="n">batched_action</span><span class="p">,</span> <span class="n">state_out</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">out</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a>        <span class="n">single_action</span> <span class="o">=</span> <span class="n">unbatch</span><span class="p">(</span><span class="n">batched_action</span><span class="p">)</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a>    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">single_action</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a>    <span class="n">single_action</span> <span class="o">=</span> <span class="n">single_action</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a>    <span class="c1"># Return action, internal state(s), infos.</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>    <span class="k">return</span> <span class="n">single_action</span><span class="p">,</span> <span class="p">[</span><span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">state_out</span><span class="p">],</span> \
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>        <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">info</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.policy.Policy.export_checkpoint">
<code class="highlight language-python"><span class="n">export_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">export_dir</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Export Policy checkpoint to local directory.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>export_dir</code></td>
        <td><code>str</code></td>
        <td><p>Local writable directory.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">export_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">export_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="sd">&quot;&quot;&quot;Export Policy checkpoint to local directory.</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="sd">        export_dir: Local writable directory.</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.policy.Policy.export_model">
<code class="highlight language-python"><span class="n">export_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">export_dir</span><span class="p">,</span> <span class="n">onnx</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Exports the Policy's Model to local directory for serving.</p>
<p>Note: The file format will depend on the deep learning framework used.
See the child classed of Policy and their <code>export_model</code>
implementations for more details.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>export_dir</code></td>
        <td><code>str</code></td>
        <td><p>Local writable directory.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>onnx</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>If given, will export model in ONNX format. The
value of this parameter set the ONNX OpSet version to use.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">export_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">export_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>                 <span class="n">onnx</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="sd">&quot;&quot;&quot;Exports the Policy&#39;s Model to local directory for serving.</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="sd">    Note: The file format will depend on the deep learning framework used.</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="sd">    See the child classed of Policy and their `export_model`</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="sd">    implementations for more details.</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="sd">        export_dir: Local writable directory.</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="sd">        onnx: If given, will export model in ONNX format. The</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a><span class="sd">            value of this parameter set the ONNX OpSet version to use.</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div>
        </details>
    </div>

  </div>




  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.policy.Policy.get_exploration_state">
<code class="highlight language-python"><span class="n">get_exploration_state</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Returns the state of this Policy's exploration component.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Dict[str, Any]</code></td>
      <td><p>Serializable information on the <code>self.exploration</code> object.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">get_exploration_state</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]:</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="sd">&quot;&quot;&quot;Returns the state of this Policy&#39;s exploration component.</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="sd">        Serializable information on the `self.exploration` object.</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">exploration</span><span class="o">.</span><span class="n">get_state</span><span class="p">()</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.policy.Policy.get_initial_state">
<code class="highlight language-python"><span class="n">get_initial_state</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Returns initial RNN state for the current policy.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>List[TensorType]</code></td>
      <td><p>Initial RNN state for the current policy.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">get_initial_state</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]:</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="sd">&quot;&quot;&quot;Returns initial RNN state for the current policy.</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="sd">        List[TensorType]: Initial RNN state for the current policy.</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>    <span class="k">return</span> <span class="p">[]</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.policy.Policy.get_num_samples_loaded_into_buffer">
<code class="highlight language-python"><span class="n">get_num_samples_loaded_into_buffer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">buffer_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Returns the number of currently loaded samples in the given buffer.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>buffer_index</code></td>
        <td><code>int</code></td>
        <td><p>The index of the buffer (a MultiGPUTowerStack)
to use on the devices. The number of buffers on each device
depends on the value of the <code>num_multi_gpu_tower_stacks</code> config
key.</p></td>
        <td><code>0</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>int</code></td>
      <td><p>The number of tuples loaded per device.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">get_num_samples_loaded_into_buffer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">buffer_index</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="sd">&quot;&quot;&quot;Returns the number of currently loaded samples in the given buffer.</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="sd">        buffer_index: The index of the buffer (a MultiGPUTowerStack)</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="sd">            to use on the devices. The number of buffers on each device</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="sd">            depends on the value of the `num_multi_gpu_tower_stacks` config</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="sd">            key.</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="sd">        The number of tuples loaded per device.</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.policy.Policy.get_session">
<code class="highlight language-python"><span class="n">get_session</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Returns tf.Session object to use for computing actions or None.</p>
<p>Note: This method only applies to TFPolicy sub-classes. All other
sub-classes should expect a None to be returned from this method.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Optional[tf1.Session]</code></td>
      <td><p>The tf Session to use for computing actions and losses with
    this policy or None.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">get_session</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;tf1.Session&quot;</span><span class="p">]:</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="sd">&quot;&quot;&quot;Returns tf.Session object to use for computing actions or None.</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="sd">    Note: This method only applies to TFPolicy sub-classes. All other</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="sd">    sub-classes should expect a None to be returned from this method.</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="sd">        The tf Session to use for computing actions and losses with</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="sd">            this policy or None.</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>    <span class="k">return</span> <span class="kc">None</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.policy.Policy.get_state">
<code class="highlight language-python"><span class="n">get_state</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Returns the entire current state of this Policy.</p>
<p>Note: Not to be confused with an RNN model's internal state.
State includes the Model(s)' weights, optimizer weights,
the exploration component's state, as well as global variables, such
as sampling timesteps.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Union[Dict[str, Any], List[Any]]</code></td>
      <td><p>Serialized local state.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">get_state</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]]:</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="sd">&quot;&quot;&quot;Returns the entire current state of this Policy.</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="sd">    Note: Not to be confused with an RNN model&#39;s internal state.</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="sd">    State includes the Model(s)&#39; weights, optimizer weights,</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="sd">    the exploration component&#39;s state, as well as global variables, such</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="sd">    as sampling timesteps.</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="sd">        Serialized local state.</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>    <span class="n">state</span> <span class="o">=</span> <span class="p">{</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>        <span class="c1"># All the policy&#39;s weights.</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>        <span class="s2">&quot;weights&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_weights</span><span class="p">(),</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a>        <span class="c1"># The current global timestep.</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>        <span class="s2">&quot;global_timestep&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_timestep</span><span class="p">,</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a>    <span class="p">}</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a>    <span class="k">return</span> <span class="n">state</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.policy.Policy.get_weights">
<code class="highlight language-python"><span class="n">get_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Returns model weights.</p>
<p>Note: The return value of this method will reside under the "weights"
key in the return value of Policy.get_state(). Model weights are only
one part of a Policy's state. Other state information contains:
optimizer variables, exploration state, and global state vars such as
the sampling timestep.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>dict</code></td>
      <td><p>Serializable copy or view of model weights.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">get_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModelWeights</span><span class="p">:</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="sd">&quot;&quot;&quot;Returns model weights.</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="sd">    Note: The return value of this method will reside under the &quot;weights&quot;</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="sd">    key in the return value of Policy.get_state(). Model weights are only</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="sd">    one part of a Policy&#39;s state. Other state information contains:</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="sd">    optimizer variables, exploration state, and global state vars such as</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="sd">    the sampling timestep.</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="sd">        Serializable copy or view of model weights.</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.policy.Policy.import_model_from_h5">
<code class="highlight language-python"><span class="n">import_model_from_h5</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">import_file</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Imports Policy from local file.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>import_file</code></td>
        <td><code>str</code></td>
        <td><p>Local readable file.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">import_model_from_h5</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">import_file</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="sd">&quot;&quot;&quot;Imports Policy from local file.</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="sd">        import_file (str): Local readable file.</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.policy.Policy.is_recurrent">
<code class="highlight language-python"><span class="n">is_recurrent</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Whether this Policy holds a recurrent Model.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>bool</code></td>
      <td><p>True if this Policy has-a RNN-based Model.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">is_recurrent</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="sd">&quot;&quot;&quot;Whether this Policy holds a recurrent Model.</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="sd">        True if this Policy has-a RNN-based Model.</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>    <span class="k">return</span> <span class="kc">False</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.policy.Policy.learn_on_batch">
<code class="highlight language-python"><span class="n">learn_on_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Perform one learning update, given <code>samples</code>.</p>
<p>Either this method or the combination of <code>compute_gradients</code> and
<code>apply_gradients</code> must be implemented by subclasses.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>samples</code></td>
        <td><code>SampleBatch</code></td>
        <td><p>The SampleBatch object to learn from.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Dict[str, Any]</code></td>
      <td><p>Dictionary of extra metadata from <code>compute_gradients()</code>.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Examples:</strong></p>
    <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">sample_batch</span> <span class="o">=</span> <span class="n">ev</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">ev</span><span class="o">.</span><span class="n">learn_on_batch</span><span class="p">(</span><span class="n">sample_batch</span><span class="p">)</span>
</code></pre></div>

        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">learn_on_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">:</span> <span class="n">SampleBatch</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]:</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="sd">&quot;&quot;&quot;Perform one learning update, given `samples`.</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="sd">    Either this method or the combination of `compute_gradients` and</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="sd">    `apply_gradients` must be implemented by subclasses.</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="sd">        samples: The SampleBatch object to learn from.</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="sd">        Dictionary of extra metadata from `compute_gradients()`.</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a><span class="sd">    Examples:</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a><span class="sd">        &gt;&gt;&gt; sample_batch = ev.sample()</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a><span class="sd">        &gt;&gt;&gt; ev.learn_on_batch(sample_batch)</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a>    <span class="c1"># The default implementation is simply a fused `compute_gradients` plus</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a>    <span class="c1"># `apply_gradients` call.</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a>    <span class="n">grads</span><span class="p">,</span> <span class="n">grad_info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_gradients</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">grads</span><span class="p">)</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a>    <span class="k">return</span> <span class="n">grad_info</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.policy.Policy.learn_on_loaded_batch">
<code class="highlight language-python"><span class="n">learn_on_loaded_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">buffer_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Runs a single step of SGD on an already loaded data in a buffer.</p>
<p>Runs an SGD step over a slice of the pre-loaded batch, offset by
the <code>offset</code> argument (useful for performing n minibatch SGD
updates repeatedly on the same, already pre-loaded data).</p>
<p>Updates the model weights based on the averaged per-device gradients.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>offset</code></td>
        <td><code>int</code></td>
        <td><p>Offset into the preloaded data. Used for pre-loading
a train-batch once to a device, then iterating over
(subsampling through) this batch n times doing minibatch SGD.</p></td>
        <td><code>0</code></td>
      </tr>
      <tr>
        <td><code>buffer_index</code></td>
        <td><code>int</code></td>
        <td><p>The index of the buffer (a MultiGPUTowerStack)
to take the already pre-loaded data from. The number of buffers
on each device depends on the value of the
<code>num_multi_gpu_tower_stacks</code> config key.</p></td>
        <td><code>0</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td></td>
      <td><p>The outputs of extra_ops evaluated over the batch.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">learn_on_loaded_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">offset</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">buffer_index</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">):</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="sd">&quot;&quot;&quot;Runs a single step of SGD on an already loaded data in a buffer.</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="sd">    Runs an SGD step over a slice of the pre-loaded batch, offset by</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="sd">    the `offset` argument (useful for performing n minibatch SGD</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="sd">    updates repeatedly on the same, already pre-loaded data).</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="sd">    Updates the model weights based on the averaged per-device gradients.</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="sd">        offset: Offset into the preloaded data. Used for pre-loading</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a><span class="sd">            a train-batch once to a device, then iterating over</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a><span class="sd">            (subsampling through) this batch n times doing minibatch SGD.</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a><span class="sd">        buffer_index: The index of the buffer (a MultiGPUTowerStack)</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a><span class="sd">            to take the already pre-loaded data from. The number of buffers</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a><span class="sd">            on each device depends on the value of the</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a><span class="sd">            `num_multi_gpu_tower_stacks` config key.</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a><span class="sd">        The outputs of extra_ops evaluated over the batch.</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a>    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.policy.Policy.load_batch_into_buffer">
<code class="highlight language-python"><span class="n">load_batch_into_buffer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">buffer_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Bulk-loads the given SampleBatch into the devices' memories.</p>
<p>The data is split equally across all the Policy's devices.
If the data is not evenly divisible by the batch size, excess data
should be discarded.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>batch</code></td>
        <td><code>SampleBatch</code></td>
        <td><p>The SampleBatch to load.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>buffer_index</code></td>
        <td><code>int</code></td>
        <td><p>The index of the buffer (a MultiGPUTowerStack) to use
on the devices. The number of buffers on each device depends
on the value of the <code>num_multi_gpu_tower_stacks</code> config key.</p></td>
        <td><code>0</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>int</code></td>
      <td><p>The number of tuples loaded per device.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">load_batch_into_buffer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">SampleBatch</span><span class="p">,</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>                           <span class="n">buffer_index</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="sd">&quot;&quot;&quot;Bulk-loads the given SampleBatch into the devices&#39; memories.</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="sd">    The data is split equally across all the Policy&#39;s devices.</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="sd">    If the data is not evenly divisible by the batch size, excess data</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="sd">    should be discarded.</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="sd">        batch: The SampleBatch to load.</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="sd">        buffer_index: The index of the buffer (a MultiGPUTowerStack) to use</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a><span class="sd">            on the devices. The number of buffers on each device depends</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a><span class="sd">            on the value of the `num_multi_gpu_tower_stacks` config key.</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a><span class="sd">        The number of tuples loaded per device.</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a>    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.policy.Policy.loss">
<code class="highlight language-python"><span class="n">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">dist_class</span><span class="p">,</span> <span class="n">train_batch</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Loss function for this Policy.</p>
<p>Override this method in order to implement custom loss computations.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>model</code></td>
        <td><code>ModelV2</code></td>
        <td><p>The model to calculate the loss(es).</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>dist_class</code></td>
        <td><code>ActionDistribution</code></td>
        <td><p>The action distribution class to sample actions
from the model's outputs.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>train_batch</code></td>
        <td><code>SampleBatch</code></td>
        <td><p>The input batch on which to calculate the loss.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Union[Any, List[Any]]</code></td>
      <td><p>Either a single loss tensor or a list of loss tensors.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@ExperimentalAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="nd">@OverrideToImplementCustomLogic</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">ModelV2</span><span class="p">,</span> <span class="n">dist_class</span><span class="p">:</span> <span class="n">ActionDistribution</span><span class="p">,</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>         <span class="n">train_batch</span><span class="p">:</span> <span class="n">SampleBatch</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">TensorType</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]]:</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>    <span class="sd">&quot;&quot;&quot;Loss function for this Policy.</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="sd">    Override this method in order to implement custom loss computations.</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="sd">        model: The model to calculate the loss(es).</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="sd">        dist_class: The action distribution class to sample actions</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="sd">            from the model&#39;s outputs.</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a><span class="sd">        train_batch: The input batch on which to calculate the loss.</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a><span class="sd">        Either a single loss tensor or a list of loss tensors.</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a>    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.policy.Policy.num_state_tensors">
<code class="highlight language-python"><span class="n">num_state_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>The number of internal states needed by the RNN-Model of the Policy.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>int</code></td>
      <td><p>The number of RNN internal states kept by this Policy's Model.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">num_state_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="sd">&quot;&quot;&quot;The number of internal states needed by the RNN-Model of the Policy.</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="sd">        int: The number of RNN internal states kept by this Policy&#39;s Model.</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>    <span class="k">return</span> <span class="mi">0</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.policy.Policy.on_global_var_update">
<code class="highlight language-python"><span class="n">on_global_var_update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">global_vars</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Called on an update to global vars.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>global_vars</code></td>
        <td><code>Dict[str, Any]</code></td>
        <td><p>Global variables by str key, broadcast from the
driver.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">on_global_var_update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">global_vars</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="sd">&quot;&quot;&quot;Called on an update to global vars.</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="sd">        global_vars: Global variables by str key, broadcast from the</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="sd">            driver.</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>    <span class="c1"># Store the current global time step (sum over all policies&#39; sample</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>    <span class="c1"># steps).</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">global_timestep</span> <span class="o">=</span> <span class="n">global_vars</span><span class="p">[</span><span class="s2">&quot;timestep&quot;</span><span class="p">]</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.policy.Policy.postprocess_trajectory">
<code class="highlight language-python"><span class="n">postprocess_trajectory</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_batch</span><span class="p">,</span> <span class="n">other_agent_batches</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">episode</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Implements algorithm-specific trajectory postprocessing.</p>
<p>This will be called on each trajectory fragment computed during policy
evaluation. Each fragment is guaranteed to be only from one episode.
The given fragment may or may not contain the end of this episode,
depending on the <code>batch_mode=truncate_episodes|complete_episodes</code>,
<code>rollout_fragment_length</code>, and other settings.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>sample_batch</code></td>
        <td><code>SampleBatch</code></td>
        <td><p>batch of experiences for the policy,
which will contain at most one episode trajectory.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>other_agent_batches</code></td>
        <td><code>Optional[Dict[Any, Tuple[Policy, ray.rllib.policy.sample_batch.SampleBatch]]]</code></td>
        <td><p>In a multi-agent env, this contains a
mapping of agent ids to (policy, agent_batch) tuples
containing the policy and experiences of the other agents.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>episode</code></td>
        <td><code>Optional[Episode]</code></td>
        <td><p>An optional multi-agent episode object to provide
access to all of the internal episode state, which may
be useful for model-based or multi-agent algorithms.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>SampleBatch</code></td>
      <td><p>The postprocessed sample batch.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">postprocess_trajectory</span><span class="p">(</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>        <span class="n">sample_batch</span><span class="p">:</span> <span class="n">SampleBatch</span><span class="p">,</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>        <span class="n">other_agent_batches</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="n">AgentID</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>            <span class="s2">&quot;Policy&quot;</span><span class="p">,</span> <span class="n">SampleBatch</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>        <span class="n">episode</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;Episode&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SampleBatch</span><span class="p">:</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>    <span class="sd">&quot;&quot;&quot;Implements algorithm-specific trajectory postprocessing.</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="sd">    This will be called on each trajectory fragment computed during policy</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="sd">    evaluation. Each fragment is guaranteed to be only from one episode.</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="sd">    The given fragment may or may not contain the end of this episode,</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a><span class="sd">    depending on the `batch_mode=truncate_episodes|complete_episodes`,</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a><span class="sd">    `rollout_fragment_length`, and other settings.</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a><span class="sd">        sample_batch: batch of experiences for the policy,</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a><span class="sd">            which will contain at most one episode trajectory.</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a><span class="sd">        other_agent_batches: In a multi-agent env, this contains a</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a><span class="sd">            mapping of agent ids to (policy, agent_batch) tuples</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a><span class="sd">            containing the policy and experiences of the other agents.</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a><span class="sd">        episode: An optional multi-agent episode object to provide</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a><span class="sd">            access to all of the internal episode state, which may</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a><span class="sd">            be useful for model-based or multi-agent algorithms.</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a><span class="sd">        The postprocessed sample batch.</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a>    <span class="c1"># The default implementation just returns the same, unaltered batch.</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a>    <span class="k">return</span> <span class="n">sample_batch</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.policy.Policy.set_state">
<code class="highlight language-python"><span class="n">set_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Restores the entire current state of this Policy from <code>state</code>.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>state</code></td>
        <td><code>Union[Dict[str, Any], List[Any]]</code></td>
        <td><p>The new state to set this policy to. Can be
obtained by calling <code>self.get_state()</code>.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">set_state</span><span class="p">(</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>        <span class="n">state</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]],</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>    <span class="sd">&quot;&quot;&quot;Restores the entire current state of this Policy from `state`.</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="sd">        state: The new state to set this policy to. Can be</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="sd">            obtained by calling `self.get_state()`.</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s2">&quot;weights&quot;</span><span class="p">])</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">global_timestep</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="s2">&quot;global_timestep&quot;</span><span class="p">]</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.policy.Policy.set_weights">
<code class="highlight language-python"><span class="n">set_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Sets this Policy's model's weights.</p>
<p>Note: Model weights are only one part of a Policy's state. Other
state information contains: optimizer variables, exploration state,
and global state vars such as the sampling timestep.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>weights</code></td>
        <td><code>dict</code></td>
        <td><p>Serializable copy or view of model weights.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">set_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">:</span> <span class="n">ModelWeights</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="sd">&quot;&quot;&quot;Sets this Policy&#39;s model&#39;s weights.</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="sd">    Note: Model weights are only one part of a Policy&#39;s state. Other</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="sd">    state information contains: optimizer variables, exploration state,</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="sd">    and global state vars such as the sampling timestep.</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="sd">        weights: Serializable copy or view of model weights.</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>



  <div class="doc doc-object doc-class">



<h2 class="doc doc-heading" id="ray.rllib.policy.torch_policy.TorchPolicy">
        <code>
ray.rllib.policy.torch_policy.TorchPolicy            (<a title="ray.rllib.policy.policy.Policy" href="#ray.rllib.policy.policy.Policy">Policy</a>)
        </code>



</h2>

    <div class="doc doc-contents first">

      <p>PyTorch specific Policy class to use with RLlib.</p>




  <div class="doc doc-children">









  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.torch_policy.TorchPolicy.__init__">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_space</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">action_distribution_class</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">action_sampler_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">action_distribution_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_seq_len</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">get_batch_divisibility_req</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h3>

    <div class="doc doc-contents ">

      <p>Initializes a TorchPolicy instance.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>observation_space</code></td>
        <td><code>Space</code></td>
        <td><p>Observation space of the policy.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>action_space</code></td>
        <td><code>Space</code></td>
        <td><p>Action space of the policy.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>config</code></td>
        <td><code>dict</code></td>
        <td><p>The Policy's config dict.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>model</code></td>
        <td><code>Optional[ray.rllib.models.torch.torch_modelv2.TorchModelV2]</code></td>
        <td><p>PyTorch policy module. Given observations as
input, this module must return a list of outputs where the
first item is action logits, and the rest can be any value.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>loss</code></td>
        <td><code>Optional[Callable[[ray.rllib.policy.policy.Policy, ray.rllib.models.modelv2.ModelV2, Type[ray.rllib.models.torch.torch_action_dist.TorchDistributionWrapper], ray.rllib.policy.sample_batch.SampleBatch], Union[Any, List[Any]]]]</code></td>
        <td><p>Callable that returns one or more (a list of) scalar loss
terms.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>action_distribution_class</code></td>
        <td><code>Optional[Type[ray.rllib.models.torch.torch_action_dist.TorchDistributionWrapper]]</code></td>
        <td><p>Class for a torch action distribution.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>action_sampler_fn</code></td>
        <td><code>Optional[Callable[[Any, List[Any]], Tuple[Any, Any]]]</code></td>
        <td><p>A callable returning a sampled action and its
log-likelihood given Policy, ModelV2, input_dict, state batches
(optional), explore, and timestep.
Provide <code>action_sampler_fn</code> if you would like to have full
control over the action computation step, including the
model forward pass, possible sampling from a distribution,
and exploration logic.
Note: If <code>action_sampler_fn</code> is given, <code>action_distribution_fn</code>
must be None. If both <code>action_sampler_fn</code> and
<code>action_distribution_fn</code> are None, RLlib will simply pass
inputs through <code>self.model</code> to get distribution inputs, create
the distribution object, sample from it, and apply some
exploration logic to the results.
The callable takes as inputs: Policy, ModelV2, input_dict
(SampleBatch), state_batches (optional), explore, and timestep.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>action_distribution_fn</code></td>
        <td><code>Optional[Callable[[ray.rllib.policy.policy.Policy, ray.rllib.models.modelv2.ModelV2, Any, Any, Any], Tuple[Any, Type[ray.rllib.models.torch.torch_action_dist.TorchDistributionWrapper], List[Any]]]]</code></td>
        <td><p>A callable returning distribution inputs
(parameters), a dist-class to generate an action distribution
object from, and internal-state outputs (or an empty list if
not applicable).
Provide <code>action_distribution_fn</code> if you would like to only
customize the model forward pass call. The resulting
distribution parameters are then used by RLlib to create a
distribution object, sample from it, and execute any
exploration logic.
Note: If <code>action_distribution_fn</code> is given, <code>action_sampler_fn</code>
must be None. If both <code>action_sampler_fn</code> and
<code>action_distribution_fn</code> are None, RLlib will simply pass
inputs through <code>self.model</code> to get distribution inputs, create
the distribution object, sample from it, and apply some
exploration logic to the results.
The callable takes as inputs: Policy, ModelV2, ModelInputDict,
explore, timestep, is_training.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>max_seq_len</code></td>
        <td><code>int</code></td>
        <td><p>Max sequence length for LSTM training.</p></td>
        <td><code>20</code></td>
      </tr>
      <tr>
        <td><code>get_batch_divisibility_req</code></td>
        <td><code>Optional[Callable[[ray.rllib.policy.policy.Policy], int]]</code></td>
        <td><p>Optional callable that returns the
divisibility requirement for sample batches given the Policy.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/torch_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>        <span class="n">observation_space</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>        <span class="n">action_space</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>        <span class="n">config</span><span class="p">:</span> <span class="n">TrainerConfigDict</span><span class="p">,</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>        <span class="o">*</span><span class="p">,</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>        <span class="n">model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TorchModelV2</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>        <span class="n">loss</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>            <span class="n">Policy</span><span class="p">,</span> <span class="n">ModelV2</span><span class="p">,</span> <span class="n">Type</span><span class="p">[</span><span class="n">TorchDistributionWrapper</span><span class="p">],</span> <span class="n">SampleBatch</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>        <span class="p">],</span> <span class="n">Union</span><span class="p">[</span><span class="n">TensorType</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>        <span class="n">action_distribution_class</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Type</span><span class="p">[</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>            <span class="n">TorchDistributionWrapper</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>        <span class="n">action_sampler_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>            <span class="n">TensorType</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a>        <span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">TensorType</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>        <span class="n">action_distribution_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a>            <span class="n">Policy</span><span class="p">,</span> <span class="n">ModelV2</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">,</span> <span class="n">TensorType</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a>        <span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">TensorType</span><span class="p">,</span> <span class="n">Type</span><span class="p">[</span><span class="n">TorchDistributionWrapper</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a>            <span class="n">TensorType</span><span class="p">]]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a>        <span class="n">max_seq_len</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a>        <span class="n">get_batch_divisibility_req</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Policy</span><span class="p">],</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a>                                                      <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a><span class="p">):</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a>    <span class="sd">&quot;&quot;&quot;Initializes a TorchPolicy instance.</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a><span class="sd">        observation_space: Observation space of the policy.</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a><span class="sd">        action_space: Action space of the policy.</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a><span class="sd">        config: The Policy&#39;s config dict.</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a><span class="sd">        model: PyTorch policy module. Given observations as</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a><span class="sd">            input, this module must return a list of outputs where the</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a><span class="sd">            first item is action logits, and the rest can be any value.</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a><span class="sd">        loss: Callable that returns one or more (a list of) scalar loss</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a><span class="sd">            terms.</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a><span class="sd">        action_distribution_class: Class for a torch action distribution.</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a><span class="sd">        action_sampler_fn: A callable returning a sampled action and its</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a><span class="sd">            log-likelihood given Policy, ModelV2, input_dict, state batches</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a><span class="sd">            (optional), explore, and timestep.</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a><span class="sd">            Provide `action_sampler_fn` if you would like to have full</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a><span class="sd">            control over the action computation step, including the</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a><span class="sd">            model forward pass, possible sampling from a distribution,</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a><span class="sd">            and exploration logic.</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a><span class="sd">            Note: If `action_sampler_fn` is given, `action_distribution_fn`</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a><span class="sd">            must be None. If both `action_sampler_fn` and</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a><span class="sd">            `action_distribution_fn` are None, RLlib will simply pass</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a><span class="sd">            inputs through `self.model` to get distribution inputs, create</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a><span class="sd">            the distribution object, sample from it, and apply some</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="sd">            exploration logic to the results.</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="sd">            The callable takes as inputs: Policy, ModelV2, input_dict</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a><span class="sd">            (SampleBatch), state_batches (optional), explore, and timestep.</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a><span class="sd">        action_distribution_fn: A callable returning distribution inputs</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a><span class="sd">            (parameters), a dist-class to generate an action distribution</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a><span class="sd">            object from, and internal-state outputs (or an empty list if</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a><span class="sd">            not applicable).</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a><span class="sd">            Provide `action_distribution_fn` if you would like to only</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a><span class="sd">            customize the model forward pass call. The resulting</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a><span class="sd">            distribution parameters are then used by RLlib to create a</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a><span class="sd">            distribution object, sample from it, and execute any</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a><span class="sd">            exploration logic.</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a><span class="sd">            Note: If `action_distribution_fn` is given, `action_sampler_fn`</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a><span class="sd">            must be None. If both `action_sampler_fn` and</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a><span class="sd">            `action_distribution_fn` are None, RLlib will simply pass</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a><span class="sd">            inputs through `self.model` to get distribution inputs, create</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a><span class="sd">            the distribution object, sample from it, and apply some</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a><span class="sd">            exploration logic to the results.</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a><span class="sd">            The callable takes as inputs: Policy, ModelV2, ModelInputDict,</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a><span class="sd">            explore, timestep, is_training.</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a><span class="sd">        max_seq_len: Max sequence length for LSTM training.</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a><span class="sd">        get_batch_divisibility_req: Optional callable that returns the</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a><span class="sd">            divisibility requirement for sample batches given the Policy.</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">framework</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;framework&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;torch&quot;</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">observation_space</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>    <span class="c1"># Create multi-GPU model towers, if necessary.</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>    <span class="c1"># - The central main model will be stored under self.model, residing</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a>    <span class="c1">#   on self.device (normally, a CPU).</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a>    <span class="c1"># - Each GPU will have a copy of that model under</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a>    <span class="c1">#   self.model_gpu_towers, matching the devices in self.devices.</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>    <span class="c1"># - Parallelization is done by splitting the train batch and passing</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>    <span class="c1">#   it through the model copies in parallel, then averaging over the</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>    <span class="c1">#   resulting gradients, applying these averages on the main model and</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>    <span class="c1">#   updating all towers&#39; weights from the main model.</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>    <span class="c1"># - In case of just one device (1 (fake or real) GPU or 1 CPU), no</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>    <span class="c1">#   parallelization will be done.</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>    <span class="c1"># If no Model is provided, build a default one here.</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a>    <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a>        <span class="n">dist_class</span><span class="p">,</span> <span class="n">logit_dim</span> <span class="o">=</span> <span class="n">ModelCatalog</span><span class="o">.</span><span class="n">get_action_dist</span><span class="p">(</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a>            <span class="n">action_space</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">],</span> <span class="n">framework</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">framework</span><span class="p">)</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a>        <span class="n">model</span> <span class="o">=</span> <span class="n">ModelCatalog</span><span class="o">.</span><span class="n">get_model_v2</span><span class="p">(</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a>            <span class="n">obs_space</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span><span class="p">,</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a>            <span class="n">action_space</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">action_space</span><span class="p">,</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a>            <span class="n">num_outputs</span><span class="o">=</span><span class="n">logit_dim</span><span class="p">,</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a>            <span class="n">model_config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">],</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a>            <span class="n">framework</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">framework</span><span class="p">)</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>        <span class="k">if</span> <span class="n">action_distribution_class</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>            <span class="n">action_distribution_class</span> <span class="o">=</span> <span class="n">dist_class</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>    <span class="c1"># Get devices to build the graph on.</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>    <span class="n">worker_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;worker_index&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;_fake_gpus&quot;</span><span class="p">]</span> <span class="ow">and</span> \
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>            <span class="n">ray</span><span class="o">.</span><span class="n">worker</span><span class="o">.</span><span class="n">_mode</span><span class="p">()</span> <span class="o">==</span> <span class="n">ray</span><span class="o">.</span><span class="n">worker</span><span class="o">.</span><span class="n">LOCAL_MODE</span><span class="p">:</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>        <span class="n">num_gpus</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>    <span class="k">elif</span> <span class="n">worker_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>        <span class="n">num_gpus</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;num_gpus&quot;</span><span class="p">]</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>        <span class="n">num_gpus</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;num_gpus_per_worker&quot;</span><span class="p">]</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>    <span class="n">gpu_ids</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()))</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>    <span class="c1"># Place on one or more CPU(s) when either:</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>    <span class="c1"># - Fake GPU mode.</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>    <span class="c1"># - num_gpus=0 (either set by user or we are in local_mode=True).</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>    <span class="c1"># - No GPUs available.</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>    <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;_fake_gpus&quot;</span><span class="p">]</span> <span class="ow">or</span> <span class="n">num_gpus</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">gpu_ids</span><span class="p">:</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;TorchPolicy (worker=</span><span class="si">{}</span><span class="s2">) running on </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>            <span class="n">worker_idx</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>            <span class="k">if</span> <span class="n">worker_idx</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="s2">&quot;local&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> fake-GPUs&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">num_gpus</span><span class="p">)</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>            <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;_fake_gpus&quot;</span><span class="p">]</span> <span class="k">else</span> <span class="s2">&quot;CPU&quot;</span><span class="p">))</span>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">devices</span> <span class="o">=</span> <span class="p">[</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">num_gpus</span><span class="p">))</span> <span class="ow">or</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a>        <span class="p">]</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model_gpu_towers</span> <span class="o">=</span> <span class="p">[</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a>            <span class="n">model</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">num_gpus</span><span class="p">))</span> <span class="ow">or</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a>        <span class="p">]</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;target_model&quot;</span><span class="p">):</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">target_models</span> <span class="o">=</span> <span class="p">{</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a>                <span class="n">m</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_model</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a>                <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_gpu_towers</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>            <span class="p">}</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>    <span class="c1"># Place on one or more actual GPU(s), when:</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a>    <span class="c1"># - num_gpus &gt; 0 (set by user) AND</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>    <span class="c1"># - local_mode=False AND</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>    <span class="c1"># - actual GPUs available AND</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>    <span class="c1"># - non-fake GPU mode.</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a>        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;TorchPolicy (worker=</span><span class="si">{}</span><span class="s2">) running on </span><span class="si">{}</span><span class="s2"> GPU(s).&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>            <span class="n">worker_idx</span> <span class="k">if</span> <span class="n">worker_idx</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="s2">&quot;local&quot;</span><span class="p">,</span> <span class="n">num_gpus</span><span class="p">))</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>        <span class="c1"># We are a remote worker (WORKER_MODE=1):</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a>        <span class="c1"># GPUs should be assigned to us by ray.</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a>        <span class="k">if</span> <span class="n">ray</span><span class="o">.</span><span class="n">worker</span><span class="o">.</span><span class="n">_mode</span><span class="p">()</span> <span class="o">==</span> <span class="n">ray</span><span class="o">.</span><span class="n">worker</span><span class="o">.</span><span class="n">WORKER_MODE</span><span class="p">:</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a>            <span class="n">gpu_ids</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">get_gpu_ids</span><span class="p">()</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">gpu_ids</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">num_gpus</span><span class="p">:</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a>                <span class="s2">&quot;TorchPolicy was not able to find enough GPU IDs! Found &quot;</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a>                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">gpu_ids</span><span class="si">}</span><span class="s2">, but num_gpus=</span><span class="si">{</span><span class="n">num_gpus</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">devices</span> <span class="o">=</span> <span class="p">[</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a>            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">id_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">gpu_ids</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">num_gpus</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a>        <span class="p">]</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">devices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a>        <span class="n">ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">id_</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">id_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">gpu_ids</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">num_gpus</span><span class="p">]</span>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model_gpu_towers</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ids</span><span class="p">):</span>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a>            <span class="n">model_copy</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">model_gpu_towers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model_copy</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">devices</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a>        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;target_model&quot;</span><span class="p">):</span>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">target_models</span> <span class="o">=</span> <span class="p">{</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a>                <span class="n">m</span><span class="p">:</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_model</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">devices</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a>                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_gpu_towers</span><span class="p">)</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a>            <span class="p">}</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_gpu_towers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a>    <span class="c1"># Lock used for locking some methods on the object-level.</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a>    <span class="c1"># This prevents possible race conditions when calling the model</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a>    <span class="c1"># first, then its value function (e.g. in a loss function), in</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a>    <span class="c1"># between of which another model call is made (e.g. to compute an</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a>    <span class="c1"># action).</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_lock</span> <span class="o">=</span> <span class="n">threading</span><span class="o">.</span><span class="n">RLock</span><span class="p">()</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_state_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_initial_state</span><span class="p">()</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_is_recurrent</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_state_inputs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a>    <span class="c1"># Auto-update model&#39;s inference view requirements, if recurrent.</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_update_model_view_requirements_from_init_state</span><span class="p">()</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a>    <span class="c1"># Combine view_requirements for Model and Policy.</span>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">view_requirements</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">view_requirements</span><span class="p">)</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">exploration</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_exploration</span><span class="p">()</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">unwrapped_model</span> <span class="o">=</span> <span class="n">model</span>  <span class="c1"># used to support DistributedDataParallel</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a>    <span class="c1"># To ensure backward compatibility:</span>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a>    <span class="c1"># Old way: If `loss` provided here, use as-is (as a function).</span>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a>    <span class="k">if</span> <span class="n">loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span> <span class="o">=</span> <span class="n">loss</span>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a>    <span class="c1"># New way: Convert the overridden `self.loss` into a plain function,</span>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a>    <span class="c1"># so it can be called the same way as `loss` would be, ensuring</span>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a>    <span class="c1"># backward compatibility.</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a>    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="vm">__func__</span><span class="o">.</span><span class="vm">__qualname__</span> <span class="o">!=</span> <span class="s2">&quot;Policy.loss&quot;</span><span class="p">:</span>
<a id="__codelineno-0-194" name="__codelineno-0-194"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="vm">__func__</span>
<a id="__codelineno-0-195" name="__codelineno-0-195"></a>    <span class="c1"># `loss` not provided nor overridden from Policy -&gt; Set to None.</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-197" name="__codelineno-0-197"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-198" name="__codelineno-0-198"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_optimizers</span> <span class="o">=</span> <span class="n">force_list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">())</span>
<a id="__codelineno-0-199" name="__codelineno-0-199"></a>    <span class="c1"># Store, which params (by index within the model&#39;s list of</span>
<a id="__codelineno-0-200" name="__codelineno-0-200"></a>    <span class="c1"># parameters) should be updated per optimizer.</span>
<a id="__codelineno-0-201" name="__codelineno-0-201"></a>    <span class="c1"># Maps optimizer idx to set or param indices.</span>
<a id="__codelineno-0-202" name="__codelineno-0-202"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">multi_gpu_param_groups</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Set</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-203" name="__codelineno-0-203"></a>    <span class="n">main_params</span> <span class="o">=</span> <span class="p">{</span><span class="n">p</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())}</span>
<a id="__codelineno-0-204" name="__codelineno-0-204"></a>    <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizers</span><span class="p">:</span>
<a id="__codelineno-0-205" name="__codelineno-0-205"></a>        <span class="n">param_indices</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-206" name="__codelineno-0-206"></a>        <span class="k">for</span> <span class="n">pg_idx</span><span class="p">,</span> <span class="n">pg</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">o</span><span class="o">.</span><span class="n">param_groups</span><span class="p">):</span>
<a id="__codelineno-0-207" name="__codelineno-0-207"></a>            <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">pg</span><span class="p">[</span><span class="s2">&quot;params&quot;</span><span class="p">]:</span>
<a id="__codelineno-0-208" name="__codelineno-0-208"></a>                <span class="n">param_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">main_params</span><span class="p">[</span><span class="n">p</span><span class="p">])</span>
<a id="__codelineno-0-209" name="__codelineno-0-209"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">multi_gpu_param_groups</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">param_indices</span><span class="p">))</span>
<a id="__codelineno-0-210" name="__codelineno-0-210"></a>
<a id="__codelineno-0-211" name="__codelineno-0-211"></a>    <span class="c1"># Create n sample-batch buffers (num_multi_gpu_tower_stacks), each</span>
<a id="__codelineno-0-212" name="__codelineno-0-212"></a>    <span class="c1"># one with m towers (num_gpus).</span>
<a id="__codelineno-0-213" name="__codelineno-0-213"></a>    <span class="n">num_buffers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;num_multi_gpu_tower_stacks&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-214" name="__codelineno-0-214"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_loaded_batches</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_buffers</span><span class="p">)]</span>
<a id="__codelineno-0-215" name="__codelineno-0-215"></a>
<a id="__codelineno-0-216" name="__codelineno-0-216"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">dist_class</span> <span class="o">=</span> <span class="n">action_distribution_class</span>
<a id="__codelineno-0-217" name="__codelineno-0-217"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">action_sampler_fn</span> <span class="o">=</span> <span class="n">action_sampler_fn</span>
<a id="__codelineno-0-218" name="__codelineno-0-218"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">action_distribution_fn</span> <span class="o">=</span> <span class="n">action_distribution_fn</span>
<a id="__codelineno-0-219" name="__codelineno-0-219"></a>
<a id="__codelineno-0-220" name="__codelineno-0-220"></a>    <span class="c1"># If set, means we are using distributed allreduce during learning.</span>
<a id="__codelineno-0-221" name="__codelineno-0-221"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">distributed_world_size</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-222" name="__codelineno-0-222"></a>
<a id="__codelineno-0-223" name="__codelineno-0-223"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">max_seq_len</span> <span class="o">=</span> <span class="n">max_seq_len</span>
<a id="__codelineno-0-224" name="__codelineno-0-224"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">batch_divisibility_req</span> <span class="o">=</span> <span class="n">get_batch_divisibility_req</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="k">if</span> \
<a id="__codelineno-0-225" name="__codelineno-0-225"></a>        <span class="n">callable</span><span class="p">(</span><span class="n">get_batch_divisibility_req</span><span class="p">)</span> <span class="k">else</span> \
<a id="__codelineno-0-226" name="__codelineno-0-226"></a>        <span class="p">(</span><span class="n">get_batch_divisibility_req</span> <span class="ow">or</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.torch_policy.TorchPolicy.apply_gradients">
<code class="highlight language-python"><span class="n">apply_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gradients</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Applies the (previously) computed gradients.</p>
<p>Either this in combination with <code>compute_gradients()</code> or
<code>learn_on_batch()</code> must be implemented by subclasses.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>gradients</code></td>
        <td><code>Union[List[Tuple[Any, Any]], List[Any]]</code></td>
        <td><p>The already calculated gradients to apply to this
Policy.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/torch_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="k">def</span> <span class="nf">apply_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gradients</span><span class="p">:</span> <span class="n">ModelGradients</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="k">if</span> <span class="n">gradients</span> <span class="o">==</span> <span class="n">_directStepOptimizerSingleton</span><span class="p">:</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">opt</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_optimizers</span><span class="p">):</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>            <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>        <span class="c1"># TODO(sven): Not supported for multiple optimizers yet.</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_optimizers</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>        <span class="k">for</span> <span class="n">g</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()):</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>            <span class="k">if</span> <span class="n">g</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>                <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">g</span><span class="p">):</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>                    <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>                <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>                    <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">g</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_optimizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.torch_policy.TorchPolicy.compute_actions">
<code class="highlight language-python"><span class="n">compute_actions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs_batch</span><span class="p">,</span> <span class="n">state_batches</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prev_action_batch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prev_reward_batch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">info_batch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">episodes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">explore</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">timestep</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Computes actions for the current policy.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>obs_batch</code></td>
        <td><code>Union[List[Union[Any, dict, tuple]], Any, dict, tuple]</code></td>
        <td><p>Batch of observations.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>state_batches</code></td>
        <td><code>Optional[List[Any]]</code></td>
        <td><p>List of RNN state input batches, if any.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>prev_action_batch</code></td>
        <td><code>Union[List[Union[Any, dict, tuple]], Any, dict, tuple]</code></td>
        <td><p>Batch of previous action values.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>prev_reward_batch</code></td>
        <td><code>Union[List[Union[Any, dict, tuple]], Any, dict, tuple]</code></td>
        <td><p>Batch of previous rewards.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>info_batch</code></td>
        <td><code>Optional[Dict[str, list]]</code></td>
        <td><p>Batch of info objects.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>episodes</code></td>
        <td><code>Optional[List[Episode]]</code></td>
        <td><p>List of Episode objects, one for each obs in
obs_batch. This provides access to all of the internal
episode state, which may be useful for model-based or
multi-agent algorithms.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>explore</code></td>
        <td><code>Optional[bool]</code></td>
        <td><p>Whether to pick an exploitation or exploration action.
Set to None (default) for using the value of
<code>self.config["explore"]</code>.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>timestep</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>The current (sampling) time step.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>actions (TensorType)</code></td>
      <td><p>Batch of output actions, with shape like
    [BATCH_SIZE, ACTION_SHAPE].
state_outs (List[TensorType]): List of RNN state output
    batches, if any, each with shape [BATCH_SIZE, STATE_SIZE].
info (List[dict]): Dictionary of extra feature batches, if any,
    with shape like
    {"f1": [BATCH_SIZE, ...], "f2": [BATCH_SIZE, ...]}.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/torch_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="k">def</span> <span class="nf">compute_actions</span><span class="p">(</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>        <span class="n">obs_batch</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorStructType</span><span class="p">],</span> <span class="n">TensorStructType</span><span class="p">],</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>        <span class="n">state_batches</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>        <span class="n">prev_action_batch</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorStructType</span><span class="p">],</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>                                 <span class="n">TensorStructType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>        <span class="n">prev_reward_batch</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorStructType</span><span class="p">],</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>                                 <span class="n">TensorStructType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>        <span class="n">info_batch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>        <span class="n">episodes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="s2">&quot;Episode&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>        <span class="n">explore</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>        <span class="n">timestep</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>        <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> \
<a id="__codelineno-0-16" name="__codelineno-0-16"></a>        <span class="n">Tuple</span><span class="p">[</span><span class="n">TensorStructType</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]]:</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a>    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a>        <span class="n">seq_lens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">obs_batch</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a>        <span class="n">input_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lazy_tensor_dict</span><span class="p">({</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a>            <span class="n">SampleBatch</span><span class="o">.</span><span class="n">CUR_OBS</span><span class="p">:</span> <span class="n">obs_batch</span><span class="p">,</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a>            <span class="s2">&quot;is_training&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a>        <span class="p">})</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a>        <span class="k">if</span> <span class="n">prev_action_batch</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a>            <span class="n">input_dict</span><span class="p">[</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">PREV_ACTIONS</span><span class="p">]</span> <span class="o">=</span> \
<a id="__codelineno-0-26" name="__codelineno-0-26"></a>                <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">prev_action_batch</span><span class="p">)</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a>        <span class="k">if</span> <span class="n">prev_reward_batch</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a>            <span class="n">input_dict</span><span class="p">[</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">PREV_REWARDS</span><span class="p">]</span> <span class="o">=</span> \
<a id="__codelineno-0-29" name="__codelineno-0-29"></a>                <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">prev_reward_batch</span><span class="p">)</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a>        <span class="n">state_batches</span> <span class="o">=</span> <span class="p">[</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a>            <span class="n">convert_to_torch_tensor</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a>            <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="p">(</span><span class="n">state_batches</span> <span class="ow">or</span> <span class="p">[])</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a>        <span class="p">]</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_action_helper</span><span class="p">(</span><span class="n">input_dict</span><span class="p">,</span> <span class="n">state_batches</span><span class="p">,</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a>                                           <span class="n">seq_lens</span><span class="p">,</span> <span class="n">explore</span><span class="p">,</span> <span class="n">timestep</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.torch_policy.TorchPolicy.compute_actions_from_input_dict">
<code class="highlight language-python"><span class="n">compute_actions_from_input_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dict</span><span class="p">,</span> <span class="n">explore</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">timestep</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Computes actions from collected samples (across multiple-agents).</p>
<p>Takes an input dict (usually a SampleBatch) as its main data input.
This allows for using this method in case a more complex input pattern
(view requirements) is needed, for example when the Model requires the
last n observations, the last m actions/rewards, or a combination
of any of these.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>input_dict</code></td>
        <td><code>Dict[str, Any]</code></td>
        <td><p>A SampleBatch or input dict containing the Tensors
to compute actions. <code>input_dict</code> already abides to the
Policy's as well as the Model's view requirements and can
thus be passed to the Model as-is.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>explore</code></td>
        <td><code>bool</code></td>
        <td><p>Whether to pick an exploitation or exploration
action (default: None -&gt; use self.config["explore"]).</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>timestep</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>The current (sampling) time step.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>episodes</code></td>
        <td></td>
        <td><p>This provides access to all of the internal episodes'
state, which may be useful for model-based or multi-agent
algorithms.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>actions</code></td>
      <td><p>Batch of output actions, with shape like
    [BATCH_SIZE, ACTION_SHAPE].
state_outs: List of RNN state output
    batches, if any, each with shape [BATCH_SIZE, STATE_SIZE].
info: Dictionary of extra feature batches, if any, with shape like
    {"f1": [BATCH_SIZE, ...], "f2": [BATCH_SIZE, ...]}.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/torch_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">compute_actions_from_input_dict</span><span class="p">(</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>        <span class="n">input_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">],</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>        <span class="n">explore</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>        <span class="n">timestep</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>        <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> \
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>        <span class="n">Tuple</span><span class="p">[</span><span class="n">TensorType</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]]:</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>        <span class="c1"># Pass lazy (torch) tensor dict to Model as `input_dict`.</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>        <span class="n">input_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lazy_tensor_dict</span><span class="p">(</span><span class="n">input_dict</span><span class="p">)</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>        <span class="n">input_dict</span><span class="o">.</span><span class="n">set_training</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>        <span class="c1"># Pack internal state inputs into (separate) list.</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>        <span class="n">state_batches</span> <span class="o">=</span> <span class="p">[</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a>            <span class="n">input_dict</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">input_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">if</span> <span class="s2">&quot;state_in&quot;</span> <span class="ow">in</span> <span class="n">k</span><span class="p">[:</span><span class="mi">8</span><span class="p">]</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>        <span class="p">]</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a>        <span class="c1"># Calculate RNN sequence lengths.</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a>        <span class="n">seq_lens</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_dict</span><span class="p">[</span><span class="s2">&quot;obs&quot;</span><span class="p">]))</span> \
<a id="__codelineno-0-20" name="__codelineno-0-20"></a>            <span class="k">if</span> <span class="n">state_batches</span> <span class="k">else</span> <span class="kc">None</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_action_helper</span><span class="p">(</span><span class="n">input_dict</span><span class="p">,</span> <span class="n">state_batches</span><span class="p">,</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a>                                           <span class="n">seq_lens</span><span class="p">,</span> <span class="n">explore</span><span class="p">,</span> <span class="n">timestep</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>





  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.torch_policy.TorchPolicy.export_checkpoint">
<code class="highlight language-python"><span class="n">export_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">export_dir</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Export Policy checkpoint to local directory.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>export_dir</code></td>
        <td><code>str</code></td>
        <td><p>Local writable directory.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/torch_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">export_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">export_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.torch_policy.TorchPolicy.export_model">
<code class="highlight language-python"><span class="n">export_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">export_dir</span><span class="p">,</span> <span class="n">onnx</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Exports the Policy's Model to local directory for serving.</p>
<p>Creates a TorchScript model and saves it.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>export_dir</code></td>
        <td><code>str</code></td>
        <td><p>Local writable directory or filename.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>onnx</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>If given, will export model in ONNX format. The
value of this parameter set the ONNX OpSet version to use.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/torch_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="k">def</span> <span class="nf">export_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">export_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>                 <span class="n">onnx</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>    <span class="sd">&quot;&quot;&quot;Exports the Policy&#39;s Model to local directory for serving.</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="sd">    Creates a TorchScript model and saves it.</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="sd">        export_dir: Local writable directory or filename.</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="sd">        onnx: If given, will export model in ONNX format. The</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="sd">            value of this parameter set the ONNX OpSet version to use.</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_lazy_tensor_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dummy_batch</span><span class="p">)</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>    <span class="c1"># Provide dummy state inputs if not an RNN (torch cannot jit with</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a>    <span class="c1"># returned empty internal states list).</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>    <span class="k">if</span> <span class="s2">&quot;state_in_0&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dummy_batch</span><span class="p">:</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_dummy_batch</span><span class="p">[</span><span class="s2">&quot;state_in_0&quot;</span><span class="p">]</span> <span class="o">=</span> \
<a id="__codelineno-0-19" name="__codelineno-0-19"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_dummy_batch</span><span class="p">[</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">SEQ_LENS</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">])</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a>    <span class="n">state_ins</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a>    <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a>    <span class="k">while</span> <span class="s2">&quot;state_in_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dummy_batch</span><span class="p">:</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a>        <span class="n">state_ins</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dummy_batch</span><span class="p">[</span><span class="s2">&quot;state_in_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)])</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a>        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a>    <span class="n">dummy_inputs</span> <span class="o">=</span> <span class="p">{</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a>        <span class="n">k</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dummy_batch</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a>        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dummy_batch</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="s2">&quot;is_training&quot;</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a>    <span class="p">}</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">export_dir</span><span class="p">):</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a>        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">export_dir</span><span class="p">)</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a>    <span class="n">seq_lens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dummy_batch</span><span class="p">[</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">SEQ_LENS</span><span class="p">]</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a>    <span class="k">if</span> <span class="n">onnx</span><span class="p">:</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a>        <span class="n">file_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">export_dir</span><span class="p">,</span> <span class="s2">&quot;model.onnx&quot;</span><span class="p">)</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a>        <span class="n">torch</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">export</span><span class="p">(</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="n">dummy_inputs</span><span class="p">,</span> <span class="n">state_ins</span><span class="p">,</span> <span class="n">seq_lens</span><span class="p">),</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>            <span class="n">file_name</span><span class="p">,</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a>            <span class="n">export_params</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a>            <span class="n">opset_version</span><span class="o">=</span><span class="n">onnx</span><span class="p">,</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a>            <span class="n">do_constant_folding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a>            <span class="n">input_names</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">dummy_inputs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">+</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>            <span class="p">[</span><span class="s2">&quot;state_ins&quot;</span><span class="p">,</span> <span class="n">SampleBatch</span><span class="o">.</span><span class="n">SEQ_LENS</span><span class="p">],</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a>            <span class="n">output_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;output&quot;</span><span class="p">,</span> <span class="s2">&quot;state_outs&quot;</span><span class="p">],</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>            <span class="n">dynamic_axes</span><span class="o">=</span><span class="p">{</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a>                <span class="n">k</span><span class="p">:</span> <span class="p">{</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a>                    <span class="mi">0</span><span class="p">:</span> <span class="s2">&quot;batch_size&quot;</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a>                <span class="p">}</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a>                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">dummy_inputs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">+</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a>                <span class="p">[</span><span class="s2">&quot;state_ins&quot;</span><span class="p">,</span> <span class="n">SampleBatch</span><span class="o">.</span><span class="n">SEQ_LENS</span><span class="p">]</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a>            <span class="p">})</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a>        <span class="n">traced</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a>                                 <span class="p">(</span><span class="n">dummy_inputs</span><span class="p">,</span> <span class="n">state_ins</span><span class="p">,</span> <span class="n">seq_lens</span><span class="p">))</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a>        <span class="n">file_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">export_dir</span><span class="p">,</span> <span class="s2">&quot;model.pt&quot;</span><span class="p">)</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a>        <span class="n">traced</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">file_name</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.torch_policy.TorchPolicy.extra_action_out">
<code class="highlight language-python"><span class="n">extra_action_out</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dict</span><span class="p">,</span> <span class="n">state_batches</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">action_dist</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Returns dict of extra info to include in experience batch.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>input_dict</code></td>
        <td><code>Dict[str, Any]</code></td>
        <td><p>Dict of model input tensors.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>state_batches</code></td>
        <td><code>List[Any]</code></td>
        <td><p>List of state tensors.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>model</code></td>
        <td><code>TorchModelV2</code></td>
        <td><p>Reference to the model object.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>action_dist</code></td>
        <td><code>TorchDistributionWrapper</code></td>
        <td><p>Torch action dist object
to get log-probs (e.g. for already sampled actions).</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Dict[str, Any]</code></td>
      <td><p>Extra outputs to return in a <code>compute_actions_from_input_dict()</code>
call (3rd return value).</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/torch_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">extra_action_out</span><span class="p">(</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">input_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">],</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>        <span class="n">state_batches</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">],</span> <span class="n">model</span><span class="p">:</span> <span class="n">TorchModelV2</span><span class="p">,</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>        <span class="n">action_dist</span><span class="p">:</span> <span class="n">TorchDistributionWrapper</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]:</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>    <span class="sd">&quot;&quot;&quot;Returns dict of extra info to include in experience batch.</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="sd">        input_dict: Dict of model input tensors.</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="sd">        state_batches: List of state tensors.</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="sd">        model: Reference to the model object.</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="sd">        action_dist: Torch action dist object</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a><span class="sd">            to get log-probs (e.g. for already sampled actions).</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a><span class="sd">        Extra outputs to return in a `compute_actions_from_input_dict()`</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a><span class="sd">        call (3rd return value).</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a>    <span class="k">return</span> <span class="p">{}</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.torch_policy.TorchPolicy.extra_compute_grad_fetches">
<code class="highlight language-python"><span class="n">extra_compute_grad_fetches</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Extra values to fetch and return from compute_gradients().</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Dict[str, Any]</code></td>
      <td><p>Extra fetch dict to be added to the fetch dict of the
<code>compute_gradients</code> call.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/torch_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">extra_compute_grad_fetches</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="sd">&quot;&quot;&quot;Extra values to fetch and return from compute_gradients().</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="sd">        Extra fetch dict to be added to the fetch dict of the</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="sd">        `compute_gradients` call.</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>    <span class="k">return</span> <span class="p">{</span><span class="n">LEARNER_STATS_KEY</span><span class="p">:</span> <span class="p">{}}</span>  <span class="c1"># e.g, stats, td error, etc.</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.torch_policy.TorchPolicy.extra_grad_info">
<code class="highlight language-python"><span class="n">extra_grad_info</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_batch</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Return dict of extra grad info.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>train_batch</code></td>
        <td><code>SampleBatch</code></td>
        <td><p>The training batch for which to produce
extra grad info for.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Dict[str, Any]</code></td>
      <td><p>The info dict carrying grad info per str key.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/torch_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">extra_grad_info</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>                    <span class="n">train_batch</span><span class="p">:</span> <span class="n">SampleBatch</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]:</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="sd">&quot;&quot;&quot;Return dict of extra grad info.</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="sd">        train_batch: The training batch for which to produce</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="sd">            extra grad info for.</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="sd">        The info dict carrying grad info per str key.</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>    <span class="k">return</span> <span class="p">{}</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.torch_policy.TorchPolicy.extra_grad_process">
<code class="highlight language-python"><span class="n">extra_grad_process</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Called after each optimizer.zero_grad() + loss.backward() call.</p>
<p>Called for each self._optimizers/loss-value pair.
Allows for gradient processing before optimizer.step() is called.
E.g. for gradient clipping.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>optimizer</code></td>
        <td><code>torch.optim.Optimizer</code></td>
        <td><p>A torch optimizer object.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>loss</code></td>
        <td><code>Any</code></td>
        <td><p>The loss tensor associated with the optimizer.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Dict[str, Any]</code></td>
      <td><p>An dict with information on the gradient processing step.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/torch_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">extra_grad_process</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">:</span> <span class="s2">&quot;torch.optim.Optimizer&quot;</span><span class="p">,</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>                       <span class="n">loss</span><span class="p">:</span> <span class="n">TensorType</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]:</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="sd">&quot;&quot;&quot;Called after each optimizer.zero_grad() + loss.backward() call.</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="sd">    Called for each self._optimizers/loss-value pair.</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="sd">    Allows for gradient processing before optimizer.step() is called.</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="sd">    E.g. for gradient clipping.</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="sd">        optimizer: A torch optimizer object.</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="sd">        loss: The loss tensor associated with the optimizer.</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a><span class="sd">        An dict with information on the gradient processing step.</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>    <span class="k">return</span> <span class="p">{}</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.torch_policy.TorchPolicy.get_initial_state">
<code class="highlight language-python"><span class="n">get_initial_state</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Returns initial RNN state for the current policy.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>List[TensorType]</code></td>
      <td><p>Initial RNN state for the current policy.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/torch_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="k">def</span> <span class="nf">get_initial_state</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]:</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="k">return</span> <span class="p">[</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>        <span class="n">s</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_initial_state</span><span class="p">()</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>    <span class="p">]</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.torch_policy.TorchPolicy.get_num_samples_loaded_into_buffer">
<code class="highlight language-python"><span class="n">get_num_samples_loaded_into_buffer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">buffer_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Returns the number of currently loaded samples in the given buffer.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>buffer_index</code></td>
        <td><code>int</code></td>
        <td><p>The index of the buffer (a MultiGPUTowerStack)
to use on the devices. The number of buffers on each device
depends on the value of the <code>num_multi_gpu_tower_stacks</code> config
key.</p></td>
        <td><code>0</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>int</code></td>
      <td><p>The number of tuples loaded per device.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/torch_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="k">def</span> <span class="nf">get_num_samples_loaded_into_buffer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">buffer_index</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">devices</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">devices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;/cpu:0&quot;</span><span class="p">:</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>        <span class="k">assert</span> <span class="n">buffer_index</span> <span class="o">==</span> <span class="mi">0</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_loaded_batches</span><span class="p">[</span><span class="n">buffer_index</span><span class="p">])</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.torch_policy.TorchPolicy.get_state">
<code class="highlight language-python"><span class="n">get_state</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Returns the entire current state of this Policy.</p>
<p>Note: Not to be confused with an RNN model's internal state.
State includes the Model(s)' weights, optimizer weights,
the exploration component's state, as well as global variables, such
as sampling timesteps.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Union[Dict[str, Any], List[Any]]</code></td>
      <td><p>Serialized local state.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/torch_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="k">def</span> <span class="nf">get_state</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]]:</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="n">state</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_state</span><span class="p">()</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>    <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_optimizer_variables&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">o</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_optimizers</span><span class="p">):</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>        <span class="n">optim_state_dict</span> <span class="o">=</span> <span class="n">convert_to_numpy</span><span class="p">(</span><span class="n">o</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>        <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_optimizer_variables&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">optim_state_dict</span><span class="p">)</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>    <span class="c1"># Add exploration state.</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>    <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_exploration_state&quot;</span><span class="p">]</span> <span class="o">=</span> \
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">exploration</span><span class="o">.</span><span class="n">get_state</span><span class="p">()</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>    <span class="k">return</span> <span class="n">state</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.torch_policy.TorchPolicy.get_tower_stats">
<code class="highlight language-python"><span class="n">get_tower_stats</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stats_name</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Returns list of per-tower stats, copied to this Policy's device.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>stats_name</code></td>
        <td><code>str</code></td>
        <td><p>The name of the stats to average over (this str
must exist as a key inside each tower's <code>tower_stats</code> dict).</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>List[Union[Any, dict, tuple]]</code></td>
      <td><p>The list of stats tensor (structs) of all towers, copied to this
Policy's device.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>AssertionError</code></td>
        <td><p>If the <code>stats_name</code> cannot be found in any one</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/torch_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">get_tower_stats</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stats_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorStructType</span><span class="p">]:</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="sd">&quot;&quot;&quot;Returns list of per-tower stats, copied to this Policy&#39;s device.</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="sd">        stats_name: The name of the stats to average over (this str</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="sd">            must exist as a key inside each tower&#39;s `tower_stats` dict).</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="sd">        The list of stats tensor (structs) of all towers, copied to this</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="sd">        Policy&#39;s device.</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a><span class="sd">    Raises:</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a><span class="sd">        AssertionError: If the `stats_name` cannot be found in any one</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a><span class="sd">        of the tower&#39;s `tower_stats` dicts.</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>    <span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a>    <span class="k">for</span> <span class="n">tower</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_gpu_towers</span><span class="p">:</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a>        <span class="k">if</span> <span class="n">stats_name</span> <span class="ow">in</span> <span class="n">tower</span><span class="o">.</span><span class="n">tower_stats</span><span class="p">:</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a>            <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a>                <span class="n">tree</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="n">s</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a>                                   <span class="n">tower</span><span class="o">.</span><span class="n">tower_stats</span><span class="p">[</span><span class="n">stats_name</span><span class="p">]))</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a>    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> \
<a id="__codelineno-0-24" name="__codelineno-0-24"></a>        <span class="sa">f</span><span class="s2">&quot;Stats `</span><span class="si">{</span><span class="n">stats_name</span><span class="si">}</span><span class="s2">` not found in any of the towers (you have &quot;</span> \
<a id="__codelineno-0-25" name="__codelineno-0-25"></a>        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_gpu_towers</span><span class="p">)</span><span class="si">}</span><span class="s2"> towers in total)! Make &quot;</span> \
<a id="__codelineno-0-26" name="__codelineno-0-26"></a>        <span class="s2">&quot;sure you call the loss function on at least one of the towers.&quot;</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a>    <span class="k">return</span> <span class="n">data</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.torch_policy.TorchPolicy.get_weights">
<code class="highlight language-python"><span class="n">get_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Returns model weights.</p>
<p>Note: The return value of this method will reside under the "weights"
key in the return value of Policy.get_state(). Model weights are only
one part of a Policy's state. Other state information contains:
optimizer variables, exploration state, and global state vars such as
the sampling timestep.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>dict</code></td>
      <td><p>Serializable copy or view of model weights.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/torch_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="k">def</span> <span class="nf">get_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModelWeights</span><span class="p">:</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="k">return</span> <span class="p">{</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>        <span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>    <span class="p">}</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.torch_policy.TorchPolicy.import_model_from_h5">
<code class="highlight language-python"><span class="n">import_model_from_h5</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">import_file</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Imports weights into torch model.</p>

        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/torch_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="k">def</span> <span class="nf">import_model_from_h5</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">import_file</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="sd">&quot;&quot;&quot;Imports weights into torch model.&quot;&quot;&quot;</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">import_from_h5</span><span class="p">(</span><span class="n">import_file</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.torch_policy.TorchPolicy.is_recurrent">
<code class="highlight language-python"><span class="n">is_recurrent</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Whether this Policy holds a recurrent Model.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>bool</code></td>
      <td><p>True if this Policy has-a RNN-based Model.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/torch_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="k">def</span> <span class="nf">is_recurrent</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_recurrent</span>
</code></pre></div>
        </details>
    </div>

  </div>




  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.torch_policy.TorchPolicy.learn_on_loaded_batch">
<code class="highlight language-python"><span class="n">learn_on_loaded_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">buffer_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Runs a single step of SGD on an already loaded data in a buffer.</p>
<p>Runs an SGD step over a slice of the pre-loaded batch, offset by
the <code>offset</code> argument (useful for performing n minibatch SGD
updates repeatedly on the same, already pre-loaded data).</p>
<p>Updates the model weights based on the averaged per-device gradients.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>offset</code></td>
        <td><code>int</code></td>
        <td><p>Offset into the preloaded data. Used for pre-loading
a train-batch once to a device, then iterating over
(subsampling through) this batch n times doing minibatch SGD.</p></td>
        <td><code>0</code></td>
      </tr>
      <tr>
        <td><code>buffer_index</code></td>
        <td><code>int</code></td>
        <td><p>The index of the buffer (a MultiGPUTowerStack)
to take the already pre-loaded data from. The number of buffers
on each device depends on the value of the
<code>num_multi_gpu_tower_stacks</code> config key.</p></td>
        <td><code>0</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td></td>
      <td><p>The outputs of extra_ops evaluated over the batch.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/torch_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="k">def</span> <span class="nf">learn_on_loaded_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">offset</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">buffer_index</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">):</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loaded_batches</span><span class="p">[</span><span class="n">buffer_index</span><span class="p">]:</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>            <span class="s2">&quot;Must call Policy.load_batch_into_buffer() before &quot;</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>            <span class="s2">&quot;Policy.learn_on_loaded_batch()!&quot;</span><span class="p">)</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>    <span class="c1"># Get the correct slice of the already loaded batch to use,</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>    <span class="c1"># based on offset and batch size.</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>    <span class="n">device_batch_size</span> <span class="o">=</span> \
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>            <span class="s2">&quot;sgd_minibatch_size&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;train_batch_size&quot;</span><span class="p">])</span> <span class="o">//</span> \
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>        <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">devices</span><span class="p">)</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a>    <span class="c1"># Set Model to train mode.</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_gpu_towers</span><span class="p">:</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a>        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_gpu_towers</span><span class="p">:</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a>            <span class="n">t</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a>    <span class="c1"># Shortcut for 1 CPU only: Batch should already be stored in</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a>    <span class="c1"># `self._loaded_batches`.</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">devices</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">devices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cpu&quot;</span><span class="p">:</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a>        <span class="k">assert</span> <span class="n">buffer_index</span> <span class="o">==</span> <span class="mi">0</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a>        <span class="k">if</span> <span class="n">device_batch_size</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_loaded_batches</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]):</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a>            <span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loaded_batches</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a>            <span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loaded_batches</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="n">offset</span><span class="p">:</span><span class="n">offset</span> <span class="o">+</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a>                                               <span class="n">device_batch_size</span><span class="p">]</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">learn_on_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">devices</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a>        <span class="c1"># Copy weights of main model (tower-0) to all other towers.</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a>        <span class="n">state_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a>        <span class="c1"># Just making sure tower-0 is really the same as self.model.</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_gpu_towers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a>        <span class="k">for</span> <span class="n">tower</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_gpu_towers</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a>            <span class="n">tower</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a>    <span class="k">if</span> <span class="n">device_batch_size</span> <span class="o">&gt;=</span> <span class="nb">sum</span><span class="p">(</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a>            <span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loaded_batches</span><span class="p">[</span><span class="n">buffer_index</span><span class="p">]):</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a>        <span class="n">device_batches</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loaded_batches</span><span class="p">[</span><span class="n">buffer_index</span><span class="p">]</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>        <span class="n">device_batches</span> <span class="o">=</span> <span class="p">[</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a>            <span class="n">b</span><span class="p">[</span><span class="n">offset</span><span class="p">:</span><span class="n">offset</span> <span class="o">+</span> <span class="n">device_batch_size</span><span class="p">]</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>            <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loaded_batches</span><span class="p">[</span><span class="n">buffer_index</span><span class="p">]</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a>        <span class="p">]</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a>    <span class="c1"># Do the (maybe parallelized) gradient calculation step.</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a>    <span class="n">tower_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_multi_gpu_parallel_grad_calc</span><span class="p">(</span><span class="n">device_batches</span><span class="p">)</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a>    <span class="c1"># Mean-reduce gradients over GPU-towers (do this on CPU: self.device).</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a>    <span class="n">all_grads</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tower_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])):</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a>        <span class="k">if</span> <span class="n">tower_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a>            <span class="n">all_grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a>                <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a>                    <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a>                        <span class="p">[</span><span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tower_outputs</span><span class="p">]),</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a>                    <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a>        <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a>            <span class="n">all_grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a>    <span class="c1"># Set main model&#39;s grads to mean-reduced values.</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a>    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()):</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a>        <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="n">all_grads</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">_directStepOptimizerSingleton</span><span class="p">)</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>    <span class="n">batch_fetches</span> <span class="o">=</span> <span class="p">{}</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a>    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">device_batches</span><span class="p">):</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a>        <span class="n">batch_fetches</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;tower_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a>            <span class="n">LEARNER_STATS_KEY</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">extra_grad_info</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>        <span class="p">}</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a>    <span class="n">batch_fetches</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">extra_compute_grad_fetches</span><span class="p">())</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a>    <span class="k">return</span> <span class="n">batch_fetches</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.torch_policy.TorchPolicy.load_batch_into_buffer">
<code class="highlight language-python"><span class="n">load_batch_into_buffer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">buffer_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Bulk-loads the given SampleBatch into the devices' memories.</p>
<p>The data is split equally across all the Policy's devices.
If the data is not evenly divisible by the batch size, excess data
should be discarded.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>batch</code></td>
        <td><code>SampleBatch</code></td>
        <td><p>The SampleBatch to load.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>buffer_index</code></td>
        <td><code>int</code></td>
        <td><p>The index of the buffer (a MultiGPUTowerStack) to use
on the devices. The number of buffers on each device depends
on the value of the <code>num_multi_gpu_tower_stacks</code> config key.</p></td>
        <td><code>0</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>int</code></td>
      <td><p>The number of tuples loaded per device.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/torch_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="k">def</span> <span class="nf">load_batch_into_buffer</span><span class="p">(</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>        <span class="n">batch</span><span class="p">:</span> <span class="n">SampleBatch</span><span class="p">,</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>        <span class="n">buffer_index</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>    <span class="c1"># Set the is_training flag of the batch.</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>    <span class="n">batch</span><span class="o">.</span><span class="n">set_training</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>    <span class="c1"># Shortcut for 1 CPU only: Store batch in `self._loaded_batches`.</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">devices</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">devices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cpu&quot;</span><span class="p">:</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>        <span class="k">assert</span> <span class="n">buffer_index</span> <span class="o">==</span> <span class="mi">0</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>        <span class="n">pad_batch_to_sequences_of_same_size</span><span class="p">(</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>            <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a>            <span class="n">max_seq_len</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_seq_len</span><span class="p">,</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>            <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a>            <span class="n">batch_divisibility_req</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_divisibility_req</span><span class="p">,</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a>            <span class="n">view_requirements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">view_requirements</span><span class="p">,</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a>        <span class="p">)</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_lazy_tensor_dict</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_loaded_batches</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">batch</span><span class="p">]</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a>        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a>    <span class="c1"># Batch (len=28, seq-lens=[4, 7, 4, 10, 3]):</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a>    <span class="c1"># 0123 0123456 0123 0123456789ABC</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a>    <span class="c1"># 1) split into n per-GPU sub batches (n=2).</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a>    <span class="c1"># [0123 0123456] [012] [3 0123456789 ABC]</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a>    <span class="c1"># (len=14, 14 seq-lens=[4, 7, 3] [1, 10, 3])</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a>    <span class="n">slices</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">timeslices</span><span class="p">(</span><span class="n">num_slices</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">devices</span><span class="p">))</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a>    <span class="c1"># 2) zero-padding (max-seq-len=10).</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a>    <span class="c1"># - [0123000000 0123456000 0120000000]</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a>    <span class="c1"># - [3000000000 0123456789 ABC0000000]</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a>    <span class="k">for</span> <span class="nb">slice</span> <span class="ow">in</span> <span class="n">slices</span><span class="p">:</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a>        <span class="n">pad_batch_to_sequences_of_same_size</span><span class="p">(</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a>            <span class="n">batch</span><span class="o">=</span><span class="nb">slice</span><span class="p">,</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>            <span class="n">max_seq_len</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_seq_len</span><span class="p">,</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a>            <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a>            <span class="n">batch_divisibility_req</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_divisibility_req</span><span class="p">,</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a>            <span class="n">view_requirements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">view_requirements</span><span class="p">,</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a>        <span class="p">)</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a>    <span class="c1"># 3) Load splits into the given buffer (consisting of n GPUs).</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>    <span class="n">slices</span> <span class="o">=</span> <span class="p">[</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a>        <span class="nb">slice</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">devices</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="nb">slice</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">slices</span><span class="p">)</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a>    <span class="p">]</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_loaded_batches</span><span class="p">[</span><span class="n">buffer_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">slices</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a>    <span class="c1"># Return loaded samples per-device.</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a>    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">slices</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.torch_policy.TorchPolicy.num_state_tensors">
<code class="highlight language-python"><span class="n">num_state_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>The number of internal states needed by the RNN-Model of the Policy.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>int</code></td>
      <td><p>The number of RNN internal states kept by this Policy's Model.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/torch_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="k">def</span> <span class="nf">num_state_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_initial_state</span><span class="p">())</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.torch_policy.TorchPolicy.optimizer">
<code class="highlight language-python"><span class="n">optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Custom the local PyTorch optimizer(s) to use.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Union[List[torch.optim.Optimizer], torch.optim.Optimizer]</code></td>
      <td><p>The local PyTorch optimizer(s) to use for this Policy.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/torch_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">optimizer</span><span class="p">(</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>        <span class="bp">self</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="s2">&quot;torch.optim.Optimizer&quot;</span><span class="p">],</span> <span class="s2">&quot;torch.optim.Optimizer&quot;</span><span class="p">]:</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>    <span class="sd">&quot;&quot;&quot;Custom the local PyTorch optimizer(s) to use.</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="sd">        The local PyTorch optimizer(s) to use for this Policy.</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;config&quot;</span><span class="p">):</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>        <span class="n">optimizers</span> <span class="o">=</span> <span class="p">[</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>            <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">])</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>        <span class="p">]</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a>        <span class="n">optimizers</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())]</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>    <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;exploration&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">):</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a>        <span class="n">optimizers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exploration</span><span class="o">.</span><span class="n">get_exploration_optimizer</span><span class="p">(</span><span class="n">optimizers</span><span class="p">)</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a>    <span class="k">return</span> <span class="n">optimizers</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.torch_policy.TorchPolicy.set_state">
<code class="highlight language-python"><span class="n">set_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Restores the entire current state of this Policy from <code>state</code>.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>state</code></td>
        <td><code>dict</code></td>
        <td><p>The new state to set this policy to. Can be
obtained by calling <code>self.get_state()</code>.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/torch_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="k">def</span> <span class="nf">set_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="c1"># Set optimizer vars first.</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>    <span class="n">optimizer_vars</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_optimizer_variables&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>    <span class="k">if</span> <span class="n">optimizer_vars</span><span class="p">:</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">optimizer_vars</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_optimizers</span><span class="p">)</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>        <span class="k">for</span> <span class="n">o</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_optimizers</span><span class="p">,</span> <span class="n">optimizer_vars</span><span class="p">):</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>            <span class="n">optim_state_dict</span> <span class="o">=</span> <span class="n">convert_to_torch_tensor</span><span class="p">(</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>                <span class="n">s</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>            <span class="n">o</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">optim_state_dict</span><span class="p">)</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>    <span class="c1"># Set exploration&#39;s state.</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;exploration&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="s2">&quot;_exploration_state&quot;</span> <span class="ow">in</span> <span class="n">state</span><span class="p">:</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">exploration</span><span class="o">.</span><span class="n">set_state</span><span class="p">(</span><span class="n">state</span><span class="o">=</span><span class="n">state</span><span class="p">[</span><span class="s2">&quot;_exploration_state&quot;</span><span class="p">])</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>    <span class="c1"># Then the Policy&#39;s (NN) weights.</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">set_state</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.torch_policy.TorchPolicy.set_weights">
<code class="highlight language-python"><span class="n">set_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Sets this Policy's model's weights.</p>
<p>Note: Model weights are only one part of a Policy's state. Other
state information contains: optimizer variables, exploration state,
and global state vars such as the sampling timestep.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>weights</code></td>
        <td><code>dict</code></td>
        <td><p>Serializable copy or view of model weights.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/torch_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="k">def</span> <span class="nf">set_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">:</span> <span class="n">ModelWeights</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="n">weights</span> <span class="o">=</span> <span class="n">convert_to_torch_tensor</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>



  <div class="doc doc-object doc-class">



<h2 class="doc doc-heading" id="ray.rllib.policy.tf_policy.TFPolicy">
        <code>
ray.rllib.policy.tf_policy.TFPolicy            (<a title="ray.rllib.policy.policy.Policy" href="#ray.rllib.policy.policy.Policy">Policy</a>)
        </code>



</h2>

    <div class="doc doc-contents first">

      <p>An agent policy and loss implemented in TensorFlow.</p>
<p>Do not sub-class this class directly (neither should you sub-class
DynamicTFPolicy), but rather use
rllib.policy.tf_policy_template.build_tf_policy
to generate your custom tf (graph-mode or eager) Policy classes.</p>
<p>Extending this class enables RLlib to perform TensorFlow specific
optimizations on the policy, e.g., parallelization across gpus or
fusing multiple graphs together in the multi-agent setting.</p>
<p>Input tensors are typically shaped like [BATCH_SIZE, ...].</p>

<p><strong>Examples:</strong></p>
    <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">policy</span> <span class="o">=</span> <span class="n">TFPolicySubclass</span><span class="p">(</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a>    <span class="n">sess</span><span class="p">,</span> <span class="n">obs_input</span><span class="p">,</span> <span class="n">sampled_action</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">loss_inputs</span><span class="p">)</span>
</code></pre></div>
    <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">policy</span><span class="o">.</span><span class="n">compute_actions</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]))</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="p">(</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="p">[],</span> <span class="p">{})</span>
</code></pre></div>
    <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">policy</span><span class="o">.</span><span class="n">postprocess_trajectory</span><span class="p">(</span><span class="n">SampleBatch</span><span class="p">({</span><span class="o">...</span><span class="p">})))</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="n">SampleBatch</span><span class="p">({</span><span class="s2">&quot;action&quot;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span> <span class="s2">&quot;advantages&quot;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span> <span class="o">...</span><span class="p">})</span>
</code></pre></div>




  <div class="doc doc-children">









  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.tf_policy.TFPolicy.__init__">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_space</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">sess</span><span class="p">,</span> <span class="n">obs_input</span><span class="p">,</span> <span class="n">sampled_action</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">loss_inputs</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sampled_action_logp</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">action_input</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">log_likelihood</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dist_inputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dist_class</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">state_inputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">state_outputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prev_action_input</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prev_reward_input</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">seq_lens</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_seq_len</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">batch_divisibility_req</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">update_ops</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">explore</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">timestep</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h3>

    <div class="doc doc-contents ">

      <p>Initializes a Policy object.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>observation_space</code></td>
        <td><code>Space</code></td>
        <td><p>Observation space of the policy.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>action_space</code></td>
        <td><code>Space</code></td>
        <td><p>Action space of the policy.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>config</code></td>
        <td><code>dict</code></td>
        <td><p>Policy-specific configuration data.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>sess</code></td>
        <td><code>tf1.Session</code></td>
        <td><p>The TensorFlow session to use.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>obs_input</code></td>
        <td><code>Any</code></td>
        <td><p>Input placeholder for observations, of shape
[BATCH_SIZE, obs...].</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>sampled_action</code></td>
        <td><code>Any</code></td>
        <td><p>Tensor for sampling an action, of shape
[BATCH_SIZE, action...]</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>loss</code></td>
        <td><code>Union[Any, List[Any]]</code></td>
        <td><p>Scalar policy loss output tensor or a list thereof
(in case there is more than one loss).</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>loss_inputs</code></td>
        <td><code>List[Tuple[str, Any]]</code></td>
        <td><p>A (name, placeholder) tuple for each loss input
argument. Each placeholder name must
correspond to a SampleBatch column key returned by
postprocess_trajectory(), and has shape [BATCH_SIZE, data...].
These keys will be read from postprocessed sample batches and
fed into the specified placeholders during loss computation.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>model</code></td>
        <td><code>Optional[ray.rllib.models.modelv2.ModelV2]</code></td>
        <td><p>The optional ModelV2 to use for calculating actions and
losses. If not None, TFPolicy will provide functionality for
getting variables, calling the model's custom loss (if
provided), and importing weights into the model.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>sampled_action_logp</code></td>
        <td><code>Optional[Any]</code></td>
        <td><p>log probability of the sampled action.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>action_input</code></td>
        <td><code>Optional[Any]</code></td>
        <td><p>Input placeholder for actions for
logp/log-likelihood calculations.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>log_likelihood</code></td>
        <td><code>Optional[Any]</code></td>
        <td><p>Tensor to calculate the log_likelihood (given
action_input and obs_input).</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>dist_class</code></td>
        <td><code>Optional[type]</code></td>
        <td><p>An optional ActionDistribution class to use for
generating a dist object from distribution inputs.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>dist_inputs</code></td>
        <td><code>Optional[Any]</code></td>
        <td><p>Tensor to calculate the distribution
inputs/parameters.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>state_inputs</code></td>
        <td><code>Optional[List[Any]]</code></td>
        <td><p>List of RNN state input Tensors.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>state_outputs</code></td>
        <td><code>Optional[List[Any]]</code></td>
        <td><p>List of RNN state output Tensors.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>prev_action_input</code></td>
        <td><code>Optional[Any]</code></td>
        <td><p>placeholder for previous actions.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>prev_reward_input</code></td>
        <td><code>Optional[Any]</code></td>
        <td><p>placeholder for previous rewards.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>seq_lens</code></td>
        <td><code>Optional[Any]</code></td>
        <td><p>Placeholder for RNN sequence lengths, of shape
[NUM_SEQUENCES].
Note that NUM_SEQUENCES &lt;&lt; BATCH_SIZE. See
policy/rnn_sequencing.py for more information.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>max_seq_len</code></td>
        <td><code>int</code></td>
        <td><p>Max sequence length for LSTM training.</p></td>
        <td><code>20</code></td>
      </tr>
      <tr>
        <td><code>batch_divisibility_req</code></td>
        <td><code>int</code></td>
        <td><p>pad all agent experiences batches to
multiples of this value. This only has an effect if not using
a LSTM model.</p></td>
        <td><code>1</code></td>
      </tr>
      <tr>
        <td><code>update_ops</code></td>
        <td><code>List[Any]</code></td>
        <td><p>override the batchnorm update ops
to run when applying gradients. Otherwise we run all update
ops found in the current variable scope.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>explore</code></td>
        <td><code>Optional[Any]</code></td>
        <td><p>Placeholder for <code>explore</code> parameter into call to
Exploration.get_exploration_action. Explicitly set this to
False for not creating any Exploration component.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>timestep</code></td>
        <td><code>Optional[Any]</code></td>
        <td><p>Placeholder for the global sampling timestep.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/tf_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>             <span class="n">observation_space</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>             <span class="n">action_space</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>             <span class="n">config</span><span class="p">:</span> <span class="n">TrainerConfigDict</span><span class="p">,</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>             <span class="n">sess</span><span class="p">:</span> <span class="s2">&quot;tf1.Session&quot;</span><span class="p">,</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>             <span class="n">obs_input</span><span class="p">:</span> <span class="n">TensorType</span><span class="p">,</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>             <span class="n">sampled_action</span><span class="p">:</span> <span class="n">TensorType</span><span class="p">,</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>             <span class="n">loss</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">TensorType</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]],</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>             <span class="n">loss_inputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]],</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>             <span class="n">model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ModelV2</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>             <span class="n">sampled_action_logp</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>             <span class="n">action_input</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>             <span class="n">log_likelihood</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>             <span class="n">dist_inputs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a>             <span class="n">dist_class</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">type</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>             <span class="n">state_inputs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a>             <span class="n">state_outputs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a>             <span class="n">prev_action_input</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a>             <span class="n">prev_reward_input</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a>             <span class="n">seq_lens</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a>             <span class="n">max_seq_len</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a>             <span class="n">batch_divisibility_req</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a>             <span class="n">update_ops</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a>             <span class="n">explore</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a>             <span class="n">timestep</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a>    <span class="sd">&quot;&quot;&quot;Initializes a Policy object.</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a><span class="sd">        observation_space: Observation space of the policy.</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a><span class="sd">        action_space: Action space of the policy.</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a><span class="sd">        config: Policy-specific configuration data.</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a><span class="sd">        sess: The TensorFlow session to use.</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a><span class="sd">        obs_input: Input placeholder for observations, of shape</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a><span class="sd">            [BATCH_SIZE, obs...].</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a><span class="sd">        sampled_action: Tensor for sampling an action, of shape</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a><span class="sd">            [BATCH_SIZE, action...]</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a><span class="sd">        loss: Scalar policy loss output tensor or a list thereof</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a><span class="sd">            (in case there is more than one loss).</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a><span class="sd">        loss_inputs: A (name, placeholder) tuple for each loss input</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a><span class="sd">            argument. Each placeholder name must</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a><span class="sd">            correspond to a SampleBatch column key returned by</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a><span class="sd">            postprocess_trajectory(), and has shape [BATCH_SIZE, data...].</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a><span class="sd">            These keys will be read from postprocessed sample batches and</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a><span class="sd">            fed into the specified placeholders during loss computation.</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a><span class="sd">        model: The optional ModelV2 to use for calculating actions and</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a><span class="sd">            losses. If not None, TFPolicy will provide functionality for</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a><span class="sd">            getting variables, calling the model&#39;s custom loss (if</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a><span class="sd">            provided), and importing weights into the model.</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a><span class="sd">        sampled_action_logp: log probability of the sampled action.</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a><span class="sd">        action_input: Input placeholder for actions for</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a><span class="sd">            logp/log-likelihood calculations.</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a><span class="sd">        log_likelihood: Tensor to calculate the log_likelihood (given</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a><span class="sd">            action_input and obs_input).</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a><span class="sd">        dist_class: An optional ActionDistribution class to use for</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a><span class="sd">            generating a dist object from distribution inputs.</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a><span class="sd">        dist_inputs: Tensor to calculate the distribution</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a><span class="sd">            inputs/parameters.</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a><span class="sd">        state_inputs: List of RNN state input Tensors.</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a><span class="sd">        state_outputs: List of RNN state output Tensors.</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a><span class="sd">        prev_action_input: placeholder for previous actions.</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a><span class="sd">        prev_reward_input: placeholder for previous rewards.</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a><span class="sd">        seq_lens: Placeholder for RNN sequence lengths, of shape</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a><span class="sd">            [NUM_SEQUENCES].</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a><span class="sd">            Note that NUM_SEQUENCES &lt;&lt; BATCH_SIZE. See</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a><span class="sd">            policy/rnn_sequencing.py for more information.</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a><span class="sd">        max_seq_len: Max sequence length for LSTM training.</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a><span class="sd">        batch_divisibility_req: pad all agent experiences batches to</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a><span class="sd">            multiples of this value. This only has an effect if not using</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a><span class="sd">            a LSTM model.</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a><span class="sd">        update_ops: override the batchnorm update ops</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a><span class="sd">            to run when applying gradients. Otherwise we run all update</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a><span class="sd">            ops found in the current variable scope.</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a><span class="sd">        explore: Placeholder for `explore` parameter into call to</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a><span class="sd">            Exploration.get_exploration_action. Explicitly set this to</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a><span class="sd">            False for not creating any Exploration component.</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a><span class="sd">        timestep: Placeholder for the global sampling timestep.</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">framework</span> <span class="o">=</span> <span class="s2">&quot;tf&quot;</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">observation_space</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a>    <span class="c1"># Get devices to build the graph on.</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a>    <span class="n">worker_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;worker_index&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;_fake_gpus&quot;</span><span class="p">]</span> <span class="ow">and</span> \
<a id="__codelineno-0-85" name="__codelineno-0-85"></a>            <span class="n">ray</span><span class="o">.</span><span class="n">worker</span><span class="o">.</span><span class="n">_mode</span><span class="p">()</span> <span class="o">==</span> <span class="n">ray</span><span class="o">.</span><span class="n">worker</span><span class="o">.</span><span class="n">LOCAL_MODE</span><span class="p">:</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a>        <span class="n">num_gpus</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a>    <span class="k">elif</span> <span class="n">worker_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a>        <span class="n">num_gpus</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;num_gpus&quot;</span><span class="p">]</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a>        <span class="n">num_gpus</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;num_gpus_per_worker&quot;</span><span class="p">]</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a>    <span class="n">gpu_ids</span> <span class="o">=</span> <span class="n">get_gpu_devices</span><span class="p">()</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a>    <span class="c1"># Place on one or more CPU(s) when either:</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a>    <span class="c1"># - Fake GPU mode.</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a>    <span class="c1"># - num_gpus=0 (either set by user or we are in local_mode=True).</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a>    <span class="c1"># - no GPUs available.</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a>    <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;_fake_gpus&quot;</span><span class="p">]</span> <span class="ow">or</span> <span class="n">num_gpus</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">gpu_ids</span><span class="p">:</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a>        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;TFPolicy (worker=</span><span class="si">{}</span><span class="s2">) running on </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a>            <span class="n">worker_idx</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a>            <span class="k">if</span> <span class="n">worker_idx</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="s2">&quot;local&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">num_gpus</span><span class="si">}</span><span class="s2"> fake-GPUs&quot;</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a>            <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;_fake_gpus&quot;</span><span class="p">]</span> <span class="k">else</span> <span class="s2">&quot;CPU&quot;</span><span class="p">))</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">devices</span> <span class="o">=</span> <span class="p">[</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>            <span class="s2">&quot;/cpu:0&quot;</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">num_gpus</span><span class="p">))</span> <span class="ow">or</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>        <span class="p">]</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>    <span class="c1"># Place on one or more actual GPU(s), when:</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>    <span class="c1"># - num_gpus &gt; 0 (set by user) AND</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>    <span class="c1"># - local_mode=False AND</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>    <span class="c1"># - actual GPUs available AND</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>    <span class="c1"># - non-fake GPU mode.</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;TFPolicy (worker=</span><span class="si">{}</span><span class="s2">) running on </span><span class="si">{}</span><span class="s2"> GPU(s).&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>            <span class="n">worker_idx</span> <span class="k">if</span> <span class="n">worker_idx</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="s2">&quot;local&quot;</span><span class="p">,</span> <span class="n">num_gpus</span><span class="p">))</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>        <span class="c1"># We are a remote worker (WORKER_MODE=1):</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>        <span class="c1"># GPUs should be assigned to us by ray.</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>        <span class="k">if</span> <span class="n">ray</span><span class="o">.</span><span class="n">worker</span><span class="o">.</span><span class="n">_mode</span><span class="p">()</span> <span class="o">==</span> <span class="n">ray</span><span class="o">.</span><span class="n">worker</span><span class="o">.</span><span class="n">WORKER_MODE</span><span class="p">:</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a>            <span class="n">gpu_ids</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">get_gpu_ids</span><span class="p">()</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">gpu_ids</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">num_gpus</span><span class="p">:</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a>                <span class="s2">&quot;TFPolicy was not able to find enough GPU IDs! Found &quot;</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">gpu_ids</span><span class="si">}</span><span class="s2">, but num_gpus=</span><span class="si">{</span><span class="n">num_gpus</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">devices</span> <span class="o">=</span> <span class="p">[</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a>            <span class="sa">f</span><span class="s2">&quot;/gpu:</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">gpu_ids</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">num_gpus</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a>        <span class="p">]</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a>    <span class="c1"># Disable env-info placeholder.</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>    <span class="k">if</span> <span class="n">SampleBatch</span><span class="o">.</span><span class="n">INFOS</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">view_requirements</span><span class="p">:</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">view_requirements</span><span class="p">[</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">INFOS</span><span class="p">]</span><span class="o">.</span><span class="n">used_for_training</span> <span class="o">=</span> <span class="kc">False</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">view_requirements</span><span class="p">[</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a>            <span class="n">SampleBatch</span><span class="o">.</span><span class="n">INFOS</span><span class="p">]</span><span class="o">.</span><span class="n">used_for_compute_actions</span> <span class="o">=</span> <span class="kc">False</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a>    <span class="k">assert</span> <span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="n">ModelV2</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">)),</span> \
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>        <span class="s2">&quot;Model classes for TFPolicy other than `ModelV2|tf.keras.Model` &quot;</span> \
<a id="__codelineno-0-136" name="__codelineno-0-136"></a>        <span class="s2">&quot;not allowed! You passed in </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>    <span class="c1"># Auto-update model&#39;s inference view requirements, if recurrent.</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_update_model_view_requirements_from_init_state</span><span class="p">()</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>    <span class="c1"># If `explore` is explicitly set to False, don&#39;t create an exploration</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>    <span class="c1"># component.</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">exploration</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_exploration</span><span class="p">()</span> <span class="k">if</span> <span class="n">explore</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">False</span> \
<a id="__codelineno-0-145" name="__codelineno-0-145"></a>        <span class="k">else</span> <span class="kc">None</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_sess</span> <span class="o">=</span> <span class="n">sess</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_obs_input</span> <span class="o">=</span> <span class="n">obs_input</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_prev_action_input</span> <span class="o">=</span> <span class="n">prev_action_input</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_prev_reward_input</span> <span class="o">=</span> <span class="n">prev_reward_input</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_sampled_action</span> <span class="o">=</span> <span class="n">sampled_action</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_is_training</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_is_training_placeholder</span><span class="p">()</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_is_exploring</span> <span class="o">=</span> <span class="n">explore</span> <span class="k">if</span> <span class="n">explore</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> \
<a id="__codelineno-0-154" name="__codelineno-0-154"></a>        <span class="n">tf1</span><span class="o">.</span><span class="n">placeholder_with_default</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="p">(),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;is_exploring&quot;</span><span class="p">)</span>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_sampled_action_logp</span> <span class="o">=</span> <span class="n">sampled_action_logp</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_sampled_action_prob</span> <span class="o">=</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_sampled_action_logp</span><span class="p">)</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a>                                 <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sampled_action_logp</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a>                                 <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_action_input</span> <span class="o">=</span> <span class="n">action_input</span>  <span class="c1"># For logp calculations.</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_dist_inputs</span> <span class="o">=</span> <span class="n">dist_inputs</span>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">dist_class</span> <span class="o">=</span> <span class="n">dist_class</span>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_state_inputs</span> <span class="o">=</span> <span class="n">state_inputs</span> <span class="ow">or</span> <span class="p">[]</span>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_state_outputs</span> <span class="o">=</span> <span class="n">state_outputs</span> <span class="ow">or</span> <span class="p">[]</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_seq_lens</span> <span class="o">=</span> <span class="n">seq_lens</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_max_seq_len</span> <span class="o">=</span> <span class="n">max_seq_len</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_state_inputs</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_seq_lens</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a>            <span class="s2">&quot;seq_lens tensor must be given if state inputs are defined&quot;</span><span class="p">)</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_batch_divisibility_req</span> <span class="o">=</span> <span class="n">batch_divisibility_req</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_update_ops</span> <span class="o">=</span> <span class="n">update_ops</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_apply_op</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_stats_fetches</span> <span class="o">=</span> <span class="p">{}</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_timestep</span> <span class="o">=</span> <span class="n">timestep</span> <span class="k">if</span> <span class="n">timestep</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> \
<a id="__codelineno-0-177" name="__codelineno-0-177"></a>        <span class="n">tf1</span><span class="o">.</span><span class="n">placeholder_with_default</span><span class="p">(</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a>            <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">((),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span> <span class="p">(),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;timestep&quot;</span><span class="p">)</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_optimizers</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">LocalOptimizer</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a>    <span class="c1"># Backward compatibility and for some code shared with tf-eager Policy.</span>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_grads_and_vars</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ModelGradients</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ModelGradients</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_grads</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ModelGradients</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ModelGradients</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a>    <span class="c1"># Policy tf-variables (weights), whose values to get/set via</span>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a>    <span class="c1"># get_weights/set_weights.</span>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_variables</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a>    <span class="c1"># Local optimizer(s)&#39; tf-variables (e.g. state vars for Adam).</span>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a>    <span class="c1"># Will be stored alongside `self._variables` when checkpointing.</span>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_variables</span><span class="p">:</span> \
<a id="__codelineno-0-192" name="__codelineno-0-192"></a>        <span class="n">Optional</span><span class="p">[</span><span class="n">ray</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">tf_utils</span><span class="o">.</span><span class="n">TensorFlowVariables</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a>
<a id="__codelineno-0-194" name="__codelineno-0-194"></a>    <span class="c1"># The loss tf-op(s). Number of losses must match number of optimizers.</span>
<a id="__codelineno-0-195" name="__codelineno-0-195"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_losses</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a>    <span class="c1"># Backward compatibility (in case custom child TFPolicies access this</span>
<a id="__codelineno-0-197" name="__codelineno-0-197"></a>    <span class="c1"># property).</span>
<a id="__codelineno-0-198" name="__codelineno-0-198"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-199" name="__codelineno-0-199"></a>    <span class="c1"># A batch dict passed into loss function as input.</span>
<a id="__codelineno-0-200" name="__codelineno-0-200"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_loss_input_dict</span> <span class="o">=</span> <span class="p">{}</span>
<a id="__codelineno-0-201" name="__codelineno-0-201"></a>    <span class="n">losses</span> <span class="o">=</span> <span class="n">force_list</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<a id="__codelineno-0-202" name="__codelineno-0-202"></a>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-0-203" name="__codelineno-0-203"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_loss</span><span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="n">loss_inputs</span><span class="p">)</span>
<a id="__codelineno-0-204" name="__codelineno-0-204"></a>
<a id="__codelineno-0-205" name="__codelineno-0-205"></a>    <span class="c1"># The log-likelihood calculator op.</span>
<a id="__codelineno-0-206" name="__codelineno-0-206"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_log_likelihood</span> <span class="o">=</span> <span class="n">log_likelihood</span>
<a id="__codelineno-0-207" name="__codelineno-0-207"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_likelihood</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dist_inputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> \
<a id="__codelineno-0-208" name="__codelineno-0-208"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">dist_class</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-209" name="__codelineno-0-209"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_log_likelihood</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist_class</span><span class="p">(</span>
<a id="__codelineno-0-210" name="__codelineno-0-210"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_dist_inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="n">logp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_action_input</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.tf_policy.TFPolicy.apply_gradients">
<code class="highlight language-python"><span class="n">apply_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gradients</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Applies the (previously) computed gradients.</p>
<p>Either this in combination with <code>compute_gradients()</code> or
<code>learn_on_batch()</code> must be implemented by subclasses.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>gradients</code></td>
        <td><code>Union[List[Tuple[Any, Any]], List[Any]]</code></td>
        <td><p>The already calculated gradients to apply to this
Policy.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/tf_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="k">def</span> <span class="nf">apply_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gradients</span><span class="p">:</span> <span class="n">ModelGradients</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_initialized</span><span class="p">()</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>    <span class="n">builder</span> <span class="o">=</span> <span class="n">TFRunBuilder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_session</span><span class="p">(),</span> <span class="s2">&quot;apply_gradients&quot;</span><span class="p">)</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>    <span class="n">fetches</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_apply_gradients</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">gradients</span><span class="p">)</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>    <span class="n">builder</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">fetches</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.tf_policy.TFPolicy.build_apply_op">
<code class="highlight language-python"><span class="n">build_apply_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">grads_and_vars</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Override this for a custom gradient apply computation behavior.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>optimizer</code></td>
        <td><code>Union[LocalOptimizer, List[LocalOptimizer]]</code></td>
        <td><p>The local
tf optimizer to use for applying the grads and vars.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>grads_and_vars</code></td>
        <td><code>Union[ModelGradients, List[ModelGradients]]</code></td>
        <td><p>List
of tuples with grad values and the grad-value's corresponding
tf.variable in it.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>tf.Operation</code></td>
      <td><p>The tf op that applies all computed gradients
    (<code>grads_and_vars</code>) to the model(s) via the given optimizer(s).</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/tf_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">build_apply_op</span><span class="p">(</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>        <span class="n">optimizer</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">LocalOptimizer</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">LocalOptimizer</span><span class="p">]],</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>        <span class="n">grads_and_vars</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ModelGradients</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ModelGradients</span><span class="p">]],</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;tf.Operation&quot;</span><span class="p">:</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>    <span class="sd">&quot;&quot;&quot;Override this for a custom gradient apply computation behavior.</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="sd">        optimizer (Union[LocalOptimizer, List[LocalOptimizer]]): The local</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="sd">            tf optimizer to use for applying the grads and vars.</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="sd">        grads_and_vars (Union[ModelGradients, List[ModelGradients]]): List</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a><span class="sd">            of tuples with grad values and the grad-value&#39;s corresponding</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a><span class="sd">            tf.variable in it.</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a><span class="sd">        tf.Operation: The tf op that applies all computed gradients</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a><span class="sd">            (`grads_and_vars`) to the model(s) via the given optimizer(s).</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a>    <span class="n">optimizers</span> <span class="o">=</span> <span class="n">force_list</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a>    <span class="c1"># We have more than one optimizers and loss terms.</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;_tf_policy_handles_more_than_one_loss&quot;</span><span class="p">]:</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a>        <span class="n">ops</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">optim</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">optimizers</span><span class="p">):</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a>            <span class="c1"># Specify global_step (e.g. for TD3 which needs to count the</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a>            <span class="c1"># num updates that have happened).</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a>            <span class="n">ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a>                <span class="n">optim</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a>                    <span class="n">grads_and_vars</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a>                    <span class="n">global_step</span><span class="o">=</span><span class="n">tf1</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get_or_create_global_step</span><span class="p">()))</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a>        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="n">ops</span><span class="p">)</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a>    <span class="c1"># We have only one optimizer and one loss term.</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a>        <span class="k">return</span> <span class="n">optimizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a>            <span class="n">grads_and_vars</span><span class="p">,</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a>            <span class="n">global_step</span><span class="o">=</span><span class="n">tf1</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get_or_create_global_step</span><span class="p">())</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.tf_policy.TFPolicy.compute_actions">
<code class="highlight language-python"><span class="n">compute_actions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs_batch</span><span class="p">,</span> <span class="n">state_batches</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prev_action_batch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prev_reward_batch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">info_batch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">episodes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">explore</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">timestep</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Computes actions for the current policy.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>obs_batch</code></td>
        <td><code>Union[List[Any], Any]</code></td>
        <td><p>Batch of observations.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>state_batches</code></td>
        <td><code>Optional[List[Any]]</code></td>
        <td><p>List of RNN state input batches, if any.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>prev_action_batch</code></td>
        <td><code>Union[List[Any], Any]</code></td>
        <td><p>Batch of previous action values.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>prev_reward_batch</code></td>
        <td><code>Union[List[Any], Any]</code></td>
        <td><p>Batch of previous rewards.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>info_batch</code></td>
        <td><code>Optional[Dict[str, list]]</code></td>
        <td><p>Batch of info objects.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>episodes</code></td>
        <td><code>Optional[List[Episode]]</code></td>
        <td><p>List of Episode objects, one for each obs in
obs_batch. This provides access to all of the internal
episode state, which may be useful for model-based or
multi-agent algorithms.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>explore</code></td>
        <td><code>Optional[bool]</code></td>
        <td><p>Whether to pick an exploitation or exploration action.
Set to None (default) for using the value of
<code>self.config["explore"]</code>.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>timestep</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>The current (sampling) time step.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>actions (TensorType)</code></td>
      <td><p>Batch of output actions, with shape like
    [BATCH_SIZE, ACTION_SHAPE].
state_outs (List[TensorType]): List of RNN state output
    batches, if any, each with shape [BATCH_SIZE, STATE_SIZE].
info (List[dict]): Dictionary of extra feature batches, if any,
    with shape like
    {"f1": [BATCH_SIZE, ...], "f2": [BATCH_SIZE, ...]}.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/tf_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">compute_actions</span><span class="p">(</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>        <span class="n">obs_batch</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">],</span> <span class="n">TensorType</span><span class="p">],</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>        <span class="n">state_batches</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>        <span class="n">prev_action_batch</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">],</span> <span class="n">TensorType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>        <span class="n">prev_reward_batch</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">],</span> <span class="n">TensorType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>        <span class="n">info_batch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>        <span class="n">episodes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="s2">&quot;Episode&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>        <span class="n">explore</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>        <span class="n">timestep</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>        <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>    <span class="n">explore</span> <span class="o">=</span> <span class="n">explore</span> <span class="k">if</span> <span class="n">explore</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;explore&quot;</span><span class="p">]</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>    <span class="n">timestep</span> <span class="o">=</span> <span class="n">timestep</span> <span class="k">if</span> <span class="n">timestep</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_timestep</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>    <span class="n">builder</span> <span class="o">=</span> <span class="n">TFRunBuilder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_session</span><span class="p">(),</span> <span class="s2">&quot;compute_actions&quot;</span><span class="p">)</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a>    <span class="n">input_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">OBS</span><span class="p">:</span> <span class="n">obs_batch</span><span class="p">,</span> <span class="s2">&quot;is_training&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">}</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a>    <span class="k">if</span> <span class="n">state_batches</span><span class="p">:</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">state_batches</span><span class="p">):</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a>            <span class="n">input_dict</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;state_in_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">s</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a>    <span class="k">if</span> <span class="n">prev_action_batch</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a>        <span class="n">input_dict</span><span class="p">[</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">PREV_ACTIONS</span><span class="p">]</span> <span class="o">=</span> <span class="n">prev_action_batch</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a>    <span class="k">if</span> <span class="n">prev_reward_batch</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a>        <span class="n">input_dict</span><span class="p">[</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">PREV_REWARDS</span><span class="p">]</span> <span class="o">=</span> <span class="n">prev_reward_batch</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a>    <span class="n">to_fetch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_compute_actions</span><span class="p">(</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a>        <span class="n">builder</span><span class="p">,</span> <span class="n">input_dict</span><span class="o">=</span><span class="n">input_dict</span><span class="p">,</span> <span class="n">explore</span><span class="o">=</span><span class="n">explore</span><span class="p">,</span> <span class="n">timestep</span><span class="o">=</span><span class="n">timestep</span><span class="p">)</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a>    <span class="c1"># Execute session run to get action (and other fetches).</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a>    <span class="n">fetched</span> <span class="o">=</span> <span class="n">builder</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">to_fetch</span><span class="p">)</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a>    <span class="c1"># Update our global timestep by the batch size.</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">global_timestep</span> <span class="o">+=</span> \
<a id="__codelineno-0-36" name="__codelineno-0-36"></a>        <span class="nb">len</span><span class="p">(</span><span class="n">obs_batch</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obs_batch</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> \
<a id="__codelineno-0-37" name="__codelineno-0-37"></a>        <span class="k">else</span> <span class="n">tree</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">obs_batch</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>    <span class="k">return</span> <span class="n">fetched</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.tf_policy.TFPolicy.compute_actions_from_input_dict">
<code class="highlight language-python"><span class="n">compute_actions_from_input_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dict</span><span class="p">,</span> <span class="n">explore</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">timestep</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">episodes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Computes actions from collected samples (across multiple-agents).</p>
<p>Takes an input dict (usually a SampleBatch) as its main data input.
This allows for using this method in case a more complex input pattern
(view requirements) is needed, for example when the Model requires the
last n observations, the last m actions/rewards, or a combination
of any of these.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>input_dict</code></td>
        <td><code>Union[ray.rllib.policy.sample_batch.SampleBatch, Dict[str, Any]]</code></td>
        <td><p>A SampleBatch or input dict containing the Tensors
to compute actions. <code>input_dict</code> already abides to the
Policy's as well as the Model's view requirements and can
thus be passed to the Model as-is.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>explore</code></td>
        <td><code>bool</code></td>
        <td><p>Whether to pick an exploitation or exploration
action (default: None -&gt; use self.config["explore"]).</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>timestep</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>The current (sampling) time step.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>episodes</code></td>
        <td><code>Optional[List[Episode]]</code></td>
        <td><p>This provides access to all of the internal episodes'
state, which may be useful for model-based or multi-agent
algorithms.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>actions</code></td>
      <td><p>Batch of output actions, with shape like
    [BATCH_SIZE, ACTION_SHAPE].
state_outs: List of RNN state output
    batches, if any, each with shape [BATCH_SIZE, STATE_SIZE].
info: Dictionary of extra feature batches, if any, with shape like
    {"f1": [BATCH_SIZE, ...], "f2": [BATCH_SIZE, ...]}.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/tf_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">compute_actions_from_input_dict</span><span class="p">(</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>        <span class="n">input_dict</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">SampleBatch</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]],</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>        <span class="n">explore</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>        <span class="n">timestep</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>        <span class="n">episodes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="s2">&quot;Episode&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>        <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> \
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>        <span class="n">Tuple</span><span class="p">[</span><span class="n">TensorType</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]]:</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>    <span class="n">explore</span> <span class="o">=</span> <span class="n">explore</span> <span class="k">if</span> <span class="n">explore</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;explore&quot;</span><span class="p">]</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>    <span class="n">timestep</span> <span class="o">=</span> <span class="n">timestep</span> <span class="k">if</span> <span class="n">timestep</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">global_timestep</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>    <span class="c1"># Switch off is_training flag in our batch.</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>    <span class="n">input_dict</span><span class="p">[</span><span class="s2">&quot;is_training&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>    <span class="n">builder</span> <span class="o">=</span> <span class="n">TFRunBuilder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_session</span><span class="p">(),</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a>                           <span class="s2">&quot;compute_actions_from_input_dict&quot;</span><span class="p">)</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a>    <span class="n">obs_batch</span> <span class="o">=</span> <span class="n">input_dict</span><span class="p">[</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">OBS</span><span class="p">]</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a>    <span class="n">to_fetch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_compute_actions</span><span class="p">(</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a>        <span class="n">builder</span><span class="p">,</span> <span class="n">input_dict</span><span class="o">=</span><span class="n">input_dict</span><span class="p">,</span> <span class="n">explore</span><span class="o">=</span><span class="n">explore</span><span class="p">,</span> <span class="n">timestep</span><span class="o">=</span><span class="n">timestep</span><span class="p">)</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a>    <span class="c1"># Execute session run to get action (and other fetches).</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a>    <span class="n">fetched</span> <span class="o">=</span> <span class="n">builder</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">to_fetch</span><span class="p">)</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a>    <span class="c1"># Update our global timestep by the batch size.</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">global_timestep</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">obs_batch</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obs_batch</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> \
<a id="__codelineno-0-28" name="__codelineno-0-28"></a>        <span class="k">else</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_dict</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_dict</span><span class="p">,</span> <span class="n">SampleBatch</span><span class="p">)</span> \
<a id="__codelineno-0-29" name="__codelineno-0-29"></a>        <span class="k">else</span> <span class="n">obs_batch</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a>    <span class="k">return</span> <span class="n">fetched</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.tf_policy.TFPolicy.compute_gradients">
<code class="highlight language-python"><span class="n">compute_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">postprocessed_batch</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Computes gradients given a batch of experiences.</p>
<p>Either this in combination with <code>apply_gradients()</code> or
<code>learn_on_batch()</code> must be implemented by subclasses.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>postprocessed_batch</code></td>
        <td><code>SampleBatch</code></td>
        <td><p>The SampleBatch object to use
for calculating gradients.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>grads</code></td>
      <td><p>List of gradient output values.
grad_info: Extra policy-specific info values.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/tf_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="k">def</span> <span class="nf">compute_gradients</span><span class="p">(</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>        <span class="n">postprocessed_batch</span><span class="p">:</span> <span class="n">SampleBatch</span><span class="p">)</span> <span class="o">-&gt;</span> \
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>        <span class="n">Tuple</span><span class="p">[</span><span class="n">ModelGradients</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]]:</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_initialized</span><span class="p">()</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>    <span class="c1"># Switch on is_training flag in our batch.</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>    <span class="n">postprocessed_batch</span><span class="o">.</span><span class="n">set_training</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>    <span class="n">builder</span> <span class="o">=</span> <span class="n">TFRunBuilder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_session</span><span class="p">(),</span> <span class="s2">&quot;compute_gradients&quot;</span><span class="p">)</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>    <span class="n">fetches</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_compute_gradients</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">postprocessed_batch</span><span class="p">)</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>    <span class="k">return</span> <span class="n">builder</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">fetches</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.tf_policy.TFPolicy.compute_log_likelihoods">
<code class="highlight language-python"><span class="n">compute_log_likelihoods</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">obs_batch</span><span class="p">,</span> <span class="n">state_batches</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prev_action_batch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prev_reward_batch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">actions_normalized</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Computes the log-prob/likelihood for a given action and observation.</p>
<p>The log-likelihood is calculated using this Policy's action
distribution class (self.dist_class).</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>actions</code></td>
        <td><code>Union[List[Any], Any]</code></td>
        <td><p>Batch of actions, for which to retrieve the
log-probs/likelihoods (given all other inputs: obs,
states, ..).</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>obs_batch</code></td>
        <td><code>Union[List[Any], Any]</code></td>
        <td><p>Batch of observations.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>state_batches</code></td>
        <td><code>Optional[List[Any]]</code></td>
        <td><p>List of RNN state input batches, if any.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>prev_action_batch</code></td>
        <td><code>Union[List[Any], Any]</code></td>
        <td><p>Batch of previous action values.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>prev_reward_batch</code></td>
        <td><code>Union[List[Any], Any]</code></td>
        <td><p>Batch of previous rewards.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>actions_normalized</code></td>
        <td><code>bool</code></td>
        <td><p>Is the given <code>actions</code> already normalized
(between -1.0 and 1.0) or not? If not and
<code>normalize_actions=True</code>, we need to normalize the given
actions first, before calculating log likelihoods.</p></td>
        <td><code>True</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Batch of log probs/likelihoods, with shape</code></td>
      <td><p>[BATCH_SIZE].</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/tf_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">compute_log_likelihoods</span><span class="p">(</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>        <span class="n">actions</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">],</span> <span class="n">TensorType</span><span class="p">],</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>        <span class="n">obs_batch</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">],</span> <span class="n">TensorType</span><span class="p">],</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>        <span class="n">state_batches</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>        <span class="n">prev_action_batch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">],</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>                                          <span class="n">TensorType</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>        <span class="n">prev_reward_batch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">],</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>                                          <span class="n">TensorType</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>        <span class="n">actions_normalized</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorType</span><span class="p">:</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_likelihood</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Cannot compute log-prob/likelihood w/o a &quot;</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a>                         <span class="s2">&quot;self._log_likelihood op!&quot;</span><span class="p">)</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a>    <span class="c1"># Exploration hook before each forward pass.</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">exploration</span><span class="o">.</span><span class="n">before_compute_actions</span><span class="p">(</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a>        <span class="n">explore</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">tf_sess</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">get_session</span><span class="p">())</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a>    <span class="n">builder</span> <span class="o">=</span> <span class="n">TFRunBuilder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_session</span><span class="p">(),</span> <span class="s2">&quot;compute_log_likelihoods&quot;</span><span class="p">)</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a>    <span class="c1"># Normalize actions if necessary.</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a>    <span class="k">if</span> <span class="n">actions_normalized</span> <span class="ow">is</span> <span class="kc">False</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;normalize_actions&quot;</span><span class="p">]:</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a>        <span class="n">actions</span> <span class="o">=</span> <span class="n">normalize_action</span><span class="p">(</span><span class="n">actions</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space_struct</span><span class="p">)</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a>    <span class="c1"># Feed actions (for which we want logp values) into graph.</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a>    <span class="n">builder</span><span class="o">.</span><span class="n">add_feed_dict</span><span class="p">({</span><span class="bp">self</span><span class="o">.</span><span class="n">_action_input</span><span class="p">:</span> <span class="n">actions</span><span class="p">})</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a>    <span class="c1"># Feed observations.</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a>    <span class="n">builder</span><span class="o">.</span><span class="n">add_feed_dict</span><span class="p">({</span><span class="bp">self</span><span class="o">.</span><span class="n">_obs_input</span><span class="p">:</span> <span class="n">obs_batch</span><span class="p">})</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a>    <span class="c1"># Internal states.</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a>    <span class="n">state_batches</span> <span class="o">=</span> <span class="n">state_batches</span> <span class="ow">or</span> <span class="p">[]</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_state_inputs</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">state_batches</span><span class="p">):</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a>            <span class="s2">&quot;Must pass in RNN state batches for placeholders </span><span class="si">{}</span><span class="s2">, got </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a>            <span class="nb">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_state_inputs</span><span class="p">,</span> <span class="n">state_batches</span><span class="p">))</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a>    <span class="n">builder</span><span class="o">.</span><span class="n">add_feed_dict</span><span class="p">(</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>        <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a>         <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_state_inputs</span><span class="p">,</span> <span class="n">state_batches</span><span class="p">)})</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a>    <span class="k">if</span> <span class="n">state_batches</span><span class="p">:</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a>        <span class="n">builder</span><span class="o">.</span><span class="n">add_feed_dict</span><span class="p">({</span><span class="bp">self</span><span class="o">.</span><span class="n">_seq_lens</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">obs_batch</span><span class="p">))})</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a>    <span class="c1"># Prev-a and r.</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prev_action_input</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> \
<a id="__codelineno-0-45" name="__codelineno-0-45"></a>       <span class="n">prev_action_batch</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>        <span class="n">builder</span><span class="o">.</span><span class="n">add_feed_dict</span><span class="p">({</span><span class="bp">self</span><span class="o">.</span><span class="n">_prev_action_input</span><span class="p">:</span> <span class="n">prev_action_batch</span><span class="p">})</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prev_reward_input</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> \
<a id="__codelineno-0-48" name="__codelineno-0-48"></a>       <span class="n">prev_reward_batch</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a>        <span class="n">builder</span><span class="o">.</span><span class="n">add_feed_dict</span><span class="p">({</span><span class="bp">self</span><span class="o">.</span><span class="n">_prev_reward_input</span><span class="p">:</span> <span class="n">prev_reward_batch</span><span class="p">})</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a>    <span class="c1"># Fetch the log_likelihoods output and return.</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a>    <span class="n">fetches</span> <span class="o">=</span> <span class="n">builder</span><span class="o">.</span><span class="n">add_fetches</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_likelihood</span><span class="p">])</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a>    <span class="k">return</span> <span class="n">builder</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">fetches</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.tf_policy.TFPolicy.copy">
<code class="highlight language-python"><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">existing_inputs</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Creates a copy of self using existing input placeholders.</p>
<p>Optional: Only required to work with the multi-GPU optimizer.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>existing_inputs</code></td>
        <td><code>List[Tuple[str, tf1.placeholder]]</code></td>
        <td><p>Dict mapping
names (str) to tf1.placeholders to re-use (share) with the
returned copy of self.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>TFPolicy</code></td>
      <td><p>A copy of self.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/tf_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>         <span class="n">existing_inputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;tf1.placeholder&quot;</span><span class="p">]])</span> <span class="o">-&gt;</span> \
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>        <span class="s2">&quot;TFPolicy&quot;</span><span class="p">:</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>    <span class="sd">&quot;&quot;&quot;Creates a copy of self using existing input placeholders.</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="sd">    Optional: Only required to work with the multi-GPU optimizer.</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="sd">        existing_inputs (List[Tuple[str, tf1.placeholder]]): Dict mapping</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="sd">            names (str) to tf1.placeholders to re-use (share) with the</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="sd">            returned copy of self.</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a><span class="sd">        TFPolicy: A copy of self.</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.tf_policy.TFPolicy.export_checkpoint">
<code class="highlight language-python"><span class="n">export_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">export_dir</span><span class="p">,</span> <span class="n">filename_prefix</span><span class="o">=</span><span class="s1">&#39;model&#39;</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Export tensorflow checkpoint to export_dir.</p>

        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/tf_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="k">def</span> <span class="nf">export_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>                      <span class="n">export_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>                      <span class="n">filename_prefix</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;model&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>    <span class="sd">&quot;&quot;&quot;Export tensorflow checkpoint to export_dir.&quot;&quot;&quot;</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>    <span class="k">try</span><span class="p">:</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">export_dir</span><span class="p">)</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>    <span class="k">except</span> <span class="ne">OSError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>        <span class="c1"># ignore error if export dir already exists</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>        <span class="k">if</span> <span class="n">e</span><span class="o">.</span><span class="n">errno</span> <span class="o">!=</span> <span class="n">errno</span><span class="o">.</span><span class="n">EEXIST</span><span class="p">:</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>            <span class="k">raise</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>    <span class="n">save_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">export_dir</span><span class="p">,</span> <span class="n">filename_prefix</span><span class="p">)</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>        <span class="n">saver</span> <span class="o">=</span> <span class="n">tf1</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a>        <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_session</span><span class="p">(),</span> <span class="n">save_path</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.tf_policy.TFPolicy.export_model">
<code class="highlight language-python"><span class="n">export_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">export_dir</span><span class="p">,</span> <span class="n">onnx</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Export tensorflow graph to export_dir for serving.</p>

        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/tf_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="k">def</span> <span class="nf">export_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">export_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>                 <span class="n">onnx</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>    <span class="sd">&quot;&quot;&quot;Export tensorflow graph to export_dir for serving.&quot;&quot;&quot;</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>    <span class="k">if</span> <span class="n">onnx</span><span class="p">:</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>        <span class="k">try</span><span class="p">:</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>            <span class="kn">import</span> <span class="nn">tf2onnx</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>        <span class="k">except</span> <span class="ne">ImportError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>                <span class="s2">&quot;Converting a TensorFlow model to ONNX requires &quot;</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>                <span class="s2">&quot;`tf2onnx` to be installed. Install with &quot;</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>                <span class="s2">&quot;`pip install tf2onnx`.&quot;</span><span class="p">)</span> <span class="kn">from</span> <span class="nn">e</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a>            <span class="n">signature_def_map</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_signature_def</span><span class="p">()</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a>            <span class="n">sd</span> <span class="o">=</span> <span class="n">signature_def_map</span><span class="p">[</span><span class="n">tf1</span><span class="o">.</span><span class="n">saved_model</span><span class="o">.</span><span class="n">signature_constants</span><span class="o">.</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a>                                   <span class="n">DEFAULT_SERVING_SIGNATURE_DEF_KEY</span><span class="p">]</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a>            <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">sd</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">()]</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a>            <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">sd</span><span class="o">.</span><span class="n">outputs</span><span class="o">.</span><span class="n">items</span><span class="p">()]</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a>            <span class="kn">from</span> <span class="nn">tf2onnx</span> <span class="kn">import</span> <span class="n">tf_loader</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a>            <span class="n">frozen_graph_def</span> <span class="o">=</span> <span class="n">tf_loader</span><span class="o">.</span><span class="n">freeze_session</span><span class="p">(</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_sess</span><span class="p">,</span> <span class="n">input_names</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">output_names</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a>        <span class="k">with</span> <span class="n">tf1</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">())</span> <span class="k">as</span> <span class="n">session</span><span class="p">:</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a>            <span class="n">tf</span><span class="o">.</span><span class="n">import_graph_def</span><span class="p">(</span><span class="n">frozen_graph_def</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a>            <span class="n">g</span> <span class="o">=</span> <span class="n">tf2onnx</span><span class="o">.</span><span class="n">tfonnx</span><span class="o">.</span><span class="n">process_tf_graph</span><span class="p">(</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a>                <span class="n">session</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a>                <span class="n">input_names</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a>                <span class="n">output_names</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a>                <span class="n">inputs_as_nchw</span><span class="o">=</span><span class="n">inputs</span><span class="p">)</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a>            <span class="n">model_proto</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">make_model</span><span class="p">(</span><span class="s2">&quot;onnx_model&quot;</span><span class="p">)</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a>            <span class="n">tf2onnx</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">save_onnx_model</span><span class="p">(</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a>                <span class="n">export_dir</span><span class="p">,</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>                <span class="s2">&quot;saved_model&quot;</span><span class="p">,</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a>                <span class="n">feed_dict</span><span class="o">=</span><span class="p">{},</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a>                <span class="n">model_proto</span><span class="o">=</span><span class="n">model_proto</span><span class="p">)</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a>        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>            <span class="n">signature_def_map</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_signature_def</span><span class="p">()</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a>            <span class="n">builder</span> <span class="o">=</span> <span class="n">tf1</span><span class="o">.</span><span class="n">saved_model</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">SavedModelBuilder</span><span class="p">(</span><span class="n">export_dir</span><span class="p">)</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>            <span class="n">builder</span><span class="o">.</span><span class="n">add_meta_graph_and_variables</span><span class="p">(</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">get_session</span><span class="p">(),</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a>                <span class="p">[</span><span class="n">tf1</span><span class="o">.</span><span class="n">saved_model</span><span class="o">.</span><span class="n">tag_constants</span><span class="o">.</span><span class="n">SERVING</span><span class="p">],</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a>                <span class="n">signature_def_map</span><span class="o">=</span><span class="n">signature_def_map</span><span class="p">,</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a>                <span class="n">saver</span><span class="o">=</span><span class="n">tf1</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">FileWriter</span><span class="p">(</span><span class="n">export_dir</span><span class="p">)</span><span class="o">.</span><span class="n">add_graph</span><span class="p">(</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a>                    <span class="n">graph</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span><span class="o">.</span><span class="n">graph</span><span class="p">))</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a>            <span class="n">builder</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.tf_policy.TFPolicy.extra_compute_action_feed_dict">
<code class="highlight language-python"><span class="n">extra_compute_action_feed_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Extra dict to pass to the compute actions session run.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Dict[TensorType, TensorType]</code></td>
      <td><p>A feed dict to be added to the
    feed_dict passed to the compute_actions session.run() call.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/tf_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">extra_compute_action_feed_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">TensorType</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]:</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="sd">&quot;&quot;&quot;Extra dict to pass to the compute actions session run.</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="sd">        Dict[TensorType, TensorType]: A feed dict to be added to the</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="sd">            feed_dict passed to the compute_actions session.run() call.</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>    <span class="k">return</span> <span class="p">{}</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.tf_policy.TFPolicy.extra_compute_action_fetches">
<code class="highlight language-python"><span class="n">extra_compute_action_fetches</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Extra values to fetch and return from compute_actions().</p>
<p>By default we return action probability/log-likelihood info
and action distribution inputs (if present).</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Dict[str, TensorType]</code></td>
      <td><p>An extra fetch-dict to be passed to and
   returned from the compute_actions() call.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/tf_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">extra_compute_action_fetches</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]:</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="sd">&quot;&quot;&quot;Extra values to fetch and return from compute_actions().</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="sd">    By default we return action probability/log-likelihood info</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="sd">    and action distribution inputs (if present).</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="sd">         Dict[str, TensorType]: An extra fetch-dict to be passed to and</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="sd">            returned from the compute_actions() call.</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>    <span class="n">extra_fetches</span> <span class="o">=</span> <span class="p">{}</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>    <span class="c1"># Action-logp and action-prob.</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sampled_action_logp</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>        <span class="n">extra_fetches</span><span class="p">[</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">ACTION_PROB</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sampled_action_prob</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a>        <span class="n">extra_fetches</span><span class="p">[</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">ACTION_LOGP</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sampled_action_logp</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>    <span class="c1"># Action-dist inputs.</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dist_inputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a>        <span class="n">extra_fetches</span><span class="p">[</span><span class="n">SampleBatch</span><span class="o">.</span><span class="n">ACTION_DIST_INPUTS</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dist_inputs</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a>    <span class="k">return</span> <span class="n">extra_fetches</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.tf_policy.TFPolicy.extra_compute_grad_feed_dict">
<code class="highlight language-python"><span class="n">extra_compute_grad_feed_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Extra dict to pass to the compute gradients session run.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Dict[TensorType, TensorType]</code></td>
      <td><p>Extra feed_dict to be passed to the
    compute_gradients Session.run() call.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/tf_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">extra_compute_grad_feed_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">TensorType</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]:</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="sd">&quot;&quot;&quot;Extra dict to pass to the compute gradients session run.</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="sd">        Dict[TensorType, TensorType]: Extra feed_dict to be passed to the</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="sd">            compute_gradients Session.run() call.</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>    <span class="k">return</span> <span class="p">{}</span>  <span class="c1"># e.g, kl_coeff</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.tf_policy.TFPolicy.extra_compute_grad_fetches">
<code class="highlight language-python"><span class="n">extra_compute_grad_fetches</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Extra values to fetch and return from compute_gradients().</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Dict[str, any]</code></td>
      <td><p>Extra fetch dict to be added to the fetch dict
    of the compute_gradients Session.run() call.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/tf_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">extra_compute_grad_fetches</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">any</span><span class="p">]:</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="sd">&quot;&quot;&quot;Extra values to fetch and return from compute_gradients().</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="sd">        Dict[str, any]: Extra fetch dict to be added to the fetch dict</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="sd">            of the compute_gradients Session.run() call.</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>    <span class="k">return</span> <span class="p">{</span><span class="n">LEARNER_STATS_KEY</span><span class="p">:</span> <span class="p">{}}</span>  <span class="c1"># e.g, stats, td error, etc.</span>
</code></pre></div>
        </details>
    </div>

  </div>




  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.tf_policy.TFPolicy.get_exploration_state">
<code class="highlight language-python"><span class="n">get_exploration_state</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Returns the state of this Policy's exploration component.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Dict[str, Any]</code></td>
      <td><p>Serializable information on the <code>self.exploration</code> object.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/tf_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="k">def</span> <span class="nf">get_exploration_state</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]:</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">exploration</span><span class="o">.</span><span class="n">get_state</span><span class="p">(</span><span class="n">sess</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">get_session</span><span class="p">())</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.tf_policy.TFPolicy.get_placeholder">
<code class="highlight language-python"><span class="n">get_placeholder</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Returns the given action or loss input placeholder by name.</p>
<p>If the loss has not been initialized and a loss input placeholder is
requested, an error is raised.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>name</code></td>
        <td><code>str</code></td>
        <td><p>The name of the placeholder to return. One of
SampleBatch.CUR_OBS|PREV_ACTION/REWARD or a valid key from
<code>self._loss_input_dict</code>.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>tf1.placeholder</code></td>
      <td><p>The placeholder under the given str key.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/tf_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="k">def</span> <span class="nf">get_placeholder</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;tf1.placeholder&quot;</span><span class="p">:</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a>    <span class="sd">&quot;&quot;&quot;Returns the given action or loss input placeholder by name.</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="sd">    If the loss has not been initialized and a loss input placeholder is</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="sd">    requested, an error is raised.</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="sd">        name (str): The name of the placeholder to return. One of</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="sd">            SampleBatch.CUR_OBS|PREV_ACTION/REWARD or a valid key from</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="sd">            `self._loss_input_dict`.</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a><span class="sd">        tf1.placeholder: The placeholder under the given str key.</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>    <span class="k">if</span> <span class="n">name</span> <span class="o">==</span> <span class="n">SampleBatch</span><span class="o">.</span><span class="n">CUR_OBS</span><span class="p">:</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_obs_input</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>    <span class="k">elif</span> <span class="n">name</span> <span class="o">==</span> <span class="n">SampleBatch</span><span class="o">.</span><span class="n">PREV_ACTIONS</span><span class="p">:</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prev_action_input</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a>    <span class="k">elif</span> <span class="n">name</span> <span class="o">==</span> <span class="n">SampleBatch</span><span class="o">.</span><span class="n">PREV_REWARDS</span><span class="p">:</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prev_reward_input</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a>    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss_input_dict</span><span class="p">,</span> \
<a id="__codelineno-0-23" name="__codelineno-0-23"></a>        <span class="s2">&quot;You need to populate `self._loss_input_dict` before &quot;</span> \
<a id="__codelineno-0-24" name="__codelineno-0-24"></a>        <span class="s2">&quot;`get_placeholder()` can be called&quot;</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss_input_dict</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.tf_policy.TFPolicy.get_session">
<code class="highlight language-python"><span class="n">get_session</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Returns a reference to the TF session for this policy.</p>

        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/tf_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">get_session</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;tf1.Session&quot;</span><span class="p">]:</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="sd">&quot;&quot;&quot;Returns a reference to the TF session for this policy.&quot;&quot;&quot;</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sess</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.tf_policy.TFPolicy.get_state">
<code class="highlight language-python"><span class="n">get_state</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Returns the entire current state of this Policy.</p>
<p>Note: Not to be confused with an RNN model's internal state.
State includes the Model(s)' weights, optimizer weights,
the exploration component's state, as well as global variables, such
as sampling timesteps.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Union[Dict[str, Any], List[Any]]</code></td>
      <td><p>Serialized local state.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/tf_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="k">def</span> <span class="nf">get_state</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]]:</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="c1"># For tf Policies, return Policy weights and optimizer var values.</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>    <span class="n">state</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_state</span><span class="p">()</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_variables</span><span class="o">.</span><span class="n">variables</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>        <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_optimizer_variables&quot;</span><span class="p">]</span> <span class="o">=</span> \
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_variables</span><span class="o">.</span><span class="n">variables</span><span class="p">)</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>    <span class="c1"># Add exploration state.</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>    <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_exploration_state&quot;</span><span class="p">]</span> <span class="o">=</span> \
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">exploration</span><span class="o">.</span><span class="n">get_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_session</span><span class="p">())</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>    <span class="k">return</span> <span class="n">state</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.tf_policy.TFPolicy.get_weights">
<code class="highlight language-python"><span class="n">get_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Returns model weights.</p>
<p>Note: The return value of this method will reside under the "weights"
key in the return value of Policy.get_state(). Model weights are only
one part of a Policy's state. Other state information contains:
optimizer variables, exploration state, and global state vars such as
the sampling timestep.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Union[Dict[str, Any], List[Any]]</code></td>
      <td><p>Serializable copy or view of model weights.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/tf_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="k">def</span> <span class="nf">get_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]]:</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_variables</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.tf_policy.TFPolicy.gradients">
<code class="highlight language-python"><span class="n">gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Override this for a custom gradient computation behavior.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>optimizer</code></td>
        <td><code>Union[LocalOptimizer, List[LocalOptimizer]]</code></td>
        <td><p>A single
LocalOptimizer of a list thereof to use for gradient
calculations. If more than one optimizer given, the number of
optimizers must match the number of losses provided.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>loss</code></td>
        <td><code>Union[TensorType, List[TensorType]]</code></td>
        <td><p>A single loss term
or a list thereof to use for gradient calculations.
If more than one loss given, the number of loss terms must
match the number of optimizers provided.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Union[List[ModelGradients], List[List[ModelGradients]]]</code></td>
      <td><p>List of
    ModelGradients (grads and vars OR just grads) OR List of List
    of ModelGradients in case we have more than one
    optimizer/loss.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/tf_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">gradients</span><span class="p">(</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>        <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>        <span class="n">optimizer</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">LocalOptimizer</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">LocalOptimizer</span><span class="p">]],</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>        <span class="n">loss</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">TensorType</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]],</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">ModelGradients</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">ModelGradients</span><span class="p">]]]:</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>    <span class="sd">&quot;&quot;&quot;Override this for a custom gradient computation behavior.</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a><span class="sd">        optimizer (Union[LocalOptimizer, List[LocalOptimizer]]): A single</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a><span class="sd">            LocalOptimizer of a list thereof to use for gradient</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a><span class="sd">            calculations. If more than one optimizer given, the number of</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a><span class="sd">            optimizers must match the number of losses provided.</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a><span class="sd">        loss (Union[TensorType, List[TensorType]]): A single loss term</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a><span class="sd">            or a list thereof to use for gradient calculations.</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a><span class="sd">            If more than one loss given, the number of loss terms must</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a><span class="sd">            match the number of optimizers provided.</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a><span class="sd">        Union[List[ModelGradients], List[List[ModelGradients]]]: List of</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a><span class="sd">            ModelGradients (grads and vars OR just grads) OR List of List</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a><span class="sd">            of ModelGradients in case we have more than one</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a><span class="sd">            optimizer/loss.</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a>    <span class="n">optimizers</span> <span class="o">=</span> <span class="n">force_list</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a>    <span class="n">losses</span> <span class="o">=</span> <span class="n">force_list</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a>    <span class="c1"># We have more than one optimizers and loss terms.</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;_tf_policy_handles_more_than_one_loss&quot;</span><span class="p">]:</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a>        <span class="n">grads</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a>        <span class="k">for</span> <span class="n">optim</span><span class="p">,</span> <span class="n">loss_</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">optimizers</span><span class="p">,</span> <span class="n">losses</span><span class="p">):</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a>            <span class="n">grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">optim</span><span class="o">.</span><span class="n">compute_gradients</span><span class="p">(</span><span class="n">loss_</span><span class="p">))</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a>    <span class="c1"># We have only one optimizer and one loss term.</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a>        <span class="k">return</span> <span class="n">optimizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">compute_gradients</span><span class="p">(</span><span class="n">losses</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.tf_policy.TFPolicy.import_model_from_h5">
<code class="highlight language-python"><span class="n">import_model_from_h5</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">import_file</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Imports weights into tf model.</p>

        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/tf_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="k">def</span> <span class="nf">import_model_from_h5</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">import_file</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="sd">&quot;&quot;&quot;Imports weights into tf model.&quot;&quot;&quot;</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;No `self.model` to import into!&quot;</span><span class="p">)</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>    <span class="c1"># Make sure the session is the right one (see issue #7046).</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">import_from_h5</span><span class="p">(</span><span class="n">import_file</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.tf_policy.TFPolicy.is_recurrent">
<code class="highlight language-python"><span class="n">is_recurrent</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Whether this Policy holds a recurrent Model.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>bool</code></td>
      <td><p>True if this Policy has-a RNN-based Model.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/tf_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="k">def</span> <span class="nf">is_recurrent</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_state_inputs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.tf_policy.TFPolicy.learn_on_batch">
<code class="highlight language-python"><span class="n">learn_on_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">postprocessed_batch</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Perform one learning update, given <code>samples</code>.</p>
<p>Either this method or the combination of <code>compute_gradients</code> and
<code>apply_gradients</code> must be implemented by subclasses.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>samples</code></td>
        <td></td>
        <td><p>The SampleBatch object to learn from.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Dict[str, Any]</code></td>
      <td><p>Dictionary of extra metadata from <code>compute_gradients()</code>.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Examples:</strong></p>
    <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">sample_batch</span> <span class="o">=</span> <span class="n">ev</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">ev</span><span class="o">.</span><span class="n">learn_on_batch</span><span class="p">(</span><span class="n">sample_batch</span><span class="p">)</span>
</code></pre></div>

        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/tf_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="k">def</span> <span class="nf">learn_on_batch</span><span class="p">(</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">postprocessed_batch</span><span class="p">:</span> <span class="n">SampleBatch</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]:</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_initialized</span><span class="p">()</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>    <span class="c1"># Switch on is_training flag in our batch.</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>    <span class="n">postprocessed_batch</span><span class="o">.</span><span class="n">set_training</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>    <span class="n">builder</span> <span class="o">=</span> <span class="n">TFRunBuilder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_session</span><span class="p">(),</span> <span class="s2">&quot;learn_on_batch&quot;</span><span class="p">)</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>    <span class="c1"># Callback handling.</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>    <span class="n">learn_stats</span> <span class="o">=</span> <span class="p">{}</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">on_learn_on_batch</span><span class="p">(</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>        <span class="n">policy</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_batch</span><span class="o">=</span><span class="n">postprocessed_batch</span><span class="p">,</span> <span class="n">result</span><span class="o">=</span><span class="n">learn_stats</span><span class="p">)</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>    <span class="n">fetches</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_learn_on_batch</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">postprocessed_batch</span><span class="p">)</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a>    <span class="n">stats</span> <span class="o">=</span> <span class="n">builder</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">fetches</span><span class="p">)</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a>    <span class="n">stats</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;custom_metrics&quot;</span><span class="p">:</span> <span class="n">learn_stats</span><span class="p">})</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a>    <span class="k">return</span> <span class="n">stats</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.tf_policy.TFPolicy.loss_initialized">
<code class="highlight language-python"><span class="n">loss_initialized</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Returns whether the loss term(s) have been initialized.</p>

        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/tf_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="k">def</span> <span class="nf">loss_initialized</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a>    <span class="sd">&quot;&quot;&quot;Returns whether the loss term(s) have been initialized.&quot;&quot;&quot;</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_losses</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.tf_policy.TFPolicy.num_state_tensors">
<code class="highlight language-python"><span class="n">num_state_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>The number of internal states needed by the RNN-Model of the Policy.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>int</code></td>
      <td><p>The number of RNN internal states kept by this Policy's Model.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/tf_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="k">def</span> <span class="nf">num_state_tensors</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_state_inputs</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.tf_policy.TFPolicy.optimizer">
<code class="highlight language-python"><span class="n">optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>TF optimizer to use for policy optimization.</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>tf.keras.optimizers.Optimizer</code></td>
      <td><p>The local optimizer to use for this
    Policy's Model.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/tf_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;tf.keras.optimizers.Optimizer&quot;</span><span class="p">:</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="sd">&quot;&quot;&quot;TF optimizer to use for policy optimization.</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a><span class="sd">        tf.keras.optimizers.Optimizer: The local optimizer to use for this</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="sd">            Policy&#39;s Model.</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;config&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="s2">&quot;lr&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">:</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>        <span class="k">return</span> <span class="n">tf1</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">])</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>        <span class="k">return</span> <span class="n">tf1</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">()</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.tf_policy.TFPolicy.set_state">
<code class="highlight language-python"><span class="n">set_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Restores the entire current state of this Policy from <code>state</code>.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>state</code></td>
        <td><code>dict</code></td>
        <td><p>The new state to set this policy to. Can be
obtained by calling <code>self.get_state()</code>.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/tf_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="k">def</span> <span class="nf">set_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="c1"># Set optimizer vars first.</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>    <span class="n">optimizer_vars</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_optimizer_variables&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>    <span class="k">if</span> <span class="n">optimizer_vars</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer_variables</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">optimizer_vars</span><span class="p">)</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>    <span class="c1"># Set exploration&#39;s state.</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;exploration&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="s2">&quot;_exploration_state&quot;</span> <span class="ow">in</span> <span class="n">state</span><span class="p">:</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">exploration</span><span class="o">.</span><span class="n">set_state</span><span class="p">(</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>            <span class="n">state</span><span class="o">=</span><span class="n">state</span><span class="p">[</span><span class="s2">&quot;_exploration_state&quot;</span><span class="p">],</span> <span class="n">sess</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">get_session</span><span class="p">())</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>    <span class="c1"># Set the Policy&#39;s (NN) weights.</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">set_state</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.tf_policy.TFPolicy.set_weights">
<code class="highlight language-python"><span class="n">set_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Sets this Policy's model's weights.</p>
<p>Note: Model weights are only one part of a Policy's state. Other
state information contains: optimizer variables, exploration state,
and global state vars such as the sampling timestep.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>weights</code></td>
        <td></td>
        <td><p>Serializable copy or view of model weights.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/tf_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="k">def</span> <span class="nf">set_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_variables</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 class="doc doc-heading" id="ray.rllib.policy.tf_policy.TFPolicy.variables">
<code class="highlight language-python"><span class="n">variables</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Return the list of all savable variables for this policy.</p>

        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/tf_policy.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="k">def</span> <span class="nf">variables</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a>    <span class="sd">&quot;&quot;&quot;Return the list of all savable variables for this policy.&quot;&quot;&quot;</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;No `self.model` to get variables for!&quot;</span><span class="p">)</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">variables</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">variables</span><span class="p">()</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>



  <div class="doc doc-object doc-function">



<h2 class="doc doc-heading" id="ray.rllib.policy.policy_template.build_policy_class">
<code class="highlight language-python"><span class="n">ray</span><span class="o">.</span><span class="n">rllib</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">policy_template</span><span class="o">.</span><span class="n">build_policy_class</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">framework</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">get_default_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stats_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">postprocess_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">extra_action_out_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">extra_grad_process_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">extra_learn_fetches_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">optimizer_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">validate_spaces</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">before_init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">before_loss_init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">after_init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_after_loss_init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">action_sampler_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">action_distribution_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">make_model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">make_model_and_action_dist</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">compute_gradients_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">apply_gradients_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mixins</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">get_batch_divisibility_req</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>


</h2>

    <div class="doc doc-contents first">

      <p>Helper function for creating a new Policy class at runtime.</p>
<p>Supports frameworks JAX and PyTorch.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>name</code></td>
        <td><code>str</code></td>
        <td><p>name of the policy (e.g., "PPOTorchPolicy")</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>framework</code></td>
        <td><code>str</code></td>
        <td><p>Either "jax" or "torch".</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>loss_fn</code></td>
        <td><code>Optional[Callable[[Policy, ModelV2,
Type[TorchDistributionWrapper], SampleBatch], Union[TensorType,
List[TensorType]]]]</code></td>
        <td><p>Callable that returns a loss tensor.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>get_default_config</code></td>
        <td><code>Optional[Callable[[None], TrainerConfigDict]]</code></td>
        <td><p>Optional callable that returns the default config to merge with any
overrides. If None, uses only(!) the user-provided
PartialTrainerConfigDict as dict for this Policy.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>postprocess_fn</code></td>
        <td><code>Optional[Callable[[Policy, SampleBatch,
Optional[Dict[Any, SampleBatch]], Optional[&#34;Episode&#34;]],
SampleBatch]]</code></td>
        <td><p>Optional callable for post-processing experience
batches (called after the super's <code>postprocess_trajectory</code> method).</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>stats_fn</code></td>
        <td><code>Optional[Callable[[Policy, SampleBatch],
Dict[str, TensorType]]]</code></td>
        <td><p>Optional callable that returns a dict of
values given the policy and training batch. If None,
will use <code>TorchPolicy.extra_grad_info()</code> instead. The stats dict is
used for logging (e.g. in TensorBoard).</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>extra_action_out_fn</code></td>
        <td><code>Optional[Callable[[Policy, Dict[str, TensorType],
List[TensorType], ModelV2, TorchDistributionWrapper]], Dict[str,
TensorType]]]</code></td>
        <td><p>Optional callable that returns a dict of extra
values to include in experiences. If None, no extra computations
will be performed.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>extra_grad_process_fn</code></td>
        <td><code>Optional[Callable[[Policy,
&#34;torch.optim.Optimizer&#34;, TensorType], Dict[str, TensorType]]]</code></td>
        <td><p>Optional callable that is called after gradients are computed and
returns a processing info dict. If None, will call the
<code>TorchPolicy.extra_grad_process()</code> method instead.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>#</code></td>
        <td><code>TODO</code></td>
        <td><p>(sven) dissolve naming mismatch between "learn" and "compute.."</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>extra_learn_fetches_fn</code></td>
        <td><code>Optional[Callable[[Policy],
Dict[str, TensorType]]]</code></td>
        <td><p>Optional callable that returns a dict of
extra tensors from the policy after loss evaluation. If None,
will call the <code>TorchPolicy.extra_compute_grad_fetches()</code> method
instead.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>optimizer_fn</code></td>
        <td><code>Optional[Callable[[Policy, TrainerConfigDict],
&#34;torch.optim.Optimizer&#34;]]</code></td>
        <td><p>Optional callable that returns a
torch optimizer given the policy and config. If None, will call
the <code>TorchPolicy.optimizer()</code> method instead (which returns a
torch Adam optimizer).</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>validate_spaces</code></td>
        <td><code>Optional[Callable[[Policy, gym.Space, gym.Space,
TrainerConfigDict], None]]</code></td>
        <td><p>Optional callable that takes the
Policy, observation_space, action_space, and config to check for
correctness. If None, no spaces checking will be done.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>before_init</code></td>
        <td><code>Optional[Callable[[Policy, gym.Space, gym.Space,
TrainerConfigDict], None]]</code></td>
        <td><p>Optional callable to run at the
beginning of <code>Policy.__init__</code> that takes the same arguments as
the Policy constructor. If None, this step will be skipped.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>before_loss_init</code></td>
        <td><code>Optional[Callable[[Policy, gym.spaces.Space,
gym.spaces.Space, TrainerConfigDict], None]]</code></td>
        <td><p>Optional callable to
run prior to loss init. If None, this step will be skipped.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>after_init</code></td>
        <td><code>Optional[Callable[[Policy, gym.Space, gym.Space,
TrainerConfigDict], None]]</code></td>
        <td><p>instead.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>_after_loss_init</code></td>
        <td><code>Optional[Callable[[Policy, gym.spaces.Space,
gym.spaces.Space, TrainerConfigDict], None]]</code></td>
        <td><p>Optional callable to
run after the loss init. If None, this step will be skipped.
This will be deprecated at some point and renamed into <code>after_init</code>
to match <code>build_tf_policy()</code> behavior.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>action_sampler_fn</code></td>
        <td><code>Optional[Callable[[TensorType, List[TensorType]],
Tuple[TensorType, TensorType]]]</code></td>
        <td><p>Optional callable returning a
sampled action and its log-likelihood given some (obs and state)
inputs. If None, will either use <code>action_distribution_fn</code> or
compute actions by calling self.model, then sampling from the
so parameterized action distribution.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>action_distribution_fn</code></td>
        <td><code>Optional[Callable[[Policy, ModelV2, TensorType,
TensorType, TensorType], Tuple[TensorType,
Type[TorchDistributionWrapper], List[TensorType]]]]</code></td>
        <td><p>A callable
that takes the Policy, Model, the observation batch, an
explore-flag, a timestep, and an is_training flag and returns a
tuple of a) distribution inputs (parameters), b) a dist-class to
generate an action distribution object from, and c) internal-state
outputs (empty list if not applicable). If None, will either use
<code>action_sampler_fn</code> or compute actions by calling self.model,
then sampling from the parameterized action distribution.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>make_model</code></td>
        <td><code>Optional[Callable[[Policy, gym.spaces.Space,
gym.spaces.Space, TrainerConfigDict], ModelV2]]</code></td>
        <td><p>Optional callable
that takes the same arguments as Policy.<strong>init</strong> and returns a
model instance. The distribution class will be determined
automatically. Note: Only one of <code>make_model</code> or
<code>make_model_and_action_dist</code> should be provided. If both are None,
a default Model will be created.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>make_model_and_action_dist</code></td>
        <td><code>Optional[Callable[[Policy,
gym.spaces.Space, gym.spaces.Space, TrainerConfigDict],
Tuple[ModelV2, Type[TorchDistributionWrapper]]]]</code></td>
        <td><p>Optional
callable that takes the same arguments as Policy.<strong>init</strong> and
returns a tuple of model instance and torch action distribution
class.
Note: Only one of <code>make_model</code> or <code>make_model_and_action_dist</code>
should be provided. If both are None, a default Model will be
created.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>compute_gradients_fn</code></td>
        <td><code>Optional[Callable[
[Policy, SampleBatch], Tuple[ModelGradients, dict]]]</code></td>
        <td><p>Optional
callable that the sampled batch an computes the gradients w.r.
to the loss function.
If None, will call the <code>TorchPolicy.compute_gradients()</code> method
instead.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>apply_gradients_fn</code></td>
        <td><code>Optional[Callable[[Policy,
&#34;torch.optim.Optimizer&#34;], None]]</code></td>
        <td><p>Optional callable that
takes a grads list and applies these to the Model's parameters.
If None, will call the <code>TorchPolicy.apply_gradients()</code> method
instead.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>mixins</code></td>
        <td><code>Optional[List[type]]</code></td>
        <td><p>Optional list of any class mixins for
the returned policy class. These mixins will be applied in order
and will have higher precedence than the TorchPolicy class.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>get_batch_divisibility_req</code></td>
        <td><code>Optional[Callable[[Policy], int]]</code></td>
        <td><p>Optional callable that returns the divisibility requirement for
sample batches. If None, will assume a value of 1.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Type[TorchPolicy]</code></td>
      <td><p>TorchPolicy child class constructed from the
    specified args.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/policy_template.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">build_policy_class</span><span class="p">(</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>        <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>        <span class="n">framework</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>        <span class="o">*</span><span class="p">,</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>        <span class="n">loss_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>            <span class="n">Policy</span><span class="p">,</span> <span class="n">ModelV2</span><span class="p">,</span> <span class="n">Type</span><span class="p">[</span><span class="n">TorchDistributionWrapper</span><span class="p">],</span> <span class="n">SampleBatch</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>        <span class="p">],</span> <span class="n">Union</span><span class="p">[</span><span class="n">TensorType</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]]]],</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>        <span class="n">get_default_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[],</span> <span class="n">TrainerConfigDict</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>        <span class="n">stats_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Policy</span><span class="p">,</span> <span class="n">SampleBatch</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>            <span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>        <span class="n">postprocess_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>            <span class="n">Policy</span><span class="p">,</span> <span class="n">SampleBatch</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">SampleBatch</span><span class="p">]],</span> <span class="n">Optional</span><span class="p">[</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>                <span class="s2">&quot;Episode&quot;</span><span class="p">]</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>        <span class="p">],</span> <span class="n">SampleBatch</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a>        <span class="n">extra_action_out_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>            <span class="n">Policy</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">],</span> <span class="n">ModelV2</span><span class="p">,</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a>            <span class="n">TorchDistributionWrapper</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a>        <span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a>        <span class="n">extra_grad_process_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a>            <span class="n">Policy</span><span class="p">,</span> <span class="s2">&quot;torch.optim.Optimizer&quot;</span><span class="p">,</span> <span class="n">TensorType</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a>        <span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a>        <span class="c1"># TODO: (sven) Replace &quot;fetches&quot; with &quot;process&quot;.</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a>        <span class="n">extra_learn_fetches_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Policy</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a>            <span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a>        <span class="n">optimizer_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Policy</span><span class="p">,</span> <span class="n">TrainerConfigDict</span><span class="p">],</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a>                                        <span class="s2">&quot;torch.optim.Optimizer&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a>        <span class="n">validate_spaces</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a>            <span class="p">[</span><span class="n">Policy</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span> <span class="n">TrainerConfigDict</span><span class="p">],</span> <span class="kc">None</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a>        <span class="n">before_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a>            <span class="p">[</span><span class="n">Policy</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span> <span class="n">TrainerConfigDict</span><span class="p">],</span> <span class="kc">None</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a>        <span class="n">before_loss_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a>            <span class="n">Policy</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span> <span class="n">TrainerConfigDict</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a>        <span class="p">],</span> <span class="kc">None</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a>        <span class="n">after_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a>            <span class="p">[</span><span class="n">Policy</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span> <span class="n">TrainerConfigDict</span><span class="p">],</span> <span class="kc">None</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a>        <span class="n">_after_loss_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a>            <span class="n">Policy</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span> <span class="n">TrainerConfigDict</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>        <span class="p">],</span> <span class="kc">None</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a>        <span class="n">action_sampler_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">TensorType</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a>            <span class="n">TensorType</span><span class="p">]],</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">TensorType</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a>        <span class="n">action_distribution_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a>            <span class="n">Policy</span><span class="p">,</span> <span class="n">ModelV2</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">,</span> <span class="n">TensorType</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>        <span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">TensorType</span><span class="p">,</span> <span class="nb">type</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a>        <span class="n">make_model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>            <span class="n">Policy</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span> <span class="n">TrainerConfigDict</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a>        <span class="p">],</span> <span class="n">ModelV2</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a>        <span class="n">make_model_and_action_dist</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a>            <span class="n">Policy</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span> <span class="n">TrainerConfigDict</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a>        <span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">ModelV2</span><span class="p">,</span> <span class="n">Type</span><span class="p">[</span><span class="n">TorchDistributionWrapper</span><span class="p">]]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a>        <span class="n">compute_gradients_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Policy</span><span class="p">,</span> <span class="n">SampleBatch</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a>            <span class="n">ModelGradients</span><span class="p">,</span> <span class="nb">dict</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a>        <span class="n">apply_gradients_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a>            <span class="p">[</span><span class="n">Policy</span><span class="p">,</span> <span class="s2">&quot;torch.optim.Optimizer&quot;</span><span class="p">],</span> <span class="kc">None</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a>        <span class="n">mixins</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">type</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a>        <span class="n">get_batch_divisibility_req</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Policy</span><span class="p">],</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Type</span><span class="p">[</span><span class="n">TorchPolicy</span><span class="p">]:</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a>    <span class="sd">&quot;&quot;&quot;Helper function for creating a new Policy class at runtime.</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a><span class="sd">    Supports frameworks JAX and PyTorch.</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a><span class="sd">        name (str): name of the policy (e.g., &quot;PPOTorchPolicy&quot;)</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a><span class="sd">        framework (str): Either &quot;jax&quot; or &quot;torch&quot;.</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a><span class="sd">        loss_fn (Optional[Callable[[Policy, ModelV2,</span>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a><span class="sd">            Type[TorchDistributionWrapper], SampleBatch], Union[TensorType,</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a><span class="sd">            List[TensorType]]]]): Callable that returns a loss tensor.</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a><span class="sd">        get_default_config (Optional[Callable[[None], TrainerConfigDict]]):</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a><span class="sd">            Optional callable that returns the default config to merge with any</span>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a><span class="sd">            overrides. If None, uses only(!) the user-provided</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a><span class="sd">            PartialTrainerConfigDict as dict for this Policy.</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a><span class="sd">        postprocess_fn (Optional[Callable[[Policy, SampleBatch,</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a><span class="sd">            Optional[Dict[Any, SampleBatch]], Optional[&quot;Episode&quot;]],</span>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a><span class="sd">            SampleBatch]]): Optional callable for post-processing experience</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a><span class="sd">            batches (called after the super&#39;s `postprocess_trajectory` method).</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a><span class="sd">        stats_fn (Optional[Callable[[Policy, SampleBatch],</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a><span class="sd">            Dict[str, TensorType]]]): Optional callable that returns a dict of</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a><span class="sd">            values given the policy and training batch. If None,</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a><span class="sd">            will use `TorchPolicy.extra_grad_info()` instead. The stats dict is</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a><span class="sd">            used for logging (e.g. in TensorBoard).</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a><span class="sd">        extra_action_out_fn (Optional[Callable[[Policy, Dict[str, TensorType],</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a><span class="sd">            List[TensorType], ModelV2, TorchDistributionWrapper]], Dict[str,</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a><span class="sd">            TensorType]]]): Optional callable that returns a dict of extra</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a><span class="sd">            values to include in experiences. If None, no extra computations</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a><span class="sd">            will be performed.</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a><span class="sd">        extra_grad_process_fn (Optional[Callable[[Policy,</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a><span class="sd">            &quot;torch.optim.Optimizer&quot;, TensorType], Dict[str, TensorType]]]):</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a><span class="sd">            Optional callable that is called after gradients are computed and</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a><span class="sd">            returns a processing info dict. If None, will call the</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a><span class="sd">            `TorchPolicy.extra_grad_process()` method instead.</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a><span class="sd">        # TODO: (sven) dissolve naming mismatch between &quot;learn&quot; and &quot;compute..&quot;</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a><span class="sd">        extra_learn_fetches_fn (Optional[Callable[[Policy],</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a><span class="sd">            Dict[str, TensorType]]]): Optional callable that returns a dict of</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a><span class="sd">            extra tensors from the policy after loss evaluation. If None,</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a><span class="sd">            will call the `TorchPolicy.extra_compute_grad_fetches()` method</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a><span class="sd">            instead.</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a><span class="sd">        optimizer_fn (Optional[Callable[[Policy, TrainerConfigDict],</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a><span class="sd">            &quot;torch.optim.Optimizer&quot;]]): Optional callable that returns a</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a><span class="sd">            torch optimizer given the policy and config. If None, will call</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a><span class="sd">            the `TorchPolicy.optimizer()` method instead (which returns a</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a><span class="sd">            torch Adam optimizer).</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a><span class="sd">        validate_spaces (Optional[Callable[[Policy, gym.Space, gym.Space,</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a><span class="sd">            TrainerConfigDict], None]]): Optional callable that takes the</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a><span class="sd">            Policy, observation_space, action_space, and config to check for</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a><span class="sd">            correctness. If None, no spaces checking will be done.</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a><span class="sd">        before_init (Optional[Callable[[Policy, gym.Space, gym.Space,</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a><span class="sd">            TrainerConfigDict], None]]): Optional callable to run at the</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a><span class="sd">            beginning of `Policy.__init__` that takes the same arguments as</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a><span class="sd">            the Policy constructor. If None, this step will be skipped.</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a><span class="sd">        before_loss_init (Optional[Callable[[Policy, gym.spaces.Space,</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a><span class="sd">            gym.spaces.Space, TrainerConfigDict], None]]): Optional callable to</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a><span class="sd">            run prior to loss init. If None, this step will be skipped.</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a><span class="sd">        after_init (Optional[Callable[[Policy, gym.Space, gym.Space,</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a><span class="sd">            TrainerConfigDict], None]]): DEPRECATED: Use `before_loss_init`</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a><span class="sd">            instead.</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a><span class="sd">        _after_loss_init (Optional[Callable[[Policy, gym.spaces.Space,</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a><span class="sd">            gym.spaces.Space, TrainerConfigDict], None]]): Optional callable to</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a><span class="sd">            run after the loss init. If None, this step will be skipped.</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a><span class="sd">            This will be deprecated at some point and renamed into `after_init`</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a><span class="sd">            to match `build_tf_policy()` behavior.</span>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a><span class="sd">        action_sampler_fn (Optional[Callable[[TensorType, List[TensorType]],</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a><span class="sd">            Tuple[TensorType, TensorType]]]): Optional callable returning a</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a><span class="sd">            sampled action and its log-likelihood given some (obs and state)</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a><span class="sd">            inputs. If None, will either use `action_distribution_fn` or</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a><span class="sd">            compute actions by calling self.model, then sampling from the</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a><span class="sd">            so parameterized action distribution.</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a><span class="sd">        action_distribution_fn (Optional[Callable[[Policy, ModelV2, TensorType,</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a><span class="sd">            TensorType, TensorType], Tuple[TensorType,</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a><span class="sd">            Type[TorchDistributionWrapper], List[TensorType]]]]): A callable</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a><span class="sd">            that takes the Policy, Model, the observation batch, an</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a><span class="sd">            explore-flag, a timestep, and an is_training flag and returns a</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a><span class="sd">            tuple of a) distribution inputs (parameters), b) a dist-class to</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a><span class="sd">            generate an action distribution object from, and c) internal-state</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a><span class="sd">            outputs (empty list if not applicable). If None, will either use</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a><span class="sd">            `action_sampler_fn` or compute actions by calling self.model,</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a><span class="sd">            then sampling from the parameterized action distribution.</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a><span class="sd">        make_model (Optional[Callable[[Policy, gym.spaces.Space,</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a><span class="sd">            gym.spaces.Space, TrainerConfigDict], ModelV2]]): Optional callable</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a><span class="sd">            that takes the same arguments as Policy.__init__ and returns a</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a><span class="sd">            model instance. The distribution class will be determined</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a><span class="sd">            automatically. Note: Only one of `make_model` or</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a><span class="sd">            `make_model_and_action_dist` should be provided. If both are None,</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a><span class="sd">            a default Model will be created.</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a><span class="sd">        make_model_and_action_dist (Optional[Callable[[Policy,</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a><span class="sd">            gym.spaces.Space, gym.spaces.Space, TrainerConfigDict],</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a><span class="sd">            Tuple[ModelV2, Type[TorchDistributionWrapper]]]]): Optional</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a><span class="sd">            callable that takes the same arguments as Policy.__init__ and</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a><span class="sd">            returns a tuple of model instance and torch action distribution</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a><span class="sd">            class.</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a><span class="sd">            Note: Only one of `make_model` or `make_model_and_action_dist`</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a><span class="sd">            should be provided. If both are None, a default Model will be</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a><span class="sd">            created.</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a><span class="sd">        compute_gradients_fn (Optional[Callable[</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a><span class="sd">            [Policy, SampleBatch], Tuple[ModelGradients, dict]]]): Optional</span>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a><span class="sd">            callable that the sampled batch an computes the gradients w.r.</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a><span class="sd">            to the loss function.</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a><span class="sd">            If None, will call the `TorchPolicy.compute_gradients()` method</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a><span class="sd">            instead.</span>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a><span class="sd">        apply_gradients_fn (Optional[Callable[[Policy,</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a><span class="sd">            &quot;torch.optim.Optimizer&quot;], None]]): Optional callable that</span>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a><span class="sd">            takes a grads list and applies these to the Model&#39;s parameters.</span>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a><span class="sd">            If None, will call the `TorchPolicy.apply_gradients()` method</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a><span class="sd">            instead.</span>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a><span class="sd">        mixins (Optional[List[type]]): Optional list of any class mixins for</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a><span class="sd">            the returned policy class. These mixins will be applied in order</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a><span class="sd">            and will have higher precedence than the TorchPolicy class.</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a><span class="sd">        get_batch_divisibility_req (Optional[Callable[[Policy], int]]):</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a><span class="sd">            Optional callable that returns the divisibility requirement for</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a><span class="sd">            sample batches. If None, will assume a value of 1.</span>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a><span class="sd">        Type[TorchPolicy]: TorchPolicy child class constructed from the</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a><span class="sd">            specified args.</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a>    <span class="n">original_kwargs</span> <span class="o">=</span> <span class="nb">locals</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a>    <span class="n">parent_cls</span> <span class="o">=</span> <span class="n">TorchPolicy</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a>    <span class="n">base</span> <span class="o">=</span> <span class="n">add_mixins</span><span class="p">(</span><span class="n">parent_cls</span><span class="p">,</span> <span class="n">mixins</span><span class="p">)</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a>    <span class="k">class</span> <span class="nc">policy_cls</span><span class="p">(</span><span class="n">base</span><span class="p">):</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a>        <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs_space</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a>            <span class="c1"># Set up the config from possible default-config fn and given</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a>            <span class="c1"># config arg.</span>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a>            <span class="k">if</span> <span class="n">get_default_config</span><span class="p">:</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a>                <span class="n">config</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">get_default_config</span><span class="p">(),</span> <span class="o">**</span><span class="n">config</span><span class="p">)</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a>            <span class="c1"># Set the DL framework for this Policy.</span>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">framework</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;framework&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">framework</span>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a>            <span class="c1"># Validate observation- and action-spaces.</span>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a>            <span class="k">if</span> <span class="n">validate_spaces</span><span class="p">:</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a>                <span class="n">validate_spaces</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs_space</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>
<a id="__codelineno-0-194" name="__codelineno-0-194"></a>
<a id="__codelineno-0-195" name="__codelineno-0-195"></a>            <span class="c1"># Do some pre-initialization steps.</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a>            <span class="k">if</span> <span class="n">before_init</span><span class="p">:</span>
<a id="__codelineno-0-197" name="__codelineno-0-197"></a>                <span class="n">before_init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs_space</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>
<a id="__codelineno-0-198" name="__codelineno-0-198"></a>
<a id="__codelineno-0-199" name="__codelineno-0-199"></a>            <span class="c1"># Model is customized (use default action dist class).</span>
<a id="__codelineno-0-200" name="__codelineno-0-200"></a>            <span class="k">if</span> <span class="n">make_model</span><span class="p">:</span>
<a id="__codelineno-0-201" name="__codelineno-0-201"></a>                <span class="k">assert</span> <span class="n">make_model_and_action_dist</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> \
<a id="__codelineno-0-202" name="__codelineno-0-202"></a>                    <span class="s2">&quot;Either `make_model` or `make_model_and_action_dist`&quot;</span> \
<a id="__codelineno-0-203" name="__codelineno-0-203"></a>                    <span class="s2">&quot; must be None!&quot;</span>
<a id="__codelineno-0-204" name="__codelineno-0-204"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">make_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs_space</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>
<a id="__codelineno-0-205" name="__codelineno-0-205"></a>                <span class="n">dist_class</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">ModelCatalog</span><span class="o">.</span><span class="n">get_action_dist</span><span class="p">(</span>
<a id="__codelineno-0-206" name="__codelineno-0-206"></a>                    <span class="n">action_space</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">],</span> <span class="n">framework</span><span class="o">=</span><span class="n">framework</span><span class="p">)</span>
<a id="__codelineno-0-207" name="__codelineno-0-207"></a>            <span class="c1"># Model and action dist class are customized.</span>
<a id="__codelineno-0-208" name="__codelineno-0-208"></a>            <span class="k">elif</span> <span class="n">make_model_and_action_dist</span><span class="p">:</span>
<a id="__codelineno-0-209" name="__codelineno-0-209"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">dist_class</span> <span class="o">=</span> <span class="n">make_model_and_action_dist</span><span class="p">(</span>
<a id="__codelineno-0-210" name="__codelineno-0-210"></a>                    <span class="bp">self</span><span class="p">,</span> <span class="n">obs_space</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>
<a id="__codelineno-0-211" name="__codelineno-0-211"></a>            <span class="c1"># Use default model and default action dist.</span>
<a id="__codelineno-0-212" name="__codelineno-0-212"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-213" name="__codelineno-0-213"></a>                <span class="n">dist_class</span><span class="p">,</span> <span class="n">logit_dim</span> <span class="o">=</span> <span class="n">ModelCatalog</span><span class="o">.</span><span class="n">get_action_dist</span><span class="p">(</span>
<a id="__codelineno-0-214" name="__codelineno-0-214"></a>                    <span class="n">action_space</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">],</span> <span class="n">framework</span><span class="o">=</span><span class="n">framework</span><span class="p">)</span>
<a id="__codelineno-0-215" name="__codelineno-0-215"></a>                <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelCatalog</span><span class="o">.</span><span class="n">get_model_v2</span><span class="p">(</span>
<a id="__codelineno-0-216" name="__codelineno-0-216"></a>                    <span class="n">obs_space</span><span class="o">=</span><span class="n">obs_space</span><span class="p">,</span>
<a id="__codelineno-0-217" name="__codelineno-0-217"></a>                    <span class="n">action_space</span><span class="o">=</span><span class="n">action_space</span><span class="p">,</span>
<a id="__codelineno-0-218" name="__codelineno-0-218"></a>                    <span class="n">num_outputs</span><span class="o">=</span><span class="n">logit_dim</span><span class="p">,</span>
<a id="__codelineno-0-219" name="__codelineno-0-219"></a>                    <span class="n">model_config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">],</span>
<a id="__codelineno-0-220" name="__codelineno-0-220"></a>                    <span class="n">framework</span><span class="o">=</span><span class="n">framework</span><span class="p">)</span>
<a id="__codelineno-0-221" name="__codelineno-0-221"></a>
<a id="__codelineno-0-222" name="__codelineno-0-222"></a>            <span class="c1"># Make sure, we passed in a correct Model factory.</span>
<a id="__codelineno-0-223" name="__codelineno-0-223"></a>            <span class="n">model_cls</span> <span class="o">=</span> <span class="n">TorchModelV2</span> <span class="k">if</span> <span class="n">framework</span> <span class="o">==</span> <span class="s2">&quot;torch&quot;</span> <span class="k">else</span> <span class="n">JAXModelV2</span>
<a id="__codelineno-0-224" name="__codelineno-0-224"></a>            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">model_cls</span><span class="p">),</span> \
<a id="__codelineno-0-225" name="__codelineno-0-225"></a>                <span class="s2">&quot;ERROR: Generated Model must be a TorchModelV2 object!&quot;</span>
<a id="__codelineno-0-226" name="__codelineno-0-226"></a>
<a id="__codelineno-0-227" name="__codelineno-0-227"></a>            <span class="c1"># Call the framework-specific Policy constructor.</span>
<a id="__codelineno-0-228" name="__codelineno-0-228"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">parent_cls</span> <span class="o">=</span> <span class="n">parent_cls</span>
<a id="__codelineno-0-229" name="__codelineno-0-229"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">parent_cls</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-230" name="__codelineno-0-230"></a>                <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-231" name="__codelineno-0-231"></a>                <span class="n">observation_space</span><span class="o">=</span><span class="n">obs_space</span><span class="p">,</span>
<a id="__codelineno-0-232" name="__codelineno-0-232"></a>                <span class="n">action_space</span><span class="o">=</span><span class="n">action_space</span><span class="p">,</span>
<a id="__codelineno-0-233" name="__codelineno-0-233"></a>                <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
<a id="__codelineno-0-234" name="__codelineno-0-234"></a>                <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
<a id="__codelineno-0-235" name="__codelineno-0-235"></a>                <span class="n">loss</span><span class="o">=</span><span class="kc">None</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;in_evaluation&quot;</span><span class="p">]</span> <span class="k">else</span> <span class="n">loss_fn</span><span class="p">,</span>
<a id="__codelineno-0-236" name="__codelineno-0-236"></a>                <span class="n">action_distribution_class</span><span class="o">=</span><span class="n">dist_class</span><span class="p">,</span>
<a id="__codelineno-0-237" name="__codelineno-0-237"></a>                <span class="n">action_sampler_fn</span><span class="o">=</span><span class="n">action_sampler_fn</span><span class="p">,</span>
<a id="__codelineno-0-238" name="__codelineno-0-238"></a>                <span class="n">action_distribution_fn</span><span class="o">=</span><span class="n">action_distribution_fn</span><span class="p">,</span>
<a id="__codelineno-0-239" name="__codelineno-0-239"></a>                <span class="n">max_seq_len</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">][</span><span class="s2">&quot;max_seq_len&quot;</span><span class="p">],</span>
<a id="__codelineno-0-240" name="__codelineno-0-240"></a>                <span class="n">get_batch_divisibility_req</span><span class="o">=</span><span class="n">get_batch_divisibility_req</span><span class="p">,</span>
<a id="__codelineno-0-241" name="__codelineno-0-241"></a>            <span class="p">)</span>
<a id="__codelineno-0-242" name="__codelineno-0-242"></a>
<a id="__codelineno-0-243" name="__codelineno-0-243"></a>            <span class="c1"># Merge Model&#39;s view requirements into Policy&#39;s.</span>
<a id="__codelineno-0-244" name="__codelineno-0-244"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">view_requirements</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">view_requirements</span><span class="p">)</span>
<a id="__codelineno-0-245" name="__codelineno-0-245"></a>
<a id="__codelineno-0-246" name="__codelineno-0-246"></a>            <span class="n">_before_loss_init</span> <span class="o">=</span> <span class="n">before_loss_init</span> <span class="ow">or</span> <span class="n">after_init</span>
<a id="__codelineno-0-247" name="__codelineno-0-247"></a>            <span class="k">if</span> <span class="n">_before_loss_init</span><span class="p">:</span>
<a id="__codelineno-0-248" name="__codelineno-0-248"></a>                <span class="n">_before_loss_init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span><span class="p">,</span>
<a id="__codelineno-0-249" name="__codelineno-0-249"></a>                                  <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>
<a id="__codelineno-0-250" name="__codelineno-0-250"></a>
<a id="__codelineno-0-251" name="__codelineno-0-251"></a>            <span class="c1"># Perform test runs through postprocessing- and loss functions.</span>
<a id="__codelineno-0-252" name="__codelineno-0-252"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_loss_from_dummy_batch</span><span class="p">(</span>
<a id="__codelineno-0-253" name="__codelineno-0-253"></a>                <span class="n">auto_remove_unneeded_view_reqs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-254" name="__codelineno-0-254"></a>                <span class="n">stats_fn</span><span class="o">=</span><span class="kc">None</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;in_evaluation&quot;</span><span class="p">]</span> <span class="k">else</span> <span class="n">stats_fn</span><span class="p">,</span>
<a id="__codelineno-0-255" name="__codelineno-0-255"></a>            <span class="p">)</span>
<a id="__codelineno-0-256" name="__codelineno-0-256"></a>
<a id="__codelineno-0-257" name="__codelineno-0-257"></a>            <span class="k">if</span> <span class="n">_after_loss_init</span><span class="p">:</span>
<a id="__codelineno-0-258" name="__codelineno-0-258"></a>                <span class="n">_after_loss_init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs_space</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>
<a id="__codelineno-0-259" name="__codelineno-0-259"></a>
<a id="__codelineno-0-260" name="__codelineno-0-260"></a>            <span class="c1"># Got to reset global_timestep again after this fake run-through.</span>
<a id="__codelineno-0-261" name="__codelineno-0-261"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">global_timestep</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-262" name="__codelineno-0-262"></a>
<a id="__codelineno-0-263" name="__codelineno-0-263"></a>        <span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-264" name="__codelineno-0-264"></a>        <span class="k">def</span> <span class="nf">postprocess_trajectory</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-265" name="__codelineno-0-265"></a>                                   <span class="n">sample_batch</span><span class="p">,</span>
<a id="__codelineno-0-266" name="__codelineno-0-266"></a>                                   <span class="n">other_agent_batches</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-267" name="__codelineno-0-267"></a>                                   <span class="n">episode</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<a id="__codelineno-0-268" name="__codelineno-0-268"></a>            <span class="c1"># Do all post-processing always with no_grad().</span>
<a id="__codelineno-0-269" name="__codelineno-0-269"></a>            <span class="c1"># Not using this here will introduce a memory leak</span>
<a id="__codelineno-0-270" name="__codelineno-0-270"></a>            <span class="c1"># in torch (issue #6962).</span>
<a id="__codelineno-0-271" name="__codelineno-0-271"></a>            <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_no_grad_context</span><span class="p">():</span>
<a id="__codelineno-0-272" name="__codelineno-0-272"></a>                <span class="c1"># Call super&#39;s postprocess_trajectory first.</span>
<a id="__codelineno-0-273" name="__codelineno-0-273"></a>                <span class="n">sample_batch</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">postprocess_trajectory</span><span class="p">(</span>
<a id="__codelineno-0-274" name="__codelineno-0-274"></a>                    <span class="n">sample_batch</span><span class="p">,</span> <span class="n">other_agent_batches</span><span class="p">,</span> <span class="n">episode</span><span class="p">)</span>
<a id="__codelineno-0-275" name="__codelineno-0-275"></a>                <span class="k">if</span> <span class="n">postprocess_fn</span><span class="p">:</span>
<a id="__codelineno-0-276" name="__codelineno-0-276"></a>                    <span class="k">return</span> <span class="n">postprocess_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_batch</span><span class="p">,</span>
<a id="__codelineno-0-277" name="__codelineno-0-277"></a>                                          <span class="n">other_agent_batches</span><span class="p">,</span> <span class="n">episode</span><span class="p">)</span>
<a id="__codelineno-0-278" name="__codelineno-0-278"></a>
<a id="__codelineno-0-279" name="__codelineno-0-279"></a>                <span class="k">return</span> <span class="n">sample_batch</span>
<a id="__codelineno-0-280" name="__codelineno-0-280"></a>
<a id="__codelineno-0-281" name="__codelineno-0-281"></a>        <span class="nd">@override</span><span class="p">(</span><span class="n">parent_cls</span><span class="p">)</span>
<a id="__codelineno-0-282" name="__codelineno-0-282"></a>        <span class="k">def</span> <span class="nf">extra_grad_process</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">):</span>
<a id="__codelineno-0-283" name="__codelineno-0-283"></a>            <span class="sd">&quot;&quot;&quot;Called after optimizer.zero_grad() and loss.backward() calls.</span>
<a id="__codelineno-0-284" name="__codelineno-0-284"></a>
<a id="__codelineno-0-285" name="__codelineno-0-285"></a><span class="sd">            Allows for gradient processing before optimizer.step() is called.</span>
<a id="__codelineno-0-286" name="__codelineno-0-286"></a><span class="sd">            E.g. for gradient clipping.</span>
<a id="__codelineno-0-287" name="__codelineno-0-287"></a><span class="sd">            &quot;&quot;&quot;</span>
<a id="__codelineno-0-288" name="__codelineno-0-288"></a>            <span class="k">if</span> <span class="n">extra_grad_process_fn</span><span class="p">:</span>
<a id="__codelineno-0-289" name="__codelineno-0-289"></a>                <span class="k">return</span> <span class="n">extra_grad_process_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
<a id="__codelineno-0-290" name="__codelineno-0-290"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-291" name="__codelineno-0-291"></a>                <span class="k">return</span> <span class="n">parent_cls</span><span class="o">.</span><span class="n">extra_grad_process</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
<a id="__codelineno-0-292" name="__codelineno-0-292"></a>
<a id="__codelineno-0-293" name="__codelineno-0-293"></a>        <span class="nd">@override</span><span class="p">(</span><span class="n">parent_cls</span><span class="p">)</span>
<a id="__codelineno-0-294" name="__codelineno-0-294"></a>        <span class="k">def</span> <span class="nf">extra_compute_grad_fetches</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-295" name="__codelineno-0-295"></a>            <span class="k">if</span> <span class="n">extra_learn_fetches_fn</span><span class="p">:</span>
<a id="__codelineno-0-296" name="__codelineno-0-296"></a>                <span class="n">fetches</span> <span class="o">=</span> <span class="n">convert_to_non_torch_type</span><span class="p">(</span>
<a id="__codelineno-0-297" name="__codelineno-0-297"></a>                    <span class="n">extra_learn_fetches_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
<a id="__codelineno-0-298" name="__codelineno-0-298"></a>                <span class="c1"># Auto-add empty learner stats dict if needed.</span>
<a id="__codelineno-0-299" name="__codelineno-0-299"></a>                <span class="k">return</span> <span class="nb">dict</span><span class="p">({</span><span class="n">LEARNER_STATS_KEY</span><span class="p">:</span> <span class="p">{}},</span> <span class="o">**</span><span class="n">fetches</span><span class="p">)</span>
<a id="__codelineno-0-300" name="__codelineno-0-300"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-301" name="__codelineno-0-301"></a>                <span class="k">return</span> <span class="n">parent_cls</span><span class="o">.</span><span class="n">extra_compute_grad_fetches</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
<a id="__codelineno-0-302" name="__codelineno-0-302"></a>
<a id="__codelineno-0-303" name="__codelineno-0-303"></a>        <span class="nd">@override</span><span class="p">(</span><span class="n">parent_cls</span><span class="p">)</span>
<a id="__codelineno-0-304" name="__codelineno-0-304"></a>        <span class="k">def</span> <span class="nf">compute_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
<a id="__codelineno-0-305" name="__codelineno-0-305"></a>            <span class="k">if</span> <span class="n">compute_gradients_fn</span><span class="p">:</span>
<a id="__codelineno-0-306" name="__codelineno-0-306"></a>                <span class="k">return</span> <span class="n">compute_gradients_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
<a id="__codelineno-0-307" name="__codelineno-0-307"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-308" name="__codelineno-0-308"></a>                <span class="k">return</span> <span class="n">parent_cls</span><span class="o">.</span><span class="n">compute_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
<a id="__codelineno-0-309" name="__codelineno-0-309"></a>
<a id="__codelineno-0-310" name="__codelineno-0-310"></a>        <span class="nd">@override</span><span class="p">(</span><span class="n">parent_cls</span><span class="p">)</span>
<a id="__codelineno-0-311" name="__codelineno-0-311"></a>        <span class="k">def</span> <span class="nf">apply_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gradients</span><span class="p">):</span>
<a id="__codelineno-0-312" name="__codelineno-0-312"></a>            <span class="k">if</span> <span class="n">apply_gradients_fn</span><span class="p">:</span>
<a id="__codelineno-0-313" name="__codelineno-0-313"></a>                <span class="n">apply_gradients_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gradients</span><span class="p">)</span>
<a id="__codelineno-0-314" name="__codelineno-0-314"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-315" name="__codelineno-0-315"></a>                <span class="n">parent_cls</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gradients</span><span class="p">)</span>
<a id="__codelineno-0-316" name="__codelineno-0-316"></a>
<a id="__codelineno-0-317" name="__codelineno-0-317"></a>        <span class="nd">@override</span><span class="p">(</span><span class="n">parent_cls</span><span class="p">)</span>
<a id="__codelineno-0-318" name="__codelineno-0-318"></a>        <span class="k">def</span> <span class="nf">extra_action_out</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dict</span><span class="p">,</span> <span class="n">state_batches</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span>
<a id="__codelineno-0-319" name="__codelineno-0-319"></a>                             <span class="n">action_dist</span><span class="p">):</span>
<a id="__codelineno-0-320" name="__codelineno-0-320"></a>            <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_no_grad_context</span><span class="p">():</span>
<a id="__codelineno-0-321" name="__codelineno-0-321"></a>                <span class="k">if</span> <span class="n">extra_action_out_fn</span><span class="p">:</span>
<a id="__codelineno-0-322" name="__codelineno-0-322"></a>                    <span class="n">stats_dict</span> <span class="o">=</span> <span class="n">extra_action_out_fn</span><span class="p">(</span>
<a id="__codelineno-0-323" name="__codelineno-0-323"></a>                        <span class="bp">self</span><span class="p">,</span> <span class="n">input_dict</span><span class="p">,</span> <span class="n">state_batches</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">action_dist</span><span class="p">)</span>
<a id="__codelineno-0-324" name="__codelineno-0-324"></a>                <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-325" name="__codelineno-0-325"></a>                    <span class="n">stats_dict</span> <span class="o">=</span> <span class="n">parent_cls</span><span class="o">.</span><span class="n">extra_action_out</span><span class="p">(</span>
<a id="__codelineno-0-326" name="__codelineno-0-326"></a>                        <span class="bp">self</span><span class="p">,</span> <span class="n">input_dict</span><span class="p">,</span> <span class="n">state_batches</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">action_dist</span><span class="p">)</span>
<a id="__codelineno-0-327" name="__codelineno-0-327"></a>                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_convert_to_non_torch_type</span><span class="p">(</span><span class="n">stats_dict</span><span class="p">)</span>
<a id="__codelineno-0-328" name="__codelineno-0-328"></a>
<a id="__codelineno-0-329" name="__codelineno-0-329"></a>        <span class="nd">@override</span><span class="p">(</span><span class="n">parent_cls</span><span class="p">)</span>
<a id="__codelineno-0-330" name="__codelineno-0-330"></a>        <span class="k">def</span> <span class="nf">optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-331" name="__codelineno-0-331"></a>            <span class="k">if</span> <span class="n">optimizer_fn</span><span class="p">:</span>
<a id="__codelineno-0-332" name="__codelineno-0-332"></a>                <span class="n">optimizers</span> <span class="o">=</span> <span class="n">optimizer_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>
<a id="__codelineno-0-333" name="__codelineno-0-333"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-334" name="__codelineno-0-334"></a>                <span class="n">optimizers</span> <span class="o">=</span> <span class="n">parent_cls</span><span class="o">.</span><span class="n">optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
<a id="__codelineno-0-335" name="__codelineno-0-335"></a>            <span class="k">return</span> <span class="n">optimizers</span>
<a id="__codelineno-0-336" name="__codelineno-0-336"></a>
<a id="__codelineno-0-337" name="__codelineno-0-337"></a>        <span class="nd">@override</span><span class="p">(</span><span class="n">parent_cls</span><span class="p">)</span>
<a id="__codelineno-0-338" name="__codelineno-0-338"></a>        <span class="k">def</span> <span class="nf">extra_grad_info</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_batch</span><span class="p">):</span>
<a id="__codelineno-0-339" name="__codelineno-0-339"></a>            <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_no_grad_context</span><span class="p">():</span>
<a id="__codelineno-0-340" name="__codelineno-0-340"></a>                <span class="k">if</span> <span class="n">stats_fn</span><span class="p">:</span>
<a id="__codelineno-0-341" name="__codelineno-0-341"></a>                    <span class="n">stats_dict</span> <span class="o">=</span> <span class="n">stats_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_batch</span><span class="p">)</span>
<a id="__codelineno-0-342" name="__codelineno-0-342"></a>                <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-343" name="__codelineno-0-343"></a>                    <span class="n">stats_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent_cls</span><span class="o">.</span><span class="n">extra_grad_info</span><span class="p">(</span>
<a id="__codelineno-0-344" name="__codelineno-0-344"></a>                        <span class="bp">self</span><span class="p">,</span> <span class="n">train_batch</span><span class="p">)</span>
<a id="__codelineno-0-345" name="__codelineno-0-345"></a>                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_convert_to_non_torch_type</span><span class="p">(</span><span class="n">stats_dict</span><span class="p">)</span>
<a id="__codelineno-0-346" name="__codelineno-0-346"></a>
<a id="__codelineno-0-347" name="__codelineno-0-347"></a>        <span class="k">def</span> <span class="nf">_no_grad_context</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-348" name="__codelineno-0-348"></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">framework</span> <span class="o">==</span> <span class="s2">&quot;torch&quot;</span><span class="p">:</span>
<a id="__codelineno-0-349" name="__codelineno-0-349"></a>                <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<a id="__codelineno-0-350" name="__codelineno-0-350"></a>            <span class="k">return</span> <span class="n">NullContextManager</span><span class="p">()</span>
<a id="__codelineno-0-351" name="__codelineno-0-351"></a>
<a id="__codelineno-0-352" name="__codelineno-0-352"></a>        <span class="k">def</span> <span class="nf">_convert_to_non_torch_type</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<a id="__codelineno-0-353" name="__codelineno-0-353"></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">framework</span> <span class="o">==</span> <span class="s2">&quot;torch&quot;</span><span class="p">:</span>
<a id="__codelineno-0-354" name="__codelineno-0-354"></a>                <span class="k">return</span> <span class="n">convert_to_non_torch_type</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<a id="__codelineno-0-355" name="__codelineno-0-355"></a>            <span class="k">return</span> <span class="n">data</span>
<a id="__codelineno-0-356" name="__codelineno-0-356"></a>
<a id="__codelineno-0-357" name="__codelineno-0-357"></a>    <span class="k">def</span> <span class="nf">with_updates</span><span class="p">(</span><span class="o">**</span><span class="n">overrides</span><span class="p">):</span>
<a id="__codelineno-0-358" name="__codelineno-0-358"></a>        <span class="sd">&quot;&quot;&quot;Creates a Torch|JAXPolicy cls based on settings of another one.</span>
<a id="__codelineno-0-359" name="__codelineno-0-359"></a>
<a id="__codelineno-0-360" name="__codelineno-0-360"></a><span class="sd">        Keyword Args:</span>
<a id="__codelineno-0-361" name="__codelineno-0-361"></a><span class="sd">            **overrides: The settings (passed into `build_torch_policy`) that</span>
<a id="__codelineno-0-362" name="__codelineno-0-362"></a><span class="sd">                should be different from the class that this method is called</span>
<a id="__codelineno-0-363" name="__codelineno-0-363"></a><span class="sd">                on.</span>
<a id="__codelineno-0-364" name="__codelineno-0-364"></a>
<a id="__codelineno-0-365" name="__codelineno-0-365"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-366" name="__codelineno-0-366"></a><span class="sd">            type: A new Torch|JAXPolicy sub-class.</span>
<a id="__codelineno-0-367" name="__codelineno-0-367"></a>
<a id="__codelineno-0-368" name="__codelineno-0-368"></a><span class="sd">        Examples:</span>
<a id="__codelineno-0-369" name="__codelineno-0-369"></a><span class="sd">        &gt;&gt; MySpecialDQNPolicyClass = DQNTorchPolicy.with_updates(</span>
<a id="__codelineno-0-370" name="__codelineno-0-370"></a><span class="sd">        ..    name=&quot;MySpecialDQNPolicyClass&quot;,</span>
<a id="__codelineno-0-371" name="__codelineno-0-371"></a><span class="sd">        ..    loss_function=[some_new_loss_function],</span>
<a id="__codelineno-0-372" name="__codelineno-0-372"></a><span class="sd">        .. )</span>
<a id="__codelineno-0-373" name="__codelineno-0-373"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-374" name="__codelineno-0-374"></a>        <span class="k">return</span> <span class="n">build_policy_class</span><span class="p">(</span><span class="o">**</span><span class="nb">dict</span><span class="p">(</span><span class="n">original_kwargs</span><span class="p">,</span> <span class="o">**</span><span class="n">overrides</span><span class="p">))</span>
<a id="__codelineno-0-375" name="__codelineno-0-375"></a>
<a id="__codelineno-0-376" name="__codelineno-0-376"></a>    <span class="n">policy_cls</span><span class="o">.</span><span class="n">with_updates</span> <span class="o">=</span> <span class="nb">staticmethod</span><span class="p">(</span><span class="n">with_updates</span><span class="p">)</span>
<a id="__codelineno-0-377" name="__codelineno-0-377"></a>    <span class="n">policy_cls</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">=</span> <span class="n">name</span>
<a id="__codelineno-0-378" name="__codelineno-0-378"></a>    <span class="n">policy_cls</span><span class="o">.</span><span class="vm">__qualname__</span> <span class="o">=</span> <span class="n">name</span>
<a id="__codelineno-0-379" name="__codelineno-0-379"></a>    <span class="k">return</span> <span class="n">policy_cls</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h2 class="doc doc-heading" id="ray.rllib.policy.tf_policy_template.build_tf_policy">
<code class="highlight language-python"><span class="n">ray</span><span class="o">.</span><span class="n">rllib</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">tf_policy_template</span><span class="o">.</span><span class="n">build_tf_policy</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">get_default_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">postprocess_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stats_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">optimizer_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">compute_gradients_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">apply_gradients_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">grad_stats_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">extra_action_out_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">extra_learn_fetches_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">validate_spaces</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">before_init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">before_loss_init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">after_init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">make_model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">action_sampler_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">action_distribution_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mixins</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">get_batch_divisibility_req</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">obs_include_prev_action_reward</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">extra_action_fetches_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">gradients_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>


</h2>

    <div class="doc doc-contents first">

      <p>Helper function for creating a dynamic tf policy at runtime.</p>
<p>Functions will be run in this order to initialize the policy:
    1. Placeholder setup: postprocess_fn
    2. Loss init: loss_fn, stats_fn
    3. Optimizer init: optimizer_fn, gradients_fn, apply_gradients_fn,
                       grad_stats_fn</p>
<p>This means that you can e.g., depend on any policy attributes created in
the running of <code>loss_fn</code> in later functions such as <code>stats_fn</code>.</p>
<p>In eager mode, the following functions will be run repeatedly on each
eager execution: loss_fn, stats_fn, gradients_fn, apply_gradients_fn,
and grad_stats_fn.</p>
<p>This means that these functions should not define any variables internally,
otherwise they will fail in eager mode execution. Variable should only
be created in make_model (if defined).</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>name</code></td>
        <td><code>str</code></td>
        <td><p>Name of the policy (e.g., "PPOTFPolicy").</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>loss_fn</code></td>
        <td><code>Callable[[
Policy, ModelV2, Type[TFActionDistribution], SampleBatch],
Union[TensorType, List[TensorType]]]</code></td>
        <td><p>Callable for calculating a
loss tensor.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>get_default_config</code></td>
        <td><code>Optional[Callable[[None], TrainerConfigDict]]</code></td>
        <td><p>Optional callable that returns the default config to merge with any
overrides. If None, uses only(!) the user-provided
PartialTrainerConfigDict as dict for this Policy.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>postprocess_fn</code></td>
        <td><code>Optional[Callable[[Policy, SampleBatch,
Optional[Dict[AgentID, SampleBatch]], Episode], None]]</code></td>
        <td><p>Optional callable for post-processing experience batches (called
after the parent class' <code>postprocess_trajectory</code> method).</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>stats_fn</code></td>
        <td><code>Optional[Callable[[Policy, SampleBatch],
Dict[str, TensorType]]]</code></td>
        <td><p>Optional callable that returns a dict of
TF tensors to fetch given the policy and batch input tensors. If
None, will not compute any stats.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>optimizer_fn</code></td>
        <td><code>Optional[Callable[[Policy, TrainerConfigDict],
&#34;tf.keras.optimizers.Optimizer&#34;]]</code></td>
        <td><p>Optional callable that returns
a tf.Optimizer given the policy and config. If None, will call
the base class' <code>optimizer()</code> method instead (which returns a
tf1.train.AdamOptimizer).</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>compute_gradients_fn</code></td>
        <td><code>Optional[Callable[[Policy,
&#34;tf.keras.optimizers.Optimizer&#34;, TensorType], ModelGradients]]</code></td>
        <td><p>Optional callable that returns a list of gradients. If None,
this defaults to optimizer.compute_gradients([loss]).</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>apply_gradients_fn</code></td>
        <td><code>Optional[Callable[[Policy,
&#34;tf.keras.optimizers.Optimizer&#34;, ModelGradients],
&#34;tf.Operation&#34;]]</code></td>
        <td><p>Optional callable that returns an apply
gradients op given policy, tf-optimizer, and grads_and_vars. If
None, will call the base class' <code>build_apply_op()</code> method instead.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>grad_stats_fn</code></td>
        <td><code>Optional[Callable[[Policy, SampleBatch, ModelGradients],
Dict[str, TensorType]]]</code></td>
        <td><p>Optional callable that returns a dict of
TF fetches given the policy, batch input, and gradient tensors. If
None, will not collect any gradient stats.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>extra_action_out_fn</code></td>
        <td><code>Optional[Callable[[Policy],
Dict[str, TensorType]]]</code></td>
        <td><p>Optional callable that returns
a dict of TF fetches given the policy object. If None, will not
perform any extra fetches.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>extra_learn_fetches_fn</code></td>
        <td><code>Optional[Callable[[Policy],
Dict[str, TensorType]]]</code></td>
        <td><p>Optional callable that returns a dict of
extra values to fetch and return when learning on a batch. If None,
will call the base class' <code>extra_compute_grad_fetches()</code> method
instead.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>validate_spaces</code></td>
        <td><code>Optional[Callable[[Policy, gym.Space, gym.Space,
TrainerConfigDict], None]]</code></td>
        <td><p>Optional callable that takes the
Policy, observation_space, action_space, and config to check
the spaces for correctness. If None, no spaces checking will be
done.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>before_init</code></td>
        <td><code>Optional[Callable[[Policy, gym.Space, gym.Space,
TrainerConfigDict], None]]</code></td>
        <td><p>Optional callable to run at the
beginning of policy init that takes the same arguments as the
policy constructor. If None, this step will be skipped.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>before_loss_init</code></td>
        <td><code>Optional[Callable[[Policy, gym.spaces.Space,
gym.spaces.Space, TrainerConfigDict], None]]</code></td>
        <td><p>Optional callable to
run prior to loss init. If None, this step will be skipped.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>after_init</code></td>
        <td><code>Optional[Callable[[Policy, gym.Space, gym.Space,
TrainerConfigDict], None]]</code></td>
        <td><p>Optional callable to run at the end of
policy init. If None, this step will be skipped.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>make_model</code></td>
        <td><code>Optional[Callable[[Policy, gym.spaces.Space,
gym.spaces.Space, TrainerConfigDict], ModelV2]]</code></td>
        <td><p>Optional callable
that returns a ModelV2 object.
All policy variables should be created in this function. If None,
a default ModelV2 object will be created.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>action_sampler_fn</code></td>
        <td><code>Optional[Callable[[TensorType, List[TensorType]],
Tuple[TensorType, TensorType]]]</code></td>
        <td><p>A callable returning a sampled
action and its log-likelihood given observation and state inputs.
If None, will either use <code>action_distribution_fn</code> or
compute actions by calling self.model, then sampling from the
so parameterized action distribution.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>action_distribution_fn</code></td>
        <td><code>Optional[Callable[[Policy, ModelV2, TensorType,
TensorType, TensorType],
Tuple[TensorType, type, List[TensorType]]]]</code></td>
        <td><p>Optional callable
returning distribution inputs (parameters), a dist-class to
generate an action distribution object from, and internal-state
outputs (or an empty list if not applicable). If None, will either
use <code>action_sampler_fn</code> or compute actions by calling self.model,
then sampling from the so parameterized action distribution.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>mixins</code></td>
        <td><code>Optional[List[type]]</code></td>
        <td><p>Optional list of any class mixins for
the returned policy class. These mixins will be applied in order
and will have higher precedence than the DynamicTFPolicy class.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>get_batch_divisibility_req</code></td>
        <td><code>Optional[Callable[[Policy], int]]</code></td>
        <td><p>Optional callable that returns the divisibility requirement for
sample batches. If None, will assume a value of 1.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Type[DynamicTFPolicy]</code></td>
      <td><p>A child class of DynamicTFPolicy based on the
    specified args.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>ray/rllib/policy/tf_policy_template.py</code></summary>
          <div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="nd">@DeveloperAPI</span>
<a id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="k">def</span> <span class="nf">build_tf_policy</span><span class="p">(</span>
<a id="__codelineno-0-3" name="__codelineno-0-3"></a>        <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<a id="__codelineno-0-4" name="__codelineno-0-4"></a>        <span class="o">*</span><span class="p">,</span>
<a id="__codelineno-0-5" name="__codelineno-0-5"></a>        <span class="n">loss_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span>
<a id="__codelineno-0-6" name="__codelineno-0-6"></a>            <span class="n">Policy</span><span class="p">,</span> <span class="n">ModelV2</span><span class="p">,</span> <span class="n">Type</span><span class="p">[</span><span class="n">TFActionDistribution</span><span class="p">],</span> <span class="n">SampleBatch</span>
<a id="__codelineno-0-7" name="__codelineno-0-7"></a>        <span class="p">],</span> <span class="n">Union</span><span class="p">[</span><span class="n">TensorType</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]]],</span>
<a id="__codelineno-0-8" name="__codelineno-0-8"></a>        <span class="n">get_default_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="kc">None</span><span class="p">],</span>
<a id="__codelineno-0-9" name="__codelineno-0-9"></a>                                              <span class="n">TrainerConfigDict</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-10" name="__codelineno-0-10"></a>        <span class="n">postprocess_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span>
<a id="__codelineno-0-11" name="__codelineno-0-11"></a>            <span class="n">Policy</span><span class="p">,</span> <span class="n">SampleBatch</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="n">AgentID</span><span class="p">,</span> <span class="n">SampleBatch</span><span class="p">]],</span>
<a id="__codelineno-0-12" name="__codelineno-0-12"></a>            <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;Episode&quot;</span><span class="p">]</span>
<a id="__codelineno-0-13" name="__codelineno-0-13"></a>        <span class="p">],</span> <span class="n">SampleBatch</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-14" name="__codelineno-0-14"></a>        <span class="n">stats_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Policy</span><span class="p">,</span> <span class="n">SampleBatch</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span>
<a id="__codelineno-0-15" name="__codelineno-0-15"></a>            <span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-16" name="__codelineno-0-16"></a>        <span class="n">optimizer_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span>
<a id="__codelineno-0-17" name="__codelineno-0-17"></a>            <span class="n">Policy</span><span class="p">,</span> <span class="n">TrainerConfigDict</span>
<a id="__codelineno-0-18" name="__codelineno-0-18"></a>        <span class="p">],</span> <span class="s2">&quot;tf.keras.optimizers.Optimizer&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-19" name="__codelineno-0-19"></a>        <span class="n">compute_gradients_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span>
<a id="__codelineno-0-20" name="__codelineno-0-20"></a>            <span class="n">Policy</span><span class="p">,</span> <span class="s2">&quot;tf.keras.optimizers.Optimizer&quot;</span><span class="p">,</span> <span class="n">TensorType</span>
<a id="__codelineno-0-21" name="__codelineno-0-21"></a>        <span class="p">],</span> <span class="n">ModelGradients</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-22" name="__codelineno-0-22"></a>        <span class="n">apply_gradients_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span>
<a id="__codelineno-0-23" name="__codelineno-0-23"></a>            <span class="n">Policy</span><span class="p">,</span> <span class="s2">&quot;tf.keras.optimizers.Optimizer&quot;</span><span class="p">,</span> <span class="n">ModelGradients</span>
<a id="__codelineno-0-24" name="__codelineno-0-24"></a>        <span class="p">],</span> <span class="s2">&quot;tf.Operation&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-25" name="__codelineno-0-25"></a>        <span class="n">grad_stats_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Policy</span><span class="p">,</span> <span class="n">SampleBatch</span><span class="p">,</span> <span class="n">ModelGradients</span><span class="p">],</span>
<a id="__codelineno-0-26" name="__codelineno-0-26"></a>                                         <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-27" name="__codelineno-0-27"></a>        <span class="n">extra_action_out_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Policy</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span>
<a id="__codelineno-0-28" name="__codelineno-0-28"></a>            <span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-29" name="__codelineno-0-29"></a>        <span class="n">extra_learn_fetches_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Policy</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span>
<a id="__codelineno-0-30" name="__codelineno-0-30"></a>            <span class="nb">str</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-31" name="__codelineno-0-31"></a>        <span class="n">validate_spaces</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[</span>
<a id="__codelineno-0-32" name="__codelineno-0-32"></a>            <span class="p">[</span><span class="n">Policy</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span> <span class="n">TrainerConfigDict</span><span class="p">],</span> <span class="kc">None</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-33" name="__codelineno-0-33"></a>        <span class="n">before_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[</span>
<a id="__codelineno-0-34" name="__codelineno-0-34"></a>            <span class="p">[</span><span class="n">Policy</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span> <span class="n">TrainerConfigDict</span><span class="p">],</span> <span class="kc">None</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-35" name="__codelineno-0-35"></a>        <span class="n">before_loss_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span>
<a id="__codelineno-0-36" name="__codelineno-0-36"></a>            <span class="n">Policy</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span> <span class="n">TrainerConfigDict</span>
<a id="__codelineno-0-37" name="__codelineno-0-37"></a>        <span class="p">],</span> <span class="kc">None</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-38" name="__codelineno-0-38"></a>        <span class="n">after_init</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[</span>
<a id="__codelineno-0-39" name="__codelineno-0-39"></a>            <span class="p">[</span><span class="n">Policy</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span> <span class="n">TrainerConfigDict</span><span class="p">],</span> <span class="kc">None</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-40" name="__codelineno-0-40"></a>        <span class="n">make_model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span>
<a id="__codelineno-0-41" name="__codelineno-0-41"></a>            <span class="n">Policy</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span> <span class="n">TrainerConfigDict</span>
<a id="__codelineno-0-42" name="__codelineno-0-42"></a>        <span class="p">],</span> <span class="n">ModelV2</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-43" name="__codelineno-0-43"></a>        <span class="n">action_sampler_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">TensorType</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span>
<a id="__codelineno-0-44" name="__codelineno-0-44"></a>            <span class="n">TensorType</span><span class="p">]],</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">TensorType</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-45" name="__codelineno-0-45"></a>        <span class="n">action_distribution_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span>
<a id="__codelineno-0-46" name="__codelineno-0-46"></a>            <span class="n">Policy</span><span class="p">,</span> <span class="n">ModelV2</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">,</span> <span class="n">TensorType</span><span class="p">,</span> <span class="n">TensorType</span>
<a id="__codelineno-0-47" name="__codelineno-0-47"></a>        <span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">TensorType</span><span class="p">,</span> <span class="nb">type</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorType</span><span class="p">]]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-48" name="__codelineno-0-48"></a>        <span class="n">mixins</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">type</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-49" name="__codelineno-0-49"></a>        <span class="n">get_batch_divisibility_req</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">Policy</span><span class="p">],</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-50" name="__codelineno-0-50"></a>        <span class="c1"># Deprecated args.</span>
<a id="__codelineno-0-51" name="__codelineno-0-51"></a>        <span class="n">obs_include_prev_action_reward</span><span class="o">=</span><span class="n">DEPRECATED_VALUE</span><span class="p">,</span>
<a id="__codelineno-0-52" name="__codelineno-0-52"></a>        <span class="n">extra_action_fetches_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># Use `extra_action_out_fn`.</span>
<a id="__codelineno-0-53" name="__codelineno-0-53"></a>        <span class="n">gradients_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># Use `compute_gradients_fn`.</span>
<a id="__codelineno-0-54" name="__codelineno-0-54"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Type</span><span class="p">[</span><span class="n">DynamicTFPolicy</span><span class="p">]:</span>
<a id="__codelineno-0-55" name="__codelineno-0-55"></a>    <span class="sd">&quot;&quot;&quot;Helper function for creating a dynamic tf policy at runtime.</span>
<a id="__codelineno-0-56" name="__codelineno-0-56"></a>
<a id="__codelineno-0-57" name="__codelineno-0-57"></a><span class="sd">    Functions will be run in this order to initialize the policy:</span>
<a id="__codelineno-0-58" name="__codelineno-0-58"></a><span class="sd">        1. Placeholder setup: postprocess_fn</span>
<a id="__codelineno-0-59" name="__codelineno-0-59"></a><span class="sd">        2. Loss init: loss_fn, stats_fn</span>
<a id="__codelineno-0-60" name="__codelineno-0-60"></a><span class="sd">        3. Optimizer init: optimizer_fn, gradients_fn, apply_gradients_fn,</span>
<a id="__codelineno-0-61" name="__codelineno-0-61"></a><span class="sd">                           grad_stats_fn</span>
<a id="__codelineno-0-62" name="__codelineno-0-62"></a>
<a id="__codelineno-0-63" name="__codelineno-0-63"></a><span class="sd">    This means that you can e.g., depend on any policy attributes created in</span>
<a id="__codelineno-0-64" name="__codelineno-0-64"></a><span class="sd">    the running of `loss_fn` in later functions such as `stats_fn`.</span>
<a id="__codelineno-0-65" name="__codelineno-0-65"></a>
<a id="__codelineno-0-66" name="__codelineno-0-66"></a><span class="sd">    In eager mode, the following functions will be run repeatedly on each</span>
<a id="__codelineno-0-67" name="__codelineno-0-67"></a><span class="sd">    eager execution: loss_fn, stats_fn, gradients_fn, apply_gradients_fn,</span>
<a id="__codelineno-0-68" name="__codelineno-0-68"></a><span class="sd">    and grad_stats_fn.</span>
<a id="__codelineno-0-69" name="__codelineno-0-69"></a>
<a id="__codelineno-0-70" name="__codelineno-0-70"></a><span class="sd">    This means that these functions should not define any variables internally,</span>
<a id="__codelineno-0-71" name="__codelineno-0-71"></a><span class="sd">    otherwise they will fail in eager mode execution. Variable should only</span>
<a id="__codelineno-0-72" name="__codelineno-0-72"></a><span class="sd">    be created in make_model (if defined).</span>
<a id="__codelineno-0-73" name="__codelineno-0-73"></a>
<a id="__codelineno-0-74" name="__codelineno-0-74"></a><span class="sd">    Args:</span>
<a id="__codelineno-0-75" name="__codelineno-0-75"></a><span class="sd">        name (str): Name of the policy (e.g., &quot;PPOTFPolicy&quot;).</span>
<a id="__codelineno-0-76" name="__codelineno-0-76"></a><span class="sd">        loss_fn (Callable[[</span>
<a id="__codelineno-0-77" name="__codelineno-0-77"></a><span class="sd">            Policy, ModelV2, Type[TFActionDistribution], SampleBatch],</span>
<a id="__codelineno-0-78" name="__codelineno-0-78"></a><span class="sd">            Union[TensorType, List[TensorType]]]): Callable for calculating a</span>
<a id="__codelineno-0-79" name="__codelineno-0-79"></a><span class="sd">            loss tensor.</span>
<a id="__codelineno-0-80" name="__codelineno-0-80"></a><span class="sd">        get_default_config (Optional[Callable[[None], TrainerConfigDict]]):</span>
<a id="__codelineno-0-81" name="__codelineno-0-81"></a><span class="sd">            Optional callable that returns the default config to merge with any</span>
<a id="__codelineno-0-82" name="__codelineno-0-82"></a><span class="sd">            overrides. If None, uses only(!) the user-provided</span>
<a id="__codelineno-0-83" name="__codelineno-0-83"></a><span class="sd">            PartialTrainerConfigDict as dict for this Policy.</span>
<a id="__codelineno-0-84" name="__codelineno-0-84"></a><span class="sd">        postprocess_fn (Optional[Callable[[Policy, SampleBatch,</span>
<a id="__codelineno-0-85" name="__codelineno-0-85"></a><span class="sd">            Optional[Dict[AgentID, SampleBatch]], Episode], None]]):</span>
<a id="__codelineno-0-86" name="__codelineno-0-86"></a><span class="sd">            Optional callable for post-processing experience batches (called</span>
<a id="__codelineno-0-87" name="__codelineno-0-87"></a><span class="sd">            after the parent class&#39; `postprocess_trajectory` method).</span>
<a id="__codelineno-0-88" name="__codelineno-0-88"></a><span class="sd">        stats_fn (Optional[Callable[[Policy, SampleBatch],</span>
<a id="__codelineno-0-89" name="__codelineno-0-89"></a><span class="sd">            Dict[str, TensorType]]]): Optional callable that returns a dict of</span>
<a id="__codelineno-0-90" name="__codelineno-0-90"></a><span class="sd">            TF tensors to fetch given the policy and batch input tensors. If</span>
<a id="__codelineno-0-91" name="__codelineno-0-91"></a><span class="sd">            None, will not compute any stats.</span>
<a id="__codelineno-0-92" name="__codelineno-0-92"></a><span class="sd">        optimizer_fn (Optional[Callable[[Policy, TrainerConfigDict],</span>
<a id="__codelineno-0-93" name="__codelineno-0-93"></a><span class="sd">            &quot;tf.keras.optimizers.Optimizer&quot;]]): Optional callable that returns</span>
<a id="__codelineno-0-94" name="__codelineno-0-94"></a><span class="sd">            a tf.Optimizer given the policy and config. If None, will call</span>
<a id="__codelineno-0-95" name="__codelineno-0-95"></a><span class="sd">            the base class&#39; `optimizer()` method instead (which returns a</span>
<a id="__codelineno-0-96" name="__codelineno-0-96"></a><span class="sd">            tf1.train.AdamOptimizer).</span>
<a id="__codelineno-0-97" name="__codelineno-0-97"></a><span class="sd">        compute_gradients_fn (Optional[Callable[[Policy,</span>
<a id="__codelineno-0-98" name="__codelineno-0-98"></a><span class="sd">            &quot;tf.keras.optimizers.Optimizer&quot;, TensorType], ModelGradients]]):</span>
<a id="__codelineno-0-99" name="__codelineno-0-99"></a><span class="sd">            Optional callable that returns a list of gradients. If None,</span>
<a id="__codelineno-0-100" name="__codelineno-0-100"></a><span class="sd">            this defaults to optimizer.compute_gradients([loss]).</span>
<a id="__codelineno-0-101" name="__codelineno-0-101"></a><span class="sd">        apply_gradients_fn (Optional[Callable[[Policy,</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a><span class="sd">            &quot;tf.keras.optimizers.Optimizer&quot;, ModelGradients],</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a><span class="sd">            &quot;tf.Operation&quot;]]): Optional callable that returns an apply</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a><span class="sd">            gradients op given policy, tf-optimizer, and grads_and_vars. If</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a><span class="sd">            None, will call the base class&#39; `build_apply_op()` method instead.</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a><span class="sd">        grad_stats_fn (Optional[Callable[[Policy, SampleBatch, ModelGradients],</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a><span class="sd">            Dict[str, TensorType]]]): Optional callable that returns a dict of</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a><span class="sd">            TF fetches given the policy, batch input, and gradient tensors. If</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a><span class="sd">            None, will not collect any gradient stats.</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a><span class="sd">        extra_action_out_fn (Optional[Callable[[Policy],</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a><span class="sd">            Dict[str, TensorType]]]): Optional callable that returns</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a><span class="sd">            a dict of TF fetches given the policy object. If None, will not</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a><span class="sd">            perform any extra fetches.</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a><span class="sd">        extra_learn_fetches_fn (Optional[Callable[[Policy],</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a><span class="sd">            Dict[str, TensorType]]]): Optional callable that returns a dict of</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a><span class="sd">            extra values to fetch and return when learning on a batch. If None,</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a><span class="sd">            will call the base class&#39; `extra_compute_grad_fetches()` method</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a><span class="sd">            instead.</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a><span class="sd">        validate_spaces (Optional[Callable[[Policy, gym.Space, gym.Space,</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a><span class="sd">            TrainerConfigDict], None]]): Optional callable that takes the</span>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a><span class="sd">            Policy, observation_space, action_space, and config to check</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a><span class="sd">            the spaces for correctness. If None, no spaces checking will be</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a><span class="sd">            done.</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a><span class="sd">        before_init (Optional[Callable[[Policy, gym.Space, gym.Space,</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a><span class="sd">            TrainerConfigDict], None]]): Optional callable to run at the</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a><span class="sd">            beginning of policy init that takes the same arguments as the</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a><span class="sd">            policy constructor. If None, this step will be skipped.</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a><span class="sd">        before_loss_init (Optional[Callable[[Policy, gym.spaces.Space,</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a><span class="sd">            gym.spaces.Space, TrainerConfigDict], None]]): Optional callable to</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a><span class="sd">            run prior to loss init. If None, this step will be skipped.</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a><span class="sd">        after_init (Optional[Callable[[Policy, gym.Space, gym.Space,</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a><span class="sd">            TrainerConfigDict], None]]): Optional callable to run at the end of</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a><span class="sd">            policy init. If None, this step will be skipped.</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a><span class="sd">        make_model (Optional[Callable[[Policy, gym.spaces.Space,</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a><span class="sd">            gym.spaces.Space, TrainerConfigDict], ModelV2]]): Optional callable</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a><span class="sd">            that returns a ModelV2 object.</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a><span class="sd">            All policy variables should be created in this function. If None,</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a><span class="sd">            a default ModelV2 object will be created.</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a><span class="sd">        action_sampler_fn (Optional[Callable[[TensorType, List[TensorType]],</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a><span class="sd">            Tuple[TensorType, TensorType]]]): A callable returning a sampled</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a><span class="sd">            action and its log-likelihood given observation and state inputs.</span>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a><span class="sd">            If None, will either use `action_distribution_fn` or</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a><span class="sd">            compute actions by calling self.model, then sampling from the</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a><span class="sd">            so parameterized action distribution.</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a><span class="sd">        action_distribution_fn (Optional[Callable[[Policy, ModelV2, TensorType,</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a><span class="sd">            TensorType, TensorType],</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a><span class="sd">            Tuple[TensorType, type, List[TensorType]]]]): Optional callable</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a><span class="sd">            returning distribution inputs (parameters), a dist-class to</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a><span class="sd">            generate an action distribution object from, and internal-state</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a><span class="sd">            outputs (or an empty list if not applicable). If None, will either</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a><span class="sd">            use `action_sampler_fn` or compute actions by calling self.model,</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a><span class="sd">            then sampling from the so parameterized action distribution.</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a><span class="sd">        mixins (Optional[List[type]]): Optional list of any class mixins for</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a><span class="sd">            the returned policy class. These mixins will be applied in order</span>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a><span class="sd">            and will have higher precedence than the DynamicTFPolicy class.</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a><span class="sd">        get_batch_divisibility_req (Optional[Callable[[Policy], int]]):</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a><span class="sd">            Optional callable that returns the divisibility requirement for</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a><span class="sd">            sample batches. If None, will assume a value of 1.</span>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a><span class="sd">    Returns:</span>
<a id="__codelineno-0-161" name="__codelineno-0-161"></a><span class="sd">        Type[DynamicTFPolicy]: A child class of DynamicTFPolicy based on the</span>
<a id="__codelineno-0-162" name="__codelineno-0-162"></a><span class="sd">            specified args.</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a>    <span class="n">original_kwargs</span> <span class="o">=</span> <span class="nb">locals</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a>    <span class="n">base</span> <span class="o">=</span> <span class="n">add_mixins</span><span class="p">(</span><span class="n">DynamicTFPolicy</span><span class="p">,</span> <span class="n">mixins</span><span class="p">)</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a>    <span class="k">if</span> <span class="n">obs_include_prev_action_reward</span> <span class="o">!=</span> <span class="n">DEPRECATED_VALUE</span><span class="p">:</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a>        <span class="n">deprecation_warning</span><span class="p">(</span><span class="n">old</span><span class="o">=</span><span class="s2">&quot;obs_include_prev_action_reward&quot;</span><span class="p">,</span> <span class="n">error</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a>    <span class="k">if</span> <span class="n">extra_action_fetches_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a>        <span class="n">deprecation_warning</span><span class="p">(</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a>            <span class="n">old</span><span class="o">=</span><span class="s2">&quot;extra_action_fetches_fn&quot;</span><span class="p">,</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a>            <span class="n">new</span><span class="o">=</span><span class="s2">&quot;extra_action_out_fn&quot;</span><span class="p">,</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a>            <span class="n">error</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a>        <span class="n">extra_action_out_fn</span> <span class="o">=</span> <span class="n">extra_action_fetches_fn</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a>    <span class="k">if</span> <span class="n">gradients_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a>        <span class="n">deprecation_warning</span><span class="p">(</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a>            <span class="n">old</span><span class="o">=</span><span class="s2">&quot;gradients_fn&quot;</span><span class="p">,</span> <span class="n">new</span><span class="o">=</span><span class="s2">&quot;compute_gradients_fn&quot;</span><span class="p">,</span> <span class="n">error</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a>        <span class="n">compute_gradients_fn</span> <span class="o">=</span> <span class="n">gradients_fn</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a>    <span class="k">class</span> <span class="nc">policy_cls</span><span class="p">(</span><span class="n">base</span><span class="p">):</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a>        <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a>                     <span class="n">obs_space</span><span class="p">,</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a>                     <span class="n">action_space</span><span class="p">,</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a>                     <span class="n">config</span><span class="p">,</span>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a>                     <span class="n">existing_model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a>                     <span class="n">existing_inputs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a>            <span class="k">if</span> <span class="n">get_default_config</span><span class="p">:</span>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a>                <span class="n">config</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">get_default_config</span><span class="p">(),</span> <span class="o">**</span><span class="n">config</span><span class="p">)</span>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a>            <span class="k">if</span> <span class="n">validate_spaces</span><span class="p">:</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a>                <span class="n">validate_spaces</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs_space</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>
<a id="__codelineno-0-194" name="__codelineno-0-194"></a>
<a id="__codelineno-0-195" name="__codelineno-0-195"></a>            <span class="k">if</span> <span class="n">before_init</span><span class="p">:</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a>                <span class="n">before_init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs_space</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>
<a id="__codelineno-0-197" name="__codelineno-0-197"></a>
<a id="__codelineno-0-198" name="__codelineno-0-198"></a>            <span class="k">def</span> <span class="nf">before_loss_init_wrapper</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="n">obs_space</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span>
<a id="__codelineno-0-199" name="__codelineno-0-199"></a>                                         <span class="n">config</span><span class="p">):</span>
<a id="__codelineno-0-200" name="__codelineno-0-200"></a>                <span class="k">if</span> <span class="n">before_loss_init</span><span class="p">:</span>
<a id="__codelineno-0-201" name="__codelineno-0-201"></a>                    <span class="n">before_loss_init</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="n">obs_space</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>
<a id="__codelineno-0-202" name="__codelineno-0-202"></a>
<a id="__codelineno-0-203" name="__codelineno-0-203"></a>                <span class="k">if</span> <span class="n">extra_action_out_fn</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">policy</span><span class="o">.</span><span class="n">_is_tower</span><span class="p">:</span>
<a id="__codelineno-0-204" name="__codelineno-0-204"></a>                    <span class="n">extra_action_fetches</span> <span class="o">=</span> <span class="p">{}</span>
<a id="__codelineno-0-205" name="__codelineno-0-205"></a>                <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-206" name="__codelineno-0-206"></a>                    <span class="n">extra_action_fetches</span> <span class="o">=</span> <span class="n">extra_action_out_fn</span><span class="p">(</span><span class="n">policy</span><span class="p">)</span>
<a id="__codelineno-0-207" name="__codelineno-0-207"></a>
<a id="__codelineno-0-208" name="__codelineno-0-208"></a>                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="s2">&quot;_extra_action_fetches&quot;</span><span class="p">):</span>
<a id="__codelineno-0-209" name="__codelineno-0-209"></a>                    <span class="n">policy</span><span class="o">.</span><span class="n">_extra_action_fetches</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">extra_action_fetches</span><span class="p">)</span>
<a id="__codelineno-0-210" name="__codelineno-0-210"></a>                <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-211" name="__codelineno-0-211"></a>                    <span class="n">policy</span><span class="o">.</span><span class="n">_extra_action_fetches</span> <span class="o">=</span> <span class="n">extra_action_fetches</span>
<a id="__codelineno-0-212" name="__codelineno-0-212"></a>
<a id="__codelineno-0-213" name="__codelineno-0-213"></a>            <span class="n">DynamicTFPolicy</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-214" name="__codelineno-0-214"></a>                <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-215" name="__codelineno-0-215"></a>                <span class="n">obs_space</span><span class="o">=</span><span class="n">obs_space</span><span class="p">,</span>
<a id="__codelineno-0-216" name="__codelineno-0-216"></a>                <span class="n">action_space</span><span class="o">=</span><span class="n">action_space</span><span class="p">,</span>
<a id="__codelineno-0-217" name="__codelineno-0-217"></a>                <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
<a id="__codelineno-0-218" name="__codelineno-0-218"></a>                <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span>
<a id="__codelineno-0-219" name="__codelineno-0-219"></a>                <span class="n">stats_fn</span><span class="o">=</span><span class="n">stats_fn</span><span class="p">,</span>
<a id="__codelineno-0-220" name="__codelineno-0-220"></a>                <span class="n">grad_stats_fn</span><span class="o">=</span><span class="n">grad_stats_fn</span><span class="p">,</span>
<a id="__codelineno-0-221" name="__codelineno-0-221"></a>                <span class="n">before_loss_init</span><span class="o">=</span><span class="n">before_loss_init_wrapper</span><span class="p">,</span>
<a id="__codelineno-0-222" name="__codelineno-0-222"></a>                <span class="n">make_model</span><span class="o">=</span><span class="n">make_model</span><span class="p">,</span>
<a id="__codelineno-0-223" name="__codelineno-0-223"></a>                <span class="n">action_sampler_fn</span><span class="o">=</span><span class="n">action_sampler_fn</span><span class="p">,</span>
<a id="__codelineno-0-224" name="__codelineno-0-224"></a>                <span class="n">action_distribution_fn</span><span class="o">=</span><span class="n">action_distribution_fn</span><span class="p">,</span>
<a id="__codelineno-0-225" name="__codelineno-0-225"></a>                <span class="n">existing_inputs</span><span class="o">=</span><span class="n">existing_inputs</span><span class="p">,</span>
<a id="__codelineno-0-226" name="__codelineno-0-226"></a>                <span class="n">existing_model</span><span class="o">=</span><span class="n">existing_model</span><span class="p">,</span>
<a id="__codelineno-0-227" name="__codelineno-0-227"></a>                <span class="n">get_batch_divisibility_req</span><span class="o">=</span><span class="n">get_batch_divisibility_req</span><span class="p">,</span>
<a id="__codelineno-0-228" name="__codelineno-0-228"></a>            <span class="p">)</span>
<a id="__codelineno-0-229" name="__codelineno-0-229"></a>
<a id="__codelineno-0-230" name="__codelineno-0-230"></a>            <span class="k">if</span> <span class="n">after_init</span><span class="p">:</span>
<a id="__codelineno-0-231" name="__codelineno-0-231"></a>                <span class="n">after_init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs_space</span><span class="p">,</span> <span class="n">action_space</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>
<a id="__codelineno-0-232" name="__codelineno-0-232"></a>
<a id="__codelineno-0-233" name="__codelineno-0-233"></a>            <span class="c1"># Got to reset global_timestep again after this fake run-through.</span>
<a id="__codelineno-0-234" name="__codelineno-0-234"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">global_timestep</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-0-235" name="__codelineno-0-235"></a>
<a id="__codelineno-0-236" name="__codelineno-0-236"></a>        <span class="nd">@override</span><span class="p">(</span><span class="n">Policy</span><span class="p">)</span>
<a id="__codelineno-0-237" name="__codelineno-0-237"></a>        <span class="k">def</span> <span class="nf">postprocess_trajectory</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-238" name="__codelineno-0-238"></a>                                   <span class="n">sample_batch</span><span class="p">,</span>
<a id="__codelineno-0-239" name="__codelineno-0-239"></a>                                   <span class="n">other_agent_batches</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-240" name="__codelineno-0-240"></a>                                   <span class="n">episode</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<a id="__codelineno-0-241" name="__codelineno-0-241"></a>            <span class="c1"># Call super&#39;s postprocess_trajectory first.</span>
<a id="__codelineno-0-242" name="__codelineno-0-242"></a>            <span class="n">sample_batch</span> <span class="o">=</span> <span class="n">Policy</span><span class="o">.</span><span class="n">postprocess_trajectory</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_batch</span><span class="p">)</span>
<a id="__codelineno-0-243" name="__codelineno-0-243"></a>            <span class="k">if</span> <span class="n">postprocess_fn</span><span class="p">:</span>
<a id="__codelineno-0-244" name="__codelineno-0-244"></a>                <span class="k">return</span> <span class="n">postprocess_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample_batch</span><span class="p">,</span> <span class="n">other_agent_batches</span><span class="p">,</span>
<a id="__codelineno-0-245" name="__codelineno-0-245"></a>                                      <span class="n">episode</span><span class="p">)</span>
<a id="__codelineno-0-246" name="__codelineno-0-246"></a>            <span class="k">return</span> <span class="n">sample_batch</span>
<a id="__codelineno-0-247" name="__codelineno-0-247"></a>
<a id="__codelineno-0-248" name="__codelineno-0-248"></a>        <span class="nd">@override</span><span class="p">(</span><span class="n">TFPolicy</span><span class="p">)</span>
<a id="__codelineno-0-249" name="__codelineno-0-249"></a>        <span class="k">def</span> <span class="nf">optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-250" name="__codelineno-0-250"></a>            <span class="k">if</span> <span class="n">optimizer_fn</span><span class="p">:</span>
<a id="__codelineno-0-251" name="__codelineno-0-251"></a>                <span class="n">optimizers</span> <span class="o">=</span> <span class="n">optimizer_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>
<a id="__codelineno-0-252" name="__codelineno-0-252"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-253" name="__codelineno-0-253"></a>                <span class="n">optimizers</span> <span class="o">=</span> <span class="n">base</span><span class="o">.</span><span class="n">optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
<a id="__codelineno-0-254" name="__codelineno-0-254"></a>            <span class="n">optimizers</span> <span class="o">=</span> <span class="n">force_list</span><span class="p">(</span><span class="n">optimizers</span><span class="p">)</span>
<a id="__codelineno-0-255" name="__codelineno-0-255"></a>            <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;exploration&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">):</span>
<a id="__codelineno-0-256" name="__codelineno-0-256"></a>                <span class="n">optimizers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exploration</span><span class="o">.</span><span class="n">get_exploration_optimizer</span><span class="p">(</span>
<a id="__codelineno-0-257" name="__codelineno-0-257"></a>                    <span class="n">optimizers</span><span class="p">)</span>
<a id="__codelineno-0-258" name="__codelineno-0-258"></a>
<a id="__codelineno-0-259" name="__codelineno-0-259"></a>            <span class="c1"># No optimizers produced -&gt; Return None.</span>
<a id="__codelineno-0-260" name="__codelineno-0-260"></a>            <span class="k">if</span> <span class="ow">not</span> <span class="n">optimizers</span><span class="p">:</span>
<a id="__codelineno-0-261" name="__codelineno-0-261"></a>                <span class="k">return</span> <span class="kc">None</span>
<a id="__codelineno-0-262" name="__codelineno-0-262"></a>            <span class="c1"># New API: Allow more than one optimizer to be returned.</span>
<a id="__codelineno-0-263" name="__codelineno-0-263"></a>            <span class="c1"># -&gt; Return list.</span>
<a id="__codelineno-0-264" name="__codelineno-0-264"></a>            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;_tf_policy_handles_more_than_one_loss&quot;</span><span class="p">]:</span>
<a id="__codelineno-0-265" name="__codelineno-0-265"></a>                <span class="k">return</span> <span class="n">optimizers</span>
<a id="__codelineno-0-266" name="__codelineno-0-266"></a>            <span class="c1"># Old API: Return a single LocalOptimizer.</span>
<a id="__codelineno-0-267" name="__codelineno-0-267"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-268" name="__codelineno-0-268"></a>                <span class="k">return</span> <span class="n">optimizers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<a id="__codelineno-0-269" name="__codelineno-0-269"></a>
<a id="__codelineno-0-270" name="__codelineno-0-270"></a>        <span class="nd">@override</span><span class="p">(</span><span class="n">TFPolicy</span><span class="p">)</span>
<a id="__codelineno-0-271" name="__codelineno-0-271"></a>        <span class="k">def</span> <span class="nf">gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">):</span>
<a id="__codelineno-0-272" name="__codelineno-0-272"></a>            <span class="n">optimizers</span> <span class="o">=</span> <span class="n">force_list</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
<a id="__codelineno-0-273" name="__codelineno-0-273"></a>            <span class="n">losses</span> <span class="o">=</span> <span class="n">force_list</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<a id="__codelineno-0-274" name="__codelineno-0-274"></a>
<a id="__codelineno-0-275" name="__codelineno-0-275"></a>            <span class="k">if</span> <span class="n">compute_gradients_fn</span><span class="p">:</span>
<a id="__codelineno-0-276" name="__codelineno-0-276"></a>                <span class="c1"># New API: Allow more than one optimizer -&gt; Return a list of</span>
<a id="__codelineno-0-277" name="__codelineno-0-277"></a>                <span class="c1"># lists of gradients.</span>
<a id="__codelineno-0-278" name="__codelineno-0-278"></a>                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;_tf_policy_handles_more_than_one_loss&quot;</span><span class="p">]:</span>
<a id="__codelineno-0-279" name="__codelineno-0-279"></a>                    <span class="k">return</span> <span class="n">compute_gradients_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizers</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span>
<a id="__codelineno-0-280" name="__codelineno-0-280"></a>                <span class="c1"># Old API: Return a single List of gradients.</span>
<a id="__codelineno-0-281" name="__codelineno-0-281"></a>                <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-282" name="__codelineno-0-282"></a>                    <span class="k">return</span> <span class="n">compute_gradients_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizers</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">losses</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<a id="__codelineno-0-283" name="__codelineno-0-283"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-284" name="__codelineno-0-284"></a>                <span class="k">return</span> <span class="n">base</span><span class="o">.</span><span class="n">gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizers</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span>
<a id="__codelineno-0-285" name="__codelineno-0-285"></a>
<a id="__codelineno-0-286" name="__codelineno-0-286"></a>        <span class="nd">@override</span><span class="p">(</span><span class="n">TFPolicy</span><span class="p">)</span>
<a id="__codelineno-0-287" name="__codelineno-0-287"></a>        <span class="k">def</span> <span class="nf">build_apply_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">grads_and_vars</span><span class="p">):</span>
<a id="__codelineno-0-288" name="__codelineno-0-288"></a>            <span class="k">if</span> <span class="n">apply_gradients_fn</span><span class="p">:</span>
<a id="__codelineno-0-289" name="__codelineno-0-289"></a>                <span class="k">return</span> <span class="n">apply_gradients_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">grads_and_vars</span><span class="p">)</span>
<a id="__codelineno-0-290" name="__codelineno-0-290"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-291" name="__codelineno-0-291"></a>                <span class="k">return</span> <span class="n">base</span><span class="o">.</span><span class="n">build_apply_op</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">grads_and_vars</span><span class="p">)</span>
<a id="__codelineno-0-292" name="__codelineno-0-292"></a>
<a id="__codelineno-0-293" name="__codelineno-0-293"></a>        <span class="nd">@override</span><span class="p">(</span><span class="n">TFPolicy</span><span class="p">)</span>
<a id="__codelineno-0-294" name="__codelineno-0-294"></a>        <span class="k">def</span> <span class="nf">extra_compute_action_fetches</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-295" name="__codelineno-0-295"></a>            <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span>
<a id="__codelineno-0-296" name="__codelineno-0-296"></a>                <span class="n">base</span><span class="o">.</span><span class="n">extra_compute_action_fetches</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span>
<a id="__codelineno-0-297" name="__codelineno-0-297"></a>                <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_extra_action_fetches</span><span class="p">)</span>
<a id="__codelineno-0-298" name="__codelineno-0-298"></a>
<a id="__codelineno-0-299" name="__codelineno-0-299"></a>        <span class="nd">@override</span><span class="p">(</span><span class="n">TFPolicy</span><span class="p">)</span>
<a id="__codelineno-0-300" name="__codelineno-0-300"></a>        <span class="k">def</span> <span class="nf">extra_compute_grad_fetches</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<a id="__codelineno-0-301" name="__codelineno-0-301"></a>            <span class="k">if</span> <span class="n">extra_learn_fetches_fn</span><span class="p">:</span>
<a id="__codelineno-0-302" name="__codelineno-0-302"></a>                <span class="c1"># TODO: (sven) in torch, extra_learn_fetches do not exist.</span>
<a id="__codelineno-0-303" name="__codelineno-0-303"></a>                <span class="c1">#  Hence, things like td_error are returned by the stats_fn</span>
<a id="__codelineno-0-304" name="__codelineno-0-304"></a>                <span class="c1">#  and end up under the LEARNER_STATS_KEY. We should</span>
<a id="__codelineno-0-305" name="__codelineno-0-305"></a>                <span class="c1">#  change tf to do this as well. However, this will confilct</span>
<a id="__codelineno-0-306" name="__codelineno-0-306"></a>                <span class="c1">#  the handling of LEARNER_STATS_KEY inside the multi-GPU</span>
<a id="__codelineno-0-307" name="__codelineno-0-307"></a>                <span class="c1">#  train op.</span>
<a id="__codelineno-0-308" name="__codelineno-0-308"></a>                <span class="c1"># Auto-add empty learner stats dict if needed.</span>
<a id="__codelineno-0-309" name="__codelineno-0-309"></a>                <span class="k">return</span> <span class="nb">dict</span><span class="p">({</span>
<a id="__codelineno-0-310" name="__codelineno-0-310"></a>                    <span class="n">LEARNER_STATS_KEY</span><span class="p">:</span> <span class="p">{}</span>
<a id="__codelineno-0-311" name="__codelineno-0-311"></a>                <span class="p">},</span> <span class="o">**</span><span class="n">extra_learn_fetches_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
<a id="__codelineno-0-312" name="__codelineno-0-312"></a>            <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-313" name="__codelineno-0-313"></a>                <span class="k">return</span> <span class="n">base</span><span class="o">.</span><span class="n">extra_compute_grad_fetches</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
<a id="__codelineno-0-314" name="__codelineno-0-314"></a>
<a id="__codelineno-0-315" name="__codelineno-0-315"></a>    <span class="k">def</span> <span class="nf">with_updates</span><span class="p">(</span><span class="o">**</span><span class="n">overrides</span><span class="p">):</span>
<a id="__codelineno-0-316" name="__codelineno-0-316"></a>        <span class="sd">&quot;&quot;&quot;Allows creating a TFPolicy cls based on settings of another one.</span>
<a id="__codelineno-0-317" name="__codelineno-0-317"></a>
<a id="__codelineno-0-318" name="__codelineno-0-318"></a><span class="sd">        Keyword Args:</span>
<a id="__codelineno-0-319" name="__codelineno-0-319"></a><span class="sd">            **overrides: The settings (passed into `build_tf_policy`) that</span>
<a id="__codelineno-0-320" name="__codelineno-0-320"></a><span class="sd">                should be different from the class that this method is called</span>
<a id="__codelineno-0-321" name="__codelineno-0-321"></a><span class="sd">                on.</span>
<a id="__codelineno-0-322" name="__codelineno-0-322"></a>
<a id="__codelineno-0-323" name="__codelineno-0-323"></a><span class="sd">        Returns:</span>
<a id="__codelineno-0-324" name="__codelineno-0-324"></a><span class="sd">            type: A new TFPolicy sub-class.</span>
<a id="__codelineno-0-325" name="__codelineno-0-325"></a>
<a id="__codelineno-0-326" name="__codelineno-0-326"></a><span class="sd">        Examples:</span>
<a id="__codelineno-0-327" name="__codelineno-0-327"></a><span class="sd">        &gt;&gt; MySpecialDQNPolicyClass = DQNTFPolicy.with_updates(</span>
<a id="__codelineno-0-328" name="__codelineno-0-328"></a><span class="sd">        ..    name=&quot;MySpecialDQNPolicyClass&quot;,</span>
<a id="__codelineno-0-329" name="__codelineno-0-329"></a><span class="sd">        ..    loss_function=[some_new_loss_function],</span>
<a id="__codelineno-0-330" name="__codelineno-0-330"></a><span class="sd">        .. )</span>
<a id="__codelineno-0-331" name="__codelineno-0-331"></a><span class="sd">        &quot;&quot;&quot;</span>
<a id="__codelineno-0-332" name="__codelineno-0-332"></a>        <span class="k">return</span> <span class="n">build_tf_policy</span><span class="p">(</span><span class="o">**</span><span class="nb">dict</span><span class="p">(</span><span class="n">original_kwargs</span><span class="p">,</span> <span class="o">**</span><span class="n">overrides</span><span class="p">))</span>
<a id="__codelineno-0-333" name="__codelineno-0-333"></a>
<a id="__codelineno-0-334" name="__codelineno-0-334"></a>    <span class="k">def</span> <span class="nf">as_eager</span><span class="p">():</span>
<a id="__codelineno-0-335" name="__codelineno-0-335"></a>        <span class="k">return</span> <span class="n">eager_tf_policy</span><span class="o">.</span><span class="n">build_eager_tf_policy</span><span class="p">(</span><span class="o">**</span><span class="n">original_kwargs</span><span class="p">)</span>
<a id="__codelineno-0-336" name="__codelineno-0-336"></a>
<a id="__codelineno-0-337" name="__codelineno-0-337"></a>    <span class="n">policy_cls</span><span class="o">.</span><span class="n">with_updates</span> <span class="o">=</span> <span class="nb">staticmethod</span><span class="p">(</span><span class="n">with_updates</span><span class="p">)</span>
<a id="__codelineno-0-338" name="__codelineno-0-338"></a>    <span class="n">policy_cls</span><span class="o">.</span><span class="n">as_eager</span> <span class="o">=</span> <span class="nb">staticmethod</span><span class="p">(</span><span class="n">as_eager</span><span class="p">)</span>
<a id="__codelineno-0-339" name="__codelineno-0-339"></a>    <span class="n">policy_cls</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">=</span> <span class="n">name</span>
<a id="__codelineno-0-340" name="__codelineno-0-340"></a>    <span class="n">policy_cls</span><span class="o">.</span><span class="vm">__qualname__</span> <span class="o">=</span> <span class="n">name</span>
<a id="__codelineno-0-341" name="__codelineno-0-341"></a>    <span class="k">return</span> <span class="n">policy_cls</span>
</code></pre></div>
        </details>
    </div>

  </div>

              
            </article>
          </div>
        </div>
        
          <a href="#" class="md-top md-icon" data-md-component="top" data-md-state="hidden">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"/></svg>
            Back to top
          </a>
        
      </main>
      
        <footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        
        <a href="../agents/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Agents" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Agents
            </div>
          </div>
        </a>
      
      
        
        <a href="../env/" class="md-footer__link md-footer__link--next" aria-label="Next: Environments" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Environments
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; Anyscale, Inc 2021
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
      
      
    
    <a href="https://twitter.com/raydistributed" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
    </a>
  
    
    
      
      
    
    <a href="https://github.com/ray-project/ray" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
    
    
      
      
    
    <a href="https://ray.io" target="_blank" rel="noopener" title="ray.io" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path d="M336.5 160C322 70.7 287.8 8 248 8s-74 62.7-88.5 152h177zM152 256c0 22.2 1.2 43.5 3.3 64h185.3c2.1-20.5 3.3-41.8 3.3-64s-1.2-43.5-3.3-64H155.3c-2.1 20.5-3.3 41.8-3.3 64zm324.7-96c-28.6-67.9-86.5-120.4-158-141.6 24.4 33.8 41.2 84.7 50 141.6h108zM177.2 18.4C105.8 39.6 47.8 92.1 19.3 160h108c8.7-56.9 25.5-107.8 49.9-141.6zM487.4 192H372.7c2.1 21 3.3 42.5 3.3 64s-1.2 43-3.3 64h114.6c5.5-20.5 8.6-41.8 8.6-64s-3.1-43.5-8.5-64zM120 256c0-21.5 1.2-43 3.3-64H8.6C3.2 212.5 0 233.8 0 256s3.2 43.5 8.6 64h114.6c-2-21-3.2-42.5-3.2-64zm39.5 96c14.5 89.3 48.7 152 88.5 152s74-62.7 88.5-152h-177zm159.3 141.6c71.4-21.2 129.4-73.7 158-141.6h-108c-8.8 56.9-25.6 107.8-50 141.6zM19.3 352c28.6 67.9 86.5 120.4 158 141.6-24.4-33.8-41.2-84.7-50-141.6h-108z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.tracking", "navigation.tabs", "navigation.indexes", "content.tabs.link", "navigation.tracking", "navigation.instant", "navigation.top", "content.code.annotate"], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../../../assets/javascripts/workers/search.0bbba5b5.min.js", "version": {"provider": "mike"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.e1a181d9.min.js"></script>
      
        <script src="../../../js/termynal.js"></script>
      
        <script src="../../../js/custom.js"></script>
      
    
  </body>
</html>