{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray Crash Course - Python Multiprocessing with Ray\n",
    "\n",
    "Â© 2019-2021, Anyscale. All Rights Reserved\n",
    "\n",
    "![Anyscale Academy](../images/AnyscaleAcademyLogo.png)\n",
    "\n",
    "This lesson explores how to replace two popular multiprocessing libraries with Ray replacements to break the one-machine boundary:\n",
    "\n",
    "* [`multiprocessing.Pool`](https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing.pool) for general management of process pools.\n",
    "* [`joblib`](https://joblib.readthedocs.io/en/latest/), the underpinnings of [scikit-learn](https://scikit-learn.org/stable/), which Ray can scale to a cluster.\n",
    "\n",
    "We also examine how Ray can work with Python's [`asyncio`](https://docs.python.org/3/library/asyncio.html).\n",
    "\n",
    "> **Tip:** For more about Ray, see [ray.io](https://ray.io) or the [Ray documentation](https://docs.ray.io/en/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray, time, sys, os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Ray Dashboard, if you are running this notebook on a local machine:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop-in Replacements for Popular Single-node, Multiprocessing Libraries\n",
    "\n",
    "The Python community has three popular libraries for breaking out of Python's _global interpreter lock_ to enable better multiprocessing and concurrency. Ray now offers drop-in replacements for two of them, [`multiprocessing.Pool`](https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing.pool) and [`joblib`](https://joblib.readthedocs.io/en/latest/), and integration with the third, Python's [`asyncio`](https://docs.python.org/3/library/asyncio.html).\n",
    "\n",
    "This section explores the `multiprocessing.Pool` and `joblib` replacements.\n",
    "\n",
    "| Library | Library Docs | Ray Docs | Description |\n",
    "| :------ | :----------- | :------- | :---------- |\n",
    "| `multiprocessing.Pool` | [docs](https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing.pool) | [Ray](https://docs.ray.io/en/latest/multiprocessing.html) | Create a pool of processes for running work. The Ray replacement allows scaling to a cluster. |\n",
    "| `joblib` | [docs](https://joblib.readthedocs.io/en/latest/) | [Ray](https://docs.ray.io/en/latest/joblib.html) | Ray supports running distributed [scikit-learn](https://scikit-learn.org/stable/) programs by implementing a Ray backend for `joblib` using Ray Actors instead of local processes. This makes it easy to scale existing applications that use scikit-learn from a single node to a cluster. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing.Pool\n",
    "\n",
    "If your application already uses `multiprocessing.Pool`, then scaling beyond a single node just requires replacing your import statements from this:\n",
    "\n",
    "```python\n",
    "from multiprocessing.pool import Pool\n",
    "```\n",
    "\n",
    "To this:\n",
    "\n",
    "```python\n",
    "from ray.util.multiprocessing.pool import Pool\n",
    "```\n",
    "\n",
    "A local Ray cluster will be started the first time you create a Pool and your tasks will be distributed across it. See [Run on a Cluster](https://docs.ray.io/en/latest/multiprocessing.html#run-on-a-cluster) in the Ray documentation for details on how to use a multi-node Ray cluster instead.\n",
    "\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.util.multiprocessing import Pool\n",
    "\n",
    "def f(index):\n",
    "    return index\n",
    "\n",
    "def run_with_pool(n=100):\n",
    "    pool = Pool()\n",
    "    for result in pool.map(f, range(n)):\n",
    "        print(f'{result}|', end='')\n",
    "\n",
    "run_with_pool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used a function `run_with_pool()` to wrap a scope around the `pool` construction. That way, it goes out of scope when we're finished and Ray can reclaim the resources.\n",
    "\n",
    "The full `multiprocessing.Pool` API is supported. Please see Python's [multiprocessing documentation](https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing.pool) for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joblib\n",
    "\n",
    "Ray supports running distributed [scikit-learn](https://scikit-learn.org/) programs by implementing a Ray backend for [joblib](https://joblib.readthedocs.io/) using Ray Actors instead of local processes. This makes it easy to scale existing applications that use scikit-learn from a single node to a cluster.\n",
    "\n",
    "> **Note:** This API is new and may be revised in the future. Please [report any issues](https://github.com/ray-project/ray/issues) you encounter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, use `from ray.util.joblib import register_ray` and then run `register_ray()`. This will register Ray as a `joblib` backend for `scikit-learn` to use. Then run your original `scikit-learn` code inside `with joblib.parallel_backend('ray')`. This will start a local Ray cluster. \n",
    "\n",
    "See [Run on a Cluster](https://docs.ray.io/en/latest/joblib.html#run-on-a-cluster) in the Ray documentation for details on how to use a multi-node Ray cluster instead.\n",
    "\n",
    "Here is an example. First, we set up Ray with `joblib`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from ray.util.joblib import register_ray\n",
    "register_ray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use an example taken from the scikit-learn examples, [Restricted Boltzmann Machine features for digit classification](https://scikit-learn.org/stable/auto_examples/neural_networks/plot_rbm_logistic_classification.html#sphx-glr-auto-examples-neural-networks-plot-rbm-logistic-classification-py). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors: Yann N. Dauphin, Vlad Niculae, Gabriel Synnaeve\n",
    "# License: BSD\n",
    "\n",
    "import numpy as np\n",
    "from scipy.ndimage import convolve\n",
    "from sklearn import linear_model, datasets, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Setting up\n",
    "\n",
    "def nudge_dataset(X, Y):\n",
    "    \"\"\"\n",
    "    This produces a dataset 5 times bigger than the original one,\n",
    "    by moving the 8x8 images in X around by 1px to left, right, down, up\n",
    "    \"\"\"\n",
    "    direction_vectors = [\n",
    "        [[0, 1, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 0, 0]],\n",
    "\n",
    "        [[0, 0, 0],\n",
    "         [1, 0, 0],\n",
    "         [0, 0, 0]],\n",
    "\n",
    "        [[0, 0, 0],\n",
    "         [0, 0, 1],\n",
    "         [0, 0, 0]],\n",
    "\n",
    "        [[0, 0, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 1, 0]]]\n",
    "\n",
    "    def shift(x, w):\n",
    "        return convolve(x.reshape((8, 8)), mode='constant', weights=w).ravel()\n",
    "\n",
    "    X = np.concatenate([X] +\n",
    "                       [np.apply_along_axis(shift, 1, X, vector)\n",
    "                        for vector in direction_vectors])\n",
    "    Y = np.concatenate([Y for _ in range(5)], axis=0)\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "# Load Data\n",
    "X, y = datasets.load_digits(return_X_y=True)\n",
    "X = np.asarray(X, 'float32')\n",
    "X, Y = nudge_dataset(X, y)\n",
    "X = (X - np.min(X, 0)) / (np.max(X, 0) + 0.0001)  # 0-1 scaling\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Models we will use\n",
    "logistic = linear_model.LogisticRegression(solver='newton-cg', tol=1)\n",
    "rbm = BernoulliRBM(random_state=0, verbose=True)\n",
    "\n",
    "rbm_features_classifier = Pipeline(\n",
    "    steps=[('rbm', rbm), ('logistic', logistic)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Training\n",
    "\n",
    "# Hyper-parameters. These were set by cross-validation,\n",
    "# using a GridSearchCV. Here we are not performing cross-validation to\n",
    "# save time.\n",
    "rbm.learning_rate = 0.06\n",
    "rbm.n_iter = 10\n",
    "# More components tend to give better prediction performance, but larger\n",
    "# fitting time\n",
    "rbm.n_components = 100\n",
    "logistic.C = 6000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we actually use the Ray backend for `joblib`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with joblib.parallel_backend('ray'):\n",
    "    # Training RBM-Logistic Pipeline\n",
    "    rbm_features_classifier.fit(X_train, Y_train)\n",
    "\n",
    "    # Training the Logistic regression classifier directly on the pixel\n",
    "    raw_pixel_classifier = clone(logistic)\n",
    "    raw_pixel_classifier.C = 100.\n",
    "    raw_pixel_classifier.fit(X_train, Y_train)\n",
    "\n",
    "    # #############################################################################\n",
    "    # Evaluation\n",
    "\n",
    "    Y_pred = rbm_features_classifier.predict(X_test)\n",
    "    print(\"Logistic regression using RBM features:\\n%s\\n\" % (\n",
    "        metrics.classification_report(Y_test, Y_pred)))\n",
    "\n",
    "    Y_pred = raw_pixel_classifier.predict(X_test)\n",
    "    print(\"Logistic regression using raw pixel features:\\n%s\\n\" % (\n",
    "        metrics.classification_report(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see warnings about the `The 'context' argument`, you can safely ignore them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Ray with asyncio\n",
    "\n",
    "Python's [`asyncio`](https://docs.python.org/3/library/asyncio.html) can be used with Ray actors and tasks.\n",
    "\n",
    "> **Note:** The Async API support is experimental and work is ongoing to improve it. Please [report any issues](https://github.com/ray-project/ray/issues) you encounter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actors\n",
    "Here is an actor example, adapted from the [Ray documentation](https://docs.ray.io/en/latest/async_api.html).\n",
    "\n",
    "Note the comment before `run_concurrent`. While normally actor methods are invoked synchronously, in this case there may be concurrent invocations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "@ray.remote\n",
    "class AsyncActor:\n",
    "    # Multiple invocations of this method can be running in\n",
    "    # the event loop at the same time.\n",
    "    async def run_concurrent(self, index):\n",
    "        print(f'started {index}')\n",
    "        await asyncio.sleep(0.2)   # Concurrent workload here\n",
    "        print(f'finished {index}')\n",
    "        return index\n",
    "\n",
    "actor = AsyncActor.remote()\n",
    "\n",
    "refs = []\n",
    "values = []\n",
    "for i in range(10):\n",
    "    # regular ray.get\n",
    "    refs.append(actor.run_concurrent.remote(i))\n",
    "\n",
    "    # async ray.get\n",
    "    values.append(await actor.run_concurrent.remote(10+i))\n",
    "print(ray.get(refs))\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that using `await` with a method invocation implicitly invokes `ray.get()` on the returned object ref.\n",
    "\n",
    "Under the hood, Ray runs all of the methods inside a single python event loop.\n",
    "\n",
    "> **Note:** Running blocking `ray.get` and `ray.wait` inside async actor methods is not allowed, because `ray.get` will block the execution of the event loop.\n",
    "\n",
    "You can limit the number of concurrent task running at once using the `max_concurrency` flag. By default, 1000 tasks can be running concurrently. \n",
    "\n",
    "In the following cell, we set the `max_concurrency` to `3`, so the subsequent cell will run tasks three at a time. Since there are `12` total, we'll have four groups, each sleeping about `0.2` seconds, so it should take about `0.8` seconds to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor3 = AsyncActor.options(max_concurrency=3).remote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time ray.get([actor3.run_concurrent.remote(i) for i in range(12)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the [03: Ray Internals](../advanced-ray/03-Ray-Internals.ipynb) lesson in the [Advanced Ray](../advanced-ray/00-Advanced-Ray-Overview.ipynb) tutorial for more details on _async actors_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async Tasks\n",
    "\n",
    "For Ray tasks, the object refs returned by them can be converted to `async.Future` instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def some_task():\n",
    "    return 1\n",
    "\n",
    "# The normal Ray way:\n",
    "ref, _ = ray.wait([some_task.remote()])\n",
    "ray.get(ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `asyncio` alternative way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await some_task.remote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = await asyncio.wait([some_task.remote()])\n",
    "print(future)\n",
    "# A tuple is returned:\n",
    "for x in future:\n",
    "    print(f'  {type(x)} => {x}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the [asyncio docs](https://docs.python.org/3/library/asyncio-task.html) for more details on `asyncio` patterns, including timeouts and `asyncio.gather`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()  # \"Undo ray.init()\". Terminate all the processes started in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next lesson, [Ray Parallel Iterators](05-Ray-Parallel-Iterators.ipynb) introduces the _parallel iterator_ API for simple data ingestion and processing. It can be thought of as syntactic sugar around Ray actors and `ray.wait` loops.\n",
    "\n",
    "**NOTE**: Since Ray 1.7, `ray.util.iter` module has been deprecated, so we advice not to use this notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "382.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
